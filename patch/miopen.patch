diff --git a/CMakeLists.txt b/CMakeLists.txt
index f565a52..3973652 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -33,16 +33,16 @@ endif()
 
 # Default installation path
 if(WIN32)
-    set(CMAKE_INSTALL_PREFIX "/opt/rocm/x86_64-w64-mingw32" CACHE PATH "")
+    set(CMAKE_INSTALL_PREFIX "/p/hal/private/rocm-1.6-gcc540/x86_64-w64-mingw32" CACHE PATH "")
 else()
-    set(CMAKE_INSTALL_PREFIX "/opt/rocm" CACHE PATH "")
+    set(CMAKE_INSTALL_PREFIX "/p/hal/private/rocm-1.6-gcc540" CACHE PATH "")
 endif()
 
 project ( MIOpen C CXX )
 
 enable_testing()
 
-find_package(ROCM REQUIRED PATHS /opt/rocm)
+find_package(ROCM REQUIRED PATHS /p/hal/private/rocm-1.6-gcc540)
 
 include(ROCMInstallTargets)
 include(ROCMPackageConfigHelpers)
@@ -90,7 +90,7 @@ endif()
 option(ENABLE_HIP_WORKAROUNDS Off)
 if(ENABLE_HIP_WORKAROUNDS)
     # Add these to CMAKE_PREFIX_PATH to workaround installation problems with hip and hcc
-    list(APPEND CMAKE_PREFIX_PATH /opt/rocm/hcc /opt/rocm/hip)
+    list(APPEND CMAKE_PREFIX_PATH /p/hal/private/rocm-1.6-gcc540/hcc /p/hal/private/rocm-1.6-gcc540/hip)
 endif()
 
 set( MIOPEN_BACKEND ${MIOPEN_DEFAULT_BACKEND} CACHE STRING
@@ -108,7 +108,7 @@ if( MIOPEN_BACKEND STREQUAL "HIP" OR MIOPEN_BACKEND STREQUAL "HIPOC")
     set(MIOPEN_BACKEND_HIP 1)
     find_program(HIP_OC_COMPILER clang-ocl
         PATH_SUFFIXES bin
-        PATHS /opt/rocm
+        PATHS /p/hal/private/rocm-1.6-gcc540
     )
     if(HIP_OC_COMPILER)
         message(STATUS "hip compiler: ${HIP_OC_COMPILER}")
@@ -117,24 +117,26 @@ if( MIOPEN_BACKEND STREQUAL "HIP" OR MIOPEN_BACKEND STREQUAL "HIPOC")
         message(FATAL_ERROR "clang-ocl not found")
     endif()
     
-    find_package(hip REQUIRED PATHS /opt/rocm)
+    find_package(hip REQUIRED PATHS /p/hal/private/rocm-1.6-gcc540)
     link_libraries(stdc++)
     # A hack to make this work without the device enumerator
-    link_libraries(-amdgpu-target=gfx803 -amdgpu-target=gfx900 -Wno-unused-command-line-argument)
+    link_libraries(-amdgpu-target=gfx801 -Wno-unused-command-line-argument)
+    #link_libraries(-amdgpu-target=gfx803 -Wno-unused-command-line-argument)
+    #link_libraries(-amdgpu-target=gfx803 -amdgpu-target=gfx900 -Wno-unused-command-line-argument)
 endif()
 message( STATUS "${MIOPEN_BACKEND} backend selected." )
 
 # Online assembler
 find_program(MIOPEN_AMDGCN_ASSEMBLER
     NAMES clang
-    PATHS ${MIOPEN_AMDGCN_ASSEMBLER_PATH} /opt/rocm
+    PATHS ${MIOPEN_AMDGCN_ASSEMBLER_PATH} /p/hal/private/rocm-1.6-gcc540
     PATH_SUFFIXES /opencl/bin/x86_64
     NO_DEFAULT_PATH
 )
 message(STATUS "AMDGCN assembler: ${MIOPEN_AMDGCN_ASSEMBLER}")
 
 # miopengemm
-find_package(miopengemm PATHS /opt/rocm)
+find_package(miopengemm PATHS /p/hal/private/rocm-1.6-gcc540)
 if(miopengemm_FOUND)
     message(STATUS "Build with miopengemm")
     set(MIOPEN_USE_MIOPENGEMM 1)
@@ -143,6 +145,16 @@ else()
     set(MIOPEN_USE_MIOPENGEMM 0)
 endif()
 
+# rocblas
+find_package(rocblas PATHS /opt/rocm)
+if(rocblas_FOUND)
+    message(STATUS "Build with rocblas")
+    set(MIOPEN_USE_ROCBLAS 1)
+else()
+    message(STATUS "Build without rocblas")
+    set(MIOPEN_USE_ROCBLAS 0)
+endif()
+
 find_package(OpenSSL REQUIRED)
 set(BOOST_COMPONENTS filesystem system)
 add_definitions(-DBOOST_ALL_NO_LIB=1)
@@ -269,6 +281,7 @@ enable_cppcheck(
         ${CMAKE_CURRENT_SOURCE_DIR}/src/include
     DEFINE
         MIOPEN_USE_MIOPENGEMM=1
+        MIOPEN_USE_ROCBLAS=1
 )
 
 set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}/lib)
diff --git a/include/miopen/config.h.in b/include/miopen/config.h.in
index be10d7d..637bd66 100644
--- a/include/miopen/config.h.in
+++ b/include/miopen/config.h.in
@@ -29,6 +29,7 @@
 #cmakedefine01 MIOPEN_BACKEND_OPENCL
 #cmakedefine01 MIOPEN_BACKEND_HCC
 #cmakedefine01 MIOPEN_BACKEND_HIP
+#cmakedefine01 MIOPEN_USE_ROCBLAS
 #cmakedefine01 MIOPEN_USE_MIOPENGEMM
 #cmakedefine01 MIOPEN_BUILD_DEV
 
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index cc3205c..e60e3e9 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -168,6 +168,8 @@ if( MIOPEN_BACKEND MATCHES "OpenCL" OR MIOPEN_BACKEND STREQUAL "HIPOC" OR MIOPEN
         kernels/conv7x7c3h224w224k64u2v2p3q3f1.s
         kernels/MIOpenTensorKernels.cl
         kernels/MIOpenTensorScaleKernel.cl
+        kernels/MIOpenSubTensorOpWithScalarKernel.cl
+        kernels/MIOpenSubTensorOpWithSubTensorKernel.cl
         kernels/conv_3x3_wheel_alpha_v9_0_15_gfx803_m30.so
         kernels/conv_3x3_wheel_alpha_v9_0_15_stride_2_dil_gfx803_m30.so
         kernels/conv_3x3_wheel_alpha_v9_0_15_stride_2_dec_gfx803_m30.so
@@ -218,6 +220,7 @@ endif()
 if(miopengemm_FOUND)
     list(APPEND MIOpen_Source 
         gemm.cpp
+        gemm_v2.cpp
         gemm_api.cpp
         gemm_geometry.cpp
     )
@@ -304,6 +307,11 @@ if(miopengemm_FOUND)
     target_link_libraries( MIOpen PUBLIC miopengemm )
 endif()
 
+if(rocblas_FOUND)
+    target_link_libraries( MIOpen INTERFACE $<BUILD_INTERFACE:roc::rocblas> )
+    target_link_libraries( MIOpen PRIVATE roc::rocblas )
+endif()
+
 if(WIN32 AND NOT MSVC)
     if(BUILD_DEV)
         target_link_libraries(MIOpen PUBLIC -Wl,-export-all-symbols -Wl,-exclude-symbols=_Unwind_Resume)
diff --git a/src/binary_cache.cpp b/src/binary_cache.cpp
index a83842f..096b2a5 100644
--- a/src/binary_cache.cpp
+++ b/src/binary_cache.cpp
@@ -78,7 +78,13 @@ boost::filesystem::path GetCacheFile(const std::string& device,
                                      bool is_kernel_str)
 {
     std::string filename = (is_kernel_str ? miopen::md5(name) : name) + ".o";
-    return GetCachePath() / miopen::md5(device + ":" + args) / filename;
+    //return GetCachePath() / miopen::md5(device + ":" + args) / filename;
+    boost::filesystem::path currPath = GetCachePath() /
+      miopen::md5(device + ":" + args) / filename;
+    std::cout << "Device: " << device << ", Cache File: "
+              << currPath.native() << std::endl
+              << std::flush; // ** TEMP: DEBUG ONLY
+    return currPath;
 }
 
 std::string LoadBinary(const std::string& device,
@@ -91,10 +97,12 @@ std::string LoadBinary(const std::string& device,
     auto f = GetCacheFile(device, name, args, is_kernel_str);
     if(boost::filesystem::exists(f))
     {
+        //std::cout << "Cache file: " << f.string() << std::endl << std::flush; // ** TEMP: DEBUG ONLY
         return f.string();
     }
     else
     {
+        std::cout << "Cache file does not exist\n" << std::flush; // ** TEMP: DEBUG ONLY
         return {};
     }
 }
diff --git a/src/db_record.cpp b/src/db_record.cpp
index 113bb37..cb93890 100644
--- a/src/db_record.cpp
+++ b/src/db_record.cpp
@@ -314,7 +314,7 @@ bool DbRecord::Flush(const RecordPositions* const pos)
 
         if(!file)
         {
-            MIOPEN_LOG_E("File is unwritable.");
+            MIOPEN_LOG_E("File " + db_filename + " is unwritable.");
             return false;
         }
 
@@ -328,7 +328,7 @@ bool DbRecord::Flush(const RecordPositions* const pos)
 
         if(!from)
         {
-            MIOPEN_LOG_E("File is unreadable.");
+            MIOPEN_LOG_E("File " + db_filename + " is unreadable.");
             return false;
         }
 
@@ -336,7 +336,7 @@ bool DbRecord::Flush(const RecordPositions* const pos)
 
         if(!to)
         {
-            MIOPEN_LOG_E("Temp file is unwritable.");
+            MIOPEN_LOG_E("Temp file " + temp_name + " is unwritable.");
             return false;
         }
 
@@ -377,7 +377,7 @@ void DbRecord::ReadFile(RecordPositions* const pos)
 
     if(!file)
     {
-        MIOPEN_LOG_W("File is unreadable.");
+        MIOPEN_LOG_W("File " + db_filename + " is unreadable.");
         return;
     }
 
diff --git a/src/gemm_v2.cpp b/src/gemm_v2.cpp
new file mode 100644
index 0000000..0898734
--- /dev/null
+++ b/src/gemm_v2.cpp
@@ -0,0 +1,913 @@
+/*******************************************************************************
+ *
+ * MIT License
+ *
+ * Copyright (c) 2017 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *******************************************************************************/
+#include <miopen/gemm_v2.hpp>
+#include <miopen/logger.hpp>
+#include <miopen/env.hpp>
+
+#if MIOPEN_USE_ROCBLAS
+//#include <half.hpp>
+#include <rocblas.h>
+#include <miopen/hipoc_kernel.hpp>
+#include <miopen/perf_field.hpp>
+#endif
+
+#if MIOPEN_USE_ROCBLAS
+#define ROCBLAS_TIMING_MEMSET_SIZE (10 * 1024 * 1024)
+#endif
+
+MIOPEN_DECLARE_ENV_VAR(MIOPEN_GEMM_ENFORCE_BACKEND)
+
+namespace miopen {
+
+#if MIOPEN_USE_ROCBLAS
+// Enqueue gpu memset for rocblas kernel timing purpose
+// Be careful, will set mem to 0
+static void
+dummy_memset(Handle& handle, Data_t mem, std::size_t mem_len, miopenDataType_t data_type)
+{
+    MIOPEN_LOG_I2("dummy gpu memset");
+
+    std::size_t data_size = 0;
+
+    switch(data_type)
+    {
+       case miopenHalf:
+           break;
+       case miopenFloat:
+       {
+           data_size = sizeof(float);
+           break;
+       }
+    }
+
+    std::size_t sz = mem_len * data_size;
+
+    for(std::size_t i = 0; i < ROCBLAS_TIMING_MEMSET_SIZE; i += sz)
+#ifdef DGPU
+       hipMemsetAsync(mem, 0, sz, handle.GetStream());
+#else
+       memset(mem, 0, sz);
+#endif
+}
+#endif
+
+// hacks: control GEMM backend by enviroment variable and build option
+// very nasty
+static GemmBackend_t enforce_gemm_backend(miopenDataType_t data_type,
+                                          GemmBackend_t gemm_backend_preferred)
+{
+    GemmBackend_t gemm_backend_enforced = GemmBackend_t::nogemmbackend;
+    GemmBackend_t gemm_backend_env      = GemmBackend_t::nogemmbackend;
+
+    // enforce backend based on env variable
+    switch(Value(MIOPEN_GEMM_ENFORCE_BACKEND{}))
+    {
+    case 1: gemm_backend_env  = GemmBackend_t::rocblas; break;
+    case 2: gemm_backend_env  = GemmBackend_t::miopengemm; break;
+    case 3: gemm_backend_env  = GemmBackend_t::nogemmbackend; break;
+    default: gemm_backend_env = gemm_backend_preferred;
+    }
+
+// make sure backend chosen based on env variable is suppported
+#if MIOPEN_USE_ROCBLAS and MIOPEN_USE_MIOPENGEMM
+    switch(gemm_backend_env)
+    {
+    case GemmBackend_t::nogemmbackend: gemm_backend_enforced = GemmBackend_t::nogemmbackend; break;
+    case GemmBackend_t::rocblas: gemm_backend_enforced       = GemmBackend_t::rocblas; break;
+    case GemmBackend_t::miopengemm:
+        gemm_backend_enforced =
+            (data_type == miopenFloat) ? GemmBackend_t::miopengemm : GemmBackend_t::rocblas;
+        break;
+    }
+#elif MIOPEN_USE_ROCBLAS
+    switch(gemm_backend_env)
+    {
+    case GemmBackend_t::nogemmbackend: gemm_backend_enforced = GemmBackend_t::nogemmbackend; break;
+    case GemmBackend_t::rocblas:
+    case GemmBackend_t::miopengemm: gemm_backend_enforced = GemmBackend_t::rocblas; break;
+    }
+#elif MIOPEN_USE_MIOPENGEMM
+    switch(gemm_backend_env)
+    {
+    case GemmBackend_t::nogemmbackend: gemm_backend_enforced = GemmBackend_t::nogemmbackend; break;
+    case GemmBackend_t::rocblas:
+    case GemmBackend_t::miopengemm:
+        gemm_backend_enforced =
+            (data_type == miopenFloat) ? GemmBackend_t::miopengemm : GemmBackend_t::nogemmbackend;
+        break;
+    }
+#else
+    gemm_backend_enforced = GemmBackend_t::nogemmbackend;
+#endif
+
+    return gemm_backend_enforced;
+}
+
+miopenStatus_t CallGemm(Handle& handle,
+                        GemmDescriptor gemm_desc,
+                        ConstData_t A,
+                        int a_offset,
+                        ConstData_t B,
+                        int b_offset,
+                        Data_t C,
+                        int c_offset,
+                        std::string* kcache_key,
+                        bool enqueue_dummy_kernel,
+                        GemmBackend_t gemm_backend)
+{
+#if !MIOPEN_USE_ROCBLAS
+    (void)enqueue_dummy_kernel;
+#endif
+
+    gemm_backend = enforce_gemm_backend(gemm_desc.dataType, gemm_backend);
+    // do row-to-column major conversion here
+    if(!gemm_desc.isColMajor)
+    {
+        gemm_desc.isColMajor = true;
+        std::swap(A, B);
+        std::swap(a_offset, b_offset);
+        std::swap(gemm_desc.transA, gemm_desc.transB);
+        std::swap(gemm_desc.m, gemm_desc.n);
+        std::swap(gemm_desc.lda, gemm_desc.ldb);
+    }
+
+    switch(gemm_backend)
+    {
+       case GemmBackend_t::nogemmbackend: return miopenStatusNotImplemented;
+       case GemmBackend_t::miopengemm: return miopenStatusNotImplemented;
+#if MIOPEN_USE_ROCBLAS
+       case GemmBackend_t::rocblas: 
+       {
+           MIOPEN_LOG_FUNCTION("rocBLAS");
+
+           HipEventPtr start = nullptr;
+           HipEventPtr stop  = nullptr;
+           if(handle.IsProfilingEnabled())
+           {
+               if(enqueue_dummy_kernel)
+               {
+                   dummy_memset(handle, C, gemm_desc.m * gemm_desc.n, gemm_desc.dataType);
+               }
+
+               start = make_hip_event();
+               stop  = make_hip_event();
+               hipEventRecord(start.get(), handle.GetStream());
+           }
+
+           rocblas_status rb_status = rocblas_status::rocblas_status_internal_error;
+
+           switch(gemm_desc.dataType)
+           {
+               case miopenHalf: return miopenStatusNotImplemented;
+               case miopenFloat:
+               {
+                   float alpha = gemm_desc.alpha;
+                   float beta  = gemm_desc.beta;
+
+                   rocblas_set_stream(handle.rhandle.get(), handle.GetStream());
+
+                   rb_status   = rocblas_sgemm(
+                       handle.rhandle.get(),
+                       gemm_desc.transA ? rocblas_operation_transpose : rocblas_operation_none,
+                       gemm_desc.transB ? rocblas_operation_transpose : rocblas_operation_none,
+                       gemm_desc.m,
+                       gemm_desc.n,
+                       gemm_desc.k,
+                       &alpha,
+                       static_cast<const float*>(A) + a_offset,
+                       gemm_desc.lda,
+                       static_cast<const float*>(B) + b_offset,
+                       gemm_desc.ldb,
+                       &beta,
+                       static_cast<float*>(C) + c_offset,
+                       gemm_desc.ldc);
+               }
+               break;
+           }
+
+           if(handle.IsProfilingEnabled())
+           {
+               hipEventRecord(stop.get(), handle.GetStream());
+               hipEventSynchronize(stop.get());
+               float mS = 0;
+               hipEventElapsedTime(&mS, start.get(), stop.get());
+               handle.ResetKernelTime();
+               handle.AccumKernelTime(mS);
+           }
+
+           if(kcache_key != nullptr)
+               *kcache_key = FindDbData::GetUnusedKCacheKey();
+
+           if(rb_status != rocblas_status::rocblas_status_success)
+               MIOPEN_THROW(miopenStatusInternalError, "rocBlas error encountered");
+
+           return miopenStatusSuccess;
+       }
+#endif
+    }
+
+    return miopenStatusUnknownError;
+}
+
+// y = w * Im2Col(x)
+GemmDescriptor CreateGemmDescriptorConvFwd(const TensorDescriptor& wDesc,
+                                           const TensorDescriptor& xDesc,
+                                           const TensorDescriptor& yDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == xDesc.GetType() && wDesc.GetType() == yDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(yDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = false;
+    int m                 = wei_n;
+    int n                 = out_h * out_w;
+    int k                 = in_c * wei_h * wei_w;
+    int lda               = k;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = 1;
+    long long int strideA = 0;
+    long long int strideB = 0;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// dx = Col2Im(transpose(w) * dy)
+GemmDescriptor CreateGemmDescriptorConvBwdData(const TensorDescriptor& wDesc,
+                                               const TensorDescriptor& dyDesc,
+                                               const TensorDescriptor& dxDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == dxDesc.GetType() && wDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(dxDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = true;
+    bool transB           = false;
+    int m                 = in_c * wei_h * wei_w;
+    int n                 = out_h * out_w;
+    int k                 = wei_n;
+    int lda               = m;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = 1;
+    long long int strideA = 0;
+    long long int strideB = 0;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          dxDesc.GetType()};
+}
+
+// dw = dy * transpose(Im2Col(x))
+GemmDescriptor CreateGemmDescriptorConvBwdWeight(const TensorDescriptor& dyDesc,
+                                                 const TensorDescriptor& xDesc,
+                                                 const TensorDescriptor& dwDesc)
+{
+#ifndef NDEBUG
+    assert(dwDesc.GetType() == xDesc.GetType() && dwDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(dwDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = true;
+    int m                 = wei_n;
+    int n                 = in_c * wei_h * wei_w;
+    int k                 = out_h * out_w;
+    int lda               = k;
+    int ldb               = k;
+    int ldc               = n;
+    int batch_count       = 1;
+    long long int strideA = 0;
+    long long int strideB = 0;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 1.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// y = CNHW2NCHW(w * NCHW2CNHW(x))
+GemmDescriptor CreateGemmDescriptorConvCNHWFwd(const TensorDescriptor& wDesc,
+                                               const TensorDescriptor& xDesc,
+                                               const TensorDescriptor& yDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == xDesc.GetType() && wDesc.GetType() == yDesc.GetType());
+#endif
+
+    int in_n, in_c;
+    std::tie(in_n, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(yDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = false;
+    int m                 = wei_n;
+    int n                 = in_n * out_h * out_w;
+    int k                 = in_c;
+    int lda               = k;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = 1;
+    long long int strideA = 0;
+    long long int strideB = 0;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// dx = CNHW2NCHW(transpose(w) * NCHW2CNHW(dy))
+GemmDescriptor CreateGemmDescriptorConvCNHWBwdData(const TensorDescriptor& wDesc,
+                                                   const TensorDescriptor& dyDesc,
+                                                   const TensorDescriptor& dxDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == dxDesc.GetType() && wDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_n, in_c;
+    std::tie(in_n, in_c, std::ignore, std::ignore) = tien<4>(dxDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = true;
+    bool transB           = false;
+    int m                 = in_c;
+    int n                 = in_n * out_h * out_w;
+    int k                 = wei_n;
+    int lda               = m;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = 1;
+    long long int strideA = 0;
+    long long int strideB = 0;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          dxDesc.GetType()};
+}
+
+// y[i] = w * x[i], i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1Fwd(const TensorDescriptor& wDesc,
+                                                            const TensorDescriptor& xDesc,
+                                                            const TensorDescriptor& yDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == xDesc.GetType() && wDesc.GetType() == yDesc.GetType());
+#else
+    (void)yDesc;
+#endif
+
+    int in_n, in_c, in_h, in_w;
+    std::tie(in_n, in_c, in_h, in_w) = tien<4>(xDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = false;
+    int m                 = wei_n;
+    int n                 = in_h * in_w;
+    int k                 = in_c;
+    int lda               = k;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = in_n;
+    long long int strideA = 0;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// dx[i] = transpose(w) * dy[i], i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1BwdData(const TensorDescriptor& wDesc,
+                                                                const TensorDescriptor& dyDesc,
+                                                                const TensorDescriptor& dxDesc)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == dxDesc.GetType() && wDesc.GetType() == dyDesc.GetType());
+#else
+    (void)dyDesc;
+#endif
+
+    int in_n, in_c, in_h, in_w;
+    std::tie(in_n, in_c, in_h, in_w) = tien<4>(dxDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = true;
+    bool transB           = false;
+    int m                 = in_c;
+    int n                 = in_h * in_w;
+    int k                 = wei_n;
+    int lda               = m;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = in_n;
+    long long int strideA = 0;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          dxDesc.GetType()};
+}
+
+// dw = sum_over_batch(dy[i] * transpose(x[i])), i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1BwdWeight(const TensorDescriptor& dyDesc,
+                                                                  const TensorDescriptor& xDesc,
+                                                                  const TensorDescriptor& dwDesc)
+{
+#ifndef NDEBUG
+    assert(dwDesc.GetType() == xDesc.GetType() && dwDesc.GetType() == dyDesc.GetType());
+#else
+    (void)dyDesc;
+#endif
+
+    int in_n, in_c, in_h, in_w;
+    std::tie(in_n, in_c, in_h, in_w) = tien<4>(xDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(dwDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = true;
+    int m                 = wei_n;
+    int n                 = in_c;
+    int k                 = in_h * in_w;
+    int lda               = k;
+    int ldb               = k;
+    int ldc               = n;
+    int batch_count       = in_n;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = 0;
+    float alpha           = 1.;
+    float beta            = 1.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// y = w * Im2Col(x)
+GemmDescriptor CreateGemmDescriptorGroupConvFwd(const TensorDescriptor& wDesc,
+                                                const TensorDescriptor& xDesc,
+                                                const TensorDescriptor& yDesc,
+                                                int groupCount)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == xDesc.GetType() && wDesc.GetType() == yDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(yDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = false;
+    int m                 = wei_n / groupCount;
+    int n                 = out_h * out_w;
+    int k                 = (in_c / groupCount) * wei_h * wei_w;
+    int lda               = k;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = groupCount;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// dx = Col2Im(transpose(w) * dy)
+GemmDescriptor CreateGemmDescriptorGroupConvBwdData(const TensorDescriptor& wDesc,
+                                                    const TensorDescriptor& dyDesc,
+                                                    const TensorDescriptor& dxDesc,
+                                                    int groupCount)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == dxDesc.GetType() && wDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(dxDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = true;
+    bool transB           = false;
+    int m                 = (in_c / groupCount) * wei_h * wei_w;
+    int n                 = out_h * out_w;
+    int k                 = wei_n / groupCount;
+    int lda               = m;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = groupCount;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          dxDesc.GetType()};
+}
+
+// dw = dy * transpose(Im2Col(x))
+GemmDescriptor CreateGemmDescriptorGroupConvBwdWeight(const TensorDescriptor& dyDesc,
+                                                      const TensorDescriptor& xDesc,
+                                                      const TensorDescriptor& dwDesc,
+                                                      int groupCount)
+{
+#ifndef NDEBUG
+    assert(dwDesc.GetType() == xDesc.GetType() && dwDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_c;
+    std::tie(std::ignore, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n, wei_h, wei_w;
+    std::tie(wei_n, std::ignore, wei_h, wei_w) = tien<4>(dwDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = true;
+    int m                 = wei_n / groupCount;
+    int n                 = (in_c / groupCount) * wei_h * wei_w;
+    int k                 = out_h * out_w;
+    int lda               = k;
+    int ldb               = k;
+    int ldc               = n;
+    int batch_count       = groupCount;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 1.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// y = CNHW2NCHW(w * NCHW2CNHW(x))
+GemmDescriptor CreateGemmDescriptorGroupConvCNHWFwd(const TensorDescriptor& wDesc,
+                                                    const TensorDescriptor& xDesc,
+                                                    const TensorDescriptor& yDesc,
+                                                    int groupCount)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == xDesc.GetType() && wDesc.GetType() == yDesc.GetType());
+#endif
+
+    int in_n, in_c;
+    std::tie(in_n, in_c, std::ignore, std::ignore) = tien<4>(xDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(yDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = false;
+    bool transB           = false;
+    int m                 = wei_n / groupCount;
+    int n                 = in_n * out_h * out_w;
+    int k                 = in_c / groupCount;
+    int lda               = k;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = groupCount;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          xDesc.GetType()};
+}
+
+// dx = CNHW2NCHW(transpose(w) * NCHW2CNHW(dy))
+GemmDescriptor CreateGemmDescriptorGroupConvCNHWBwdData(const TensorDescriptor& wDesc,
+                                                        const TensorDescriptor& dyDesc,
+                                                        const TensorDescriptor& dxDesc,
+                                                        int groupCount)
+{
+#ifndef NDEBUG
+    assert(wDesc.GetType() == dxDesc.GetType() && wDesc.GetType() == dyDesc.GetType());
+#endif
+
+    int in_n, in_c;
+    std::tie(in_n, in_c, std::ignore, std::ignore) = tien<4>(dxDesc.GetLengths());
+
+    int wei_n;
+    std::tie(wei_n, std::ignore, std::ignore, std::ignore) = tien<4>(wDesc.GetLengths());
+
+    int out_h, out_w;
+    std::tie(std::ignore, std::ignore, out_h, out_w) = tien<4>(dyDesc.GetLengths());
+
+    bool isColMajor       = false;
+    bool transA           = true;
+    bool transB           = false;
+    int m                 = in_c / groupCount;
+    int n                 = in_n * out_h * out_w;
+    int k                 = wei_n / groupCount;
+    int lda               = m;
+    int ldb               = n;
+    int ldc               = n;
+    int batch_count       = groupCount;
+    long long int strideA = m * k;
+    long long int strideB = k * n;
+    long long int strideC = m * n;
+    float alpha           = 1.;
+    float beta            = 0.;
+
+    return GemmDescriptor{isColMajor,
+                          transA,
+                          transB,
+                          m,
+                          n,
+                          k,
+                          lda,
+                          ldb,
+                          ldc,
+                          batch_count,
+                          strideA,
+                          strideB,
+                          strideC,
+                          alpha,
+                          beta,
+                          dxDesc.GetType()};
+}
+
+} // namespace miopen
diff --git a/src/hip/handlehip.cpp b/src/hip/handlehip.cpp
index 0d5fef8..3360874 100644
--- a/src/hip/handlehip.cpp
+++ b/src/hip/handlehip.cpp
@@ -39,6 +39,9 @@
 #include <chrono>
 #include <thread>
 
+/* if defined, use hipMalloc/Memcpy/Free, else unified address space */
+//#define DGPU
+
 namespace miopen {
 
 // Get current context
@@ -64,21 +67,43 @@ std::size_t GetAvailableMemory()
 
 void* default_allocator(void*, size_t sz)
 {
+    void* result;
+#ifdef DGPU
     if(sz > GetAvailableMemory())
         MIOPEN_THROW("Memory not available to allocate buffer: " + std::to_string(sz));
-    void* result;
     auto status = hipMalloc(&result, sz);
+    //fprintf(stdout, "*** hipMalloc in MIOpen: result: %#lx, &: %#lx ***\n", result, &result); // ** TEMP: DEBUG ONLY
     if(status != hipSuccess)
     {
         status = hipHostMalloc(&result, sz);
+        fprintf(stdout, "*** hipHostMalloc in MIOpen: result: %%#lx, &: %#lx ***\n", result, &result); // ** TEMP: DEBUG ONLY
         if(status != hipSuccess)
             MIOPEN_THROW_HIP_STATUS(status,
                                     "Hip error creating buffer " + std::to_string(sz) + ": ");
     }
+#else // APU
+    if (posix_memalign(&result, 64, sz)) {
+      fprintf(stdout, "*** (Error) Cache-line aligned malloc in MIOpen default allocator: %#lx, &: %#lx ***\n", result, &result); // ** TEMP: DEBUG ONLY
+        MIOPEN_THROW("Error: posix_memalign failed creating buffer " + std::to_string(sz) + ": ");
+        free(result);
+        exit(-1);
+    } else {
+      fprintf(stdout, "*** Cache-line aligned malloc in MIOpen default allocator: %#lx, &: %#lx ***\n", result, &result); // ** TEMP: DEBUG ONLY
+    }
+#endif // #ifdef DGPU
     return result;
 }
 
-void default_deallocator(void*, void* mem) { hipFree(mem); }
+void default_deallocator(void*, void* mem) {
+    //fprintf(stdout, "*** hipFree in MIOpen: mem: %#lx, &: %#lx ***\n", mem, &mem); // ** TEMP: DEBUG ONLY
+#ifdef DGPU
+    hipFree(mem);
+#else // APU
+    if (mem) {
+        free(mem);
+    }
+#endif // #ifdef DGPU
+}
 
 int get_device_id() // Get random device
 {
@@ -172,6 +197,10 @@ Handle::Handle(miopenAcceleratorQueue_t stream) : impl(new HandleImpl())
         this->impl->stream = HandleImpl::reference_stream(stream);
 
     this->SetAllocator(nullptr, nullptr, nullptr);
+
+#if MIOPEN_USE_ROCBLAS
+    rhandle = CreateRocblasHandle();
+#endif
 }
 
 Handle::Handle() : impl(new HandleImpl())
@@ -186,6 +215,10 @@ Handle::Handle() : impl(new HandleImpl())
     this->impl->stream = HandleImpl::reference_stream(nullptr);
 #endif
     this->SetAllocator(nullptr, nullptr, nullptr);
+
+#if MIOPEN_USE_ROCBLAS
+    rhandle = CreateRocblasHandle();
+#endif
 }
 
 Handle::~Handle() {}
@@ -220,25 +253,52 @@ Allocator::ManageDataPtr&
 Handle::WriteTo(const void* data, Allocator::ManageDataPtr& ddata, std::size_t sz)
 {
     this->Finish();
+    //fprintf(stdout, "*** hipMemcpy H2D in MIOpen ***\n"); // ** TEMP: DEBUG ONLY
+#ifdef DGPU
     auto status = hipMemcpy(ddata.get(), data, sz, hipMemcpyHostToDevice);
     if(status != hipSuccess)
         MIOPEN_THROW_HIP_STATUS(status, "Hip error writing to buffer: ");
+#else // APU
+    void * retPtr = memcpy(ddata.get(), data, sz);
+    if (retPtr == nullptr)
+    {
+        MIOPEN_THROW("Error writing to buffer: ");
+    }
+#endif // #ifdef DGPU
     return ddata;
 }
 void Handle::ReadTo(void* data, const Allocator::ManageDataPtr& ddata, std::size_t sz)
 {
     this->Finish();
+    //fprintf(stdout, "*** hipMemcpy D2H in MIOpen ***\n"); // ** TEMP: DEBUG ONLY
+#ifdef DGPU
     auto status = hipMemcpy(data, ddata.get(), sz, hipMemcpyDeviceToHost);
     if(status != hipSuccess)
         MIOPEN_THROW_HIP_STATUS(status, "Hip error reading from buffer: ");
+#else // APU
+    void * retPtr = memcpy(data, ddata.get(), sz);
+    if (retPtr == nullptr)
+    {
+        MIOPEN_THROW("Error reading from buffer: ");
+    }
+#endif // #ifdef DGPU
 }
 
 void Handle::Copy(ConstData_t src, Data_t dest, std::size_t size)
 {
     this->impl->set_ctx();
+    //fprintf(stdout, "*** hipMemcpy D2D in MIOpen ***\n"); // ** TEMP: DEBUG ONLY
+#ifdef DGPU
     auto status = hipMemcpy(dest, src, size, hipMemcpyDeviceToDevice);
     if(status != hipSuccess)
         MIOPEN_THROW_HIP_STATUS(status, "Hip error copying buffer: ");
+#else // APU
+    void * retPtr = memcpy(dest, src, size);
+    if (retPtr == nullptr)
+    {
+        MIOPEN_THROW("Error copying buffer: ");
+    }
+#endif // #ifdef DGPU
 }
 
 KernelInvoke Handle::GetKernel(const std::string& algorithm,
@@ -364,4 +424,15 @@ shared<ConstData_t> Handle::CreateSubBuffer(ConstData_t data, std::size_t offset
     auto cdata = reinterpret_cast<const char*>(data);
     return {cdata + offset, null_deleter{}};
 }
+
+#if MIOPEN_USE_ROCBLAS
+rocblas_handle_ptr Handle::CreateRocblasHandle() const
+{
+    rocblas_handle x = nullptr;
+    rocblas_create_handle(&x);
+    auto result = rocblas_handle_ptr(x);
+    rocblas_set_stream(result.get(), GetStream());
+    return result;
+}
+#endif
 } // namespace miopen
diff --git a/src/hipoc/hipoc_kernel.cpp b/src/hipoc/hipoc_kernel.cpp
index c39e7d4..f103366 100644
--- a/src/hipoc/hipoc_kernel.cpp
+++ b/src/hipoc/hipoc_kernel.cpp
@@ -55,7 +55,7 @@ void HIPOCKernelInvoke::run(void* args, std::size_t size) const
     }
 
     // std::cerr << "Launch kernel: " << name << std::endl;
-
+    std::cout << "Launch kernel: " << name << std::endl << std::flush; // ** TEMP: DEBUG ONLY
     auto status = hipHccModuleLaunchKernel(fun,
                                            gdims[0],
                                            gdims[1],
diff --git a/src/include/miopen/gemm_v2.hpp b/src/include/miopen/gemm_v2.hpp
new file mode 100644
index 0000000..3ac873e
--- /dev/null
+++ b/src/include/miopen/gemm_v2.hpp
@@ -0,0 +1,190 @@
+/*******************************************************************************
+ *
+ * MIT License
+ *
+ * Copyright (c) 2017 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *******************************************************************************/
+#ifndef GUARD_MIOPEN_GEMM_V2_HPP_
+#define GUARD_MIOPEN_GEMM_V2_HPP_
+
+#include <miopen/miopen.h>
+#include <miopen/handle.hpp>
+#include <miopen/tensor.hpp>
+
+namespace miopen {
+
+enum GemmBackend_t
+{
+    nogemmbackend = 0,
+    rocblas       = 1,
+    miopengemm    = 2,
+};
+
+// GEMM operation: C = alpha * op(A) * op(B) + beta * C.
+// op() can be either transpose or no-operation for A or B.
+// The shape (nRow x nCol) of op(A), op(B), C are:
+//   m x k,
+//   k x n,
+//   m x n.
+// A, B, C are what are actually being saved in memory,
+//   they can either be all column-major or all row-major.
+// lda, ldb, ldc are leading dimension strides of memory for A, B, C,
+//   and leading dimension stride is:
+//     cross-column memory stride for column-major A, B, C,
+//     cross-row    memory stride for row   -major A, B, C
+// for strided batched GEMM
+//   strideA, strideB, strideC are the strides of the matrices
+struct GemmDescriptor
+{
+    bool isColMajor;
+    bool transA, transB;
+    int m, n, k;
+    int lda, ldb, ldc;
+    int batch_count;
+    long long int strideA, strideB, strideC;
+    float alpha, beta;
+    miopenDataType_t dataType;
+};
+
+miopenStatus_t CallGemm(Handle& handle,
+                        GemmDescriptor gemm_desc,
+                        ConstData_t A,
+                        int a_offset,
+                        ConstData_t B,
+                        int b_offset,
+                        Data_t C,
+                        int c_offset,
+                        std::string* kcache_key,
+                        bool enqueue_dummy_kernel,
+                        GemmBackend_t gemm_backend = GemmBackend_t::rocblas);
+
+miopenStatus_t CallGemmStridedBatched(Handle& handle,
+                                      GemmDescriptor gemm_desc,
+                                      ConstData_t A,
+                                      int a_offset,
+                                      ConstData_t B,
+                                      int b_offset,
+                                      Data_t C,
+                                      int c_offset,
+                                      std::string* kcache_key,
+                                      bool enqueue_dummy_kernel,
+                                      GemmBackend_t gemm_backend = GemmBackend_t::rocblas);
+
+miopenStatus_t
+CallGemmStridedBatchedSequential(Handle& handle,
+                                 GemmDescriptor gemm_desc,
+                                 ConstData_t A,
+                                 int a_offset,
+                                 ConstData_t B,
+                                 int b_offset,
+                                 Data_t C,
+                                 int c_offset,
+                                 std::string* kcache_key,
+                                 bool enqueue_dummy_kernel,
+                                 GemmBackend_t gemm_backend = GemmBackend_t::rocblas);
+
+// GEMM parameters for Convolution (using Im2Col) Fwd
+// y = w * Im2Col(x)
+GemmDescriptor CreateGemmDescriptorConvFwd(const TensorDescriptor& wDesc,
+                                           const TensorDescriptor& xDesc,
+                                           const TensorDescriptor& yDesc);
+
+// GEMM parameters for Convolution (using Im2Col) Bwd-Data
+// dx = Col2Im(transpose(w) * dy)
+GemmDescriptor CreateGemmDescriptorConvBwdData(const TensorDescriptor& wDesc,
+                                               const TensorDescriptor& dyDesc,
+                                               const TensorDescriptor& dxDesc);
+
+// GEMM parameters for Convolution (using Im2Col) Bwd-Weight
+// dw = dy * transpose(Im2Col(x))
+GemmDescriptor CreateGemmDescriptorConvBwdWeight(const TensorDescriptor& dyDesc,
+                                                 const TensorDescriptor& xDesc,
+                                                 const TensorDescriptor& dwDesc);
+
+// GEMM parameters for 1x1 Convolution (using CNHW) Fwd
+// y = CNHW2NCHW(w * NCHW2CNHW(x))
+GemmDescriptor CreateGemmDescriptorConvCNHWFwd(const TensorDescriptor& wDesc,
+                                               const TensorDescriptor& xDesc,
+                                               const TensorDescriptor& yDesc);
+
+// GEMM parameters for 1x1 Convolution (using CNHW) Bwd-Data
+// dx = CNHW2NCHW(transpose(w) * NCHW2CNHW(dy))
+GemmDescriptor CreateGemmDescriptorConvCNHWBwdData(const TensorDescriptor& wDesc,
+                                                   const TensorDescriptor& dyDesc,
+                                                   const TensorDescriptor& dxDesc);
+
+// strided batched GEMM parameters for 1x1 Convolution Fwd
+// y[i] = w * x[i], i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1Fwd(const TensorDescriptor& wDesc,
+                                                            const TensorDescriptor& xDesc,
+                                                            const TensorDescriptor& yDesc);
+
+// strided batched GEMM parameters for 1x1 Convolution Bwd-Data
+// dx[i] = transpose(w) * dy[i], i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1BwdData(const TensorDescriptor& wDesc,
+                                                                const TensorDescriptor& dyDesc,
+                                                                const TensorDescriptor& dxDesc);
+
+// strided batched GEMM parameters for 1x1 Convolution Bwd-Weight
+// dw = sum_over_batch(dy[i] * transpose(x[i])), i is batch id
+GemmDescriptor CreateGemmStridedBatchedDescriptorConv1x1BwdWeight(const TensorDescriptor& dyDesc,
+                                                                  const TensorDescriptor& xDesc,
+                                                                  const TensorDescriptor& dwDesc);
+
+// GEMM parameters for Group Convolution (using Im2Col) Fwd
+// y = w * Im2Col(x)
+GemmDescriptor CreateGemmDescriptorGroupConvFwd(const TensorDescriptor& wDesc,
+                                                const TensorDescriptor& xDesc,
+                                                const TensorDescriptor& yDesc,
+                                                int groupCount = 1);
+
+// GEMM parameters for Group Convolution (using Im2Col) Bwd-Data
+// dx = Col2Im(transpose(w) * dy)
+GemmDescriptor CreateGemmDescriptorGroupConvBwdData(const TensorDescriptor& wDesc,
+                                                    const TensorDescriptor& dyDesc,
+                                                    const TensorDescriptor& dxDesc,
+                                                    int groupCount = 1);
+
+// GEMM parameters for Group Convolution (using Im2Col) Bwd-Weight
+// dw = dy * transpose(Im2Col(x))
+GemmDescriptor CreateGemmDescriptorGroupConvBwdWeight(const TensorDescriptor& dyDesc,
+                                                      const TensorDescriptor& xDesc,
+                                                      const TensorDescriptor& dwDesc,
+                                                      int groupCount = 1);
+
+// GEMM parameters for 1x1 Group Convolution (using CNHW) Fwd
+// y = CNHW2NCHW(w * NCHW2CNHW(x))
+GemmDescriptor CreateGemmDescriptorGroupConvCNHWFwd(const TensorDescriptor& wDesc,
+                                                    const TensorDescriptor& xDesc,
+                                                    const TensorDescriptor& yDesc,
+                                                    int groupCount = 1);
+
+// GEMM parameters for 1x1 Group Convolution (using CNHW) Bwd-Data
+// dx = CNHW2NCHW(transpose(w) * NCHW2CNHW(dy))
+GemmDescriptor CreateGemmDescriptorGroupConvCNHWBwdData(const TensorDescriptor& wDesc,
+                                                        const TensorDescriptor& dyDesc,
+                                                        const TensorDescriptor& dxDesc,
+                                                        int groupCount = 1);
+
+} // namespace miopen
+
+#endif // GUARD_MIOPEN_GEMM_V2_HPP_
diff --git a/src/include/miopen/handle.hpp b/src/include/miopen/handle.hpp
index 1fd8816..036c34f 100644
--- a/src/include/miopen/handle.hpp
+++ b/src/include/miopen/handle.hpp
@@ -36,10 +36,19 @@
 #include <miopen/allocator.hpp>
 #include <vector>
 
+#if MIOPEN_USE_ROCBLAS
+#include <miopen/manage_ptr.hpp>
+#include <rocblas.h>
+#endif
+
 namespace miopen {
 
 struct HandleImpl;
 
+#if MIOPEN_USE_ROCBLAS
+using rocblas_handle_ptr = MIOPEN_MANAGE_PTR(rocblas_handle, rocblas_destroy_handle);
+#endif
+
 struct Handle : miopenHandle
 {
 
@@ -117,6 +126,11 @@ struct Handle : miopenHandle
         return result;
     }
 
+#if MIOPEN_USE_ROCBLAS
+    rocblas_handle_ptr CreateRocblasHandle() const;
+    rocblas_handle_ptr rhandle;
+#endif
+
     std::unique_ptr<HandleImpl> impl;
 };
 } // namespace miopen
diff --git a/src/include/miopen/kernel_cache.hpp b/src/include/miopen/kernel_cache.hpp
index e8a6bd4..a469d36 100644
--- a/src/include/miopen/kernel_cache.hpp
+++ b/src/include/miopen/kernel_cache.hpp
@@ -83,6 +83,9 @@ class KernelCache
 
     Kernel GetKernel(const std::string& algorithm, const std::string& network_config);
 
+    const std::vector<Kernel>& GetKernels(const std::string& algorithm,
+                                          const std::string& network_config);
+
     KernelCache();
 
     private:
diff --git a/src/include/miopen/perf_field.hpp b/src/include/miopen/perf_field.hpp
new file mode 100644
index 0000000..662802f
--- /dev/null
+++ b/src/include/miopen/perf_field.hpp
@@ -0,0 +1,77 @@
+/*******************************************************************************
+ *
+ * MIT License
+ *
+ * Copyright (c) 2017 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *******************************************************************************/
+#ifndef GUARD_MIOPEN_PERF_FIELD_HPP_
+#define GUARD_MIOPEN_PERF_FIELD_HPP_
+
+#include <miopen/serializable.hpp>
+
+#include <string>
+
+namespace miopen {
+
+struct PerfField
+{
+    std::string name;
+    float time;
+    std::size_t workspace;
+
+    bool operator<(const PerfField& p) const { return (time < p.time); }
+};
+
+struct FindDbData : solver::Serializable<FindDbData>
+{
+    static constexpr const char* GetUnusedKCacheKey() { return "<unused>"; }
+
+    std::string solver_id;
+    float time;
+    std::size_t workspace;
+    /// kchache_key may have a special value <unused>. It means that the particular solver doesn't
+    /// use kernel cache and doesn't require a validation of built kernel existance.
+    std::string kchache_key;
+
+    FindDbData() : solver_id("<unknown>"), time(-1), workspace(-1), kchache_key("<unknown>") {}
+
+    FindDbData(const std::string& solver_id_,
+               float time_,
+               std::size_t workspace_,
+               const std::string& kchache_key_)
+        : solver_id(solver_id_), time(time_), workspace(workspace_), kchache_key(kchache_key_)
+    {
+    }
+
+    template <class Self, class F>
+    static void Visit(Self&& self, F f)
+    {
+        f(self.solver_id, "solver_id");
+        f(self.time, "time");
+        f(self.workspace, "workspace");
+        f(self.kchache_key, "kchache_key");
+    }
+};
+
+} // namespace miopen
+
+#endif // GUARD_MIOPEN_PERF_FIELD_HPP_
diff --git a/src/include/miopen/tensor.hpp b/src/include/miopen/tensor.hpp
index 2489f50..bcaca53 100644
--- a/src/include/miopen/tensor.hpp
+++ b/src/include/miopen/tensor.hpp
@@ -51,6 +51,26 @@ auto tien(T&& x) -> decltype(tie_impl(std::forward<T>(x), typename detail::gens<
     return tie_impl(std::forward<T>(x), typename detail::gens<N>::type{});
 }
 
+template <typename F, std::size_t... Ns>
+auto create_tuple_impl(F f, detail::seq<Ns...>) -> decltype(std::make_tuple(std::forward<decltype(f(Ns))>(f(Ns))...))
+{
+        return std::make_tuple(std::forward<decltype(f(Ns))>(f(Ns))...);
+}
+
+template <std::size_t N, typename F>
+auto create_tuple(F f) -> decltype(create_tuple_impl(f, typename detail::gens<N>::type{}))
+{
+        return create_tuple_impl(f, typename detail::gens<N>::type{});
+}
+
+inline std::size_t GetTypeSize(miopenDataType_t d)
+{
+    if(d == miopenFloat)
+        return 4;
+    else
+        return 1;
+}
+
 struct TensorDescriptor : miopenTensorDescriptor
 {
     TensorDescriptor();
@@ -61,8 +81,14 @@ struct TensorDescriptor : miopenTensorDescriptor
     TensorDescriptor(miopenDataType_t t, const int* plens, int size);
     TensorDescriptor(miopenDataType_t t, const int* plens, const int* pstrides, int size);
 
+    TensorDescriptor(miopenDataType_t t,
+                     std::vector<std::size_t> lens_in,
+                     std::vector<std::size_t> strides_in);
+
     void CalculateStrides();
 
+    bool IsPacked() const;
+
     const std::vector<std::size_t>& GetLengths() const;
     const std::vector<std::size_t>& GetStrides() const;
     int GetSize() const;
@@ -96,6 +122,8 @@ struct TensorDescriptor : miopenTensorDescriptor
     std::vector<std::size_t> lens;
     std::vector<std::size_t> strides;
 
+    bool packed;
+
     miopenDataType_t type = miopenFloat;
 };
 
diff --git a/src/include/miopen/tensor_ops.hpp b/src/include/miopen/tensor_ops.hpp
index 675acc3..b28ba32 100644
--- a/src/include/miopen/tensor_ops.hpp
+++ b/src/include/miopen/tensor_ops.hpp
@@ -28,13 +28,114 @@
 
 #include <miopen/common.hpp>
 #include <miopen/datatype.hpp>
+#include <miopen/functional.hpp>
 #include <miopen/handle.hpp>
 #include <miopen/miopen.h>
 #include <miopen/object.hpp>
 #include <vector>
+#include <boost/range/combine.hpp>
+#include <boost/range/adaptor/filtered.hpp>
 
 namespace miopen {
 
+struct f_length_is_not_1_t
+{
+    template <typename T>
+    bool operator()(T&& v)
+    {
+        return boost::get<0>(v) > 1;
+    }
+};
+
+template <typename... TDescriptors>
+std::tuple<TDescriptors...>
+GetConsistentFlattenedTensorDescriptors(const TDescriptors&... real_descriptor_pack)
+{
+    constexpr std::size_t NTensor = sizeof...(TDescriptors);
+    //std::integral_constant<std::size_t, NTensor> NTensorConstant;
+
+    std::array<const TensorDescriptor*, NTensor> real_descriptors{{(&real_descriptor_pack)...}};
+
+#ifndef NDEBUG
+    // sanity check: all input TensorDescriptors should have the same GetLengths()
+    const auto& real_desc_0_lens = real_descriptors[0]->GetLengths();
+
+    for(std::size_t itensor = 1; itensor < NTensor; ++itensor)
+    {
+        if(real_desc_0_lens != real_descriptors[itensor]->GetLengths())
+            MIOPEN_THROW(miopenStatusBadParm, "Lengths of Tensors are different.");
+    }
+#endif
+    // if tensors are all packed
+    bool is_all_packed = true;
+    for(std::size_t itensor = 0; itensor < NTensor; ++itensor)
+        is_all_packed &= real_descriptors[itensor]->IsPacked();
+
+    if(is_all_packed)
+    {
+        std::size_t sz = real_descriptors[0]->GetElementSize();
+        return create_tuple<NTensor>([&](std::size_t itensor) {
+            return TensorDescriptor{real_descriptors[itensor]->GetType(), {sz}, {1}};
+        });
+    }
+// start flattening tensors
+    std::array<std::vector<std::size_t>, NTensor> array_of_flat_lengths;
+    std::array<std::vector<std::size_t>, NTensor> array_of_flat_strides;
+
+    auto non1_length_strides =
+        boost::combine(real_descriptors[0]->GetLengths(), real_descriptor_pack.GetStrides()...) |
+        boost::adaptors::filtered(f_length_is_not_1_t());
+    auto i                  = non1_length_strides.begin();
+    std::size_t flat_len    = boost::get<0>(*i);
+    auto i_previous         = i++;
+    // the 0-th dimension full-length doesn't matter
+    for(; i != non1_length_strides.end(); ++i)
+    {
+        std::size_t len = boost::get<0>(*i);
+        bool is_all_full_length = true;
+        std::size_t stride          = boost::get<1>(*i);
+        std::size_t previous_stride = boost::get<1>(*i_previous);
+        std::size_t full_len        = previous_stride / stride;
+        is_all_full_length &= (len == full_len);
+        stride          = boost::get<2>(*i);
+        previous_stride = boost::get<2>(*i_previous);
+        full_len        = previous_stride / stride;
+        is_all_full_length &= (len == full_len);
+        if(is_all_full_length)
+        {
+            flat_len *= len;
+        }
+        else
+        {
+            array_of_flat_lengths[0].push_back(flat_len);
+            previous_stride = boost::get<1>(*i_previous);
+            array_of_flat_strides[0].push_back(previous_stride);
+            previous_stride = boost::get<2>(*i_previous);
+            array_of_flat_strides[1].push_back(previous_stride);
+            flat_len = len;
+
+        }
+       i_previous = i;
+    }
+
+    // lengths of all flattend tensors are the same
+    array_of_flat_lengths[0].push_back(flat_len);
+    std::size_t previous_strides = boost::get<1>(*i_previous);
+        array_of_flat_strides[0].push_back(previous_strides);
+    previous_strides = boost::get<2>(*i_previous);
+        array_of_flat_strides[1].push_back(previous_strides);
+    for(std::size_t itensor            = 1; itensor < NTensor; ++itensor)
+        array_of_flat_lengths[itensor] = array_of_flat_lengths[0];
+
+    return create_tuple<NTensor>([&](std::size_t itensor) {
+        return TensorDescriptor{real_descriptors[itensor]->GetType(),
+                                std::move(array_of_flat_lengths[itensor]),
+                                std::move(array_of_flat_strides[itensor])};
+     });
+}
+
+TensorDescriptor GetFlattenedTensorDescriptor(const TensorDescriptor& desc);
+
 void ScaleTensor(Handle& handle, const TensorDescriptor& yDesc, Data_t y, const void* alpha);
 
 void SetTensor(Handle& handle, const TensorDescriptor& yDesc, Data_t y, const void* alpha);
diff --git a/src/kernel_cache.cpp b/src/kernel_cache.cpp
index 10e60d6..70ec895 100644
--- a/src/kernel_cache.cpp
+++ b/src/kernel_cache.cpp
@@ -117,6 +117,24 @@ Kernel KernelCache::GetKernel(const std::string& algorithm, const std::string& n
     }
 }
 
+const std::vector<Kernel>& KernelCache::GetKernels(const std::string& algorithm,
+                                                   const std::string& network_config)
+{
+    std::pair<std::string, std::string> key = std::make_pair(algorithm, network_config);
+
+    auto it = kernel_map.find(key);
+    if(it != kernel_map.end())
+    {
+        //MIOPEN_LOG_I2(it->second.size() << " kernels for key: " << key.first << " \"" << key.second
+          //                              << '\"');
+        //return it->second;
+    }
+
+    static const std::vector<Kernel> empty{};
+    MIOPEN_LOG_I2("0 kernels for key: " << key.first << " \"" << key.second << '\"');
+    return empty;
+}
+
 Kernel KernelCache::GetKernel(Handle& h,
                               const std::string& algorithm,
                               const std::string& network_config,
diff --git a/src/kernels/MIOpenSubTensorOpWithScalarKernel.cl b/src/kernels/MIOpenSubTensorOpWithScalarKernel.cl
new file mode 100644
index 0000000..670135f
--- /dev/null
+++ b/src/kernels/MIOpenSubTensorOpWithScalarKernel.cl
@@ -0,0 +1,289 @@
+/*******************************************************************************
+ *
+ * MIT License
+ *
+ * Copyright (c) 2017 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *******************************************************************************/
+
+#define PPCAT_NX(A, B) A##B
+#define PPCAT(A, B) PPCAT_NX(A, B)
+#define TWO 2
+#define FOUR 4
+#define EIGHT 8
+
+#ifndef MIOPEN_USE_FP32
+#define MIOPEN_USE_FP32 0
+#endif
+
+#ifndef MIOPEN_USE_FP16
+#define MIOPEN_USE_FP16 0
+#endif
+
+#ifndef MIOPEN_USE_INTE8
+#define MIOPEN_USE_INTE8 0
+#endif
+
+#if MIOPEN_USE_INTE8 == 1
+#define _FLOAT char
+#ifndef FLT_MAX
+#define MAX_VAL 127 /* max value */
+#else
+#define MAX_VAL FLT_MAX
+#endif
+#endif
+#if MIOPEN_USE_FP16 == 1
+#pragma OPENCL EXTENSION cl_khr_fp16 : enable
+#define _FLOAT half
+#ifndef HALF_MAX
+#define MAX_VAL 65504 /* max value */
+#else
+#define MAX_VAL HALF_MAX
+#endif
+#endif
+#if MIOPEN_USE_FP32 == 1
+#define _FLOAT float
+#ifndef FLT_MAX
+#define MAX_VAL 3.402823466e+38F /* max value */
+#else
+#define MAX_VAL FLT_MAX
+#endif
+#endif
+
+#define _FLOAT2 PPCAT(_FLOAT, TWO)
+#define _FLOAT4 PPCAT(_FLOAT, FOUR)
+#define _FLOAT8 PPCAT(_FLOAT, EIGHT)
+#define _AS_FLOAT PPCAT(as_, _FLOAT)
+
+#ifndef WORK_LENGTH_0
+#define WORK_LENGTH_0 1
+#endif
+
+#ifndef WORK_LENGTH_1
+#define WORK_LENGTH_1 1
+#endif
+
+#ifndef WORK_LENGTH_2
+#define WORK_LENGTH_2 1
+#endif
+
+#ifndef WORK_LENGTH_3
+#define WORK_LENGTH_3 1
+#endif
+
+#ifndef WORK_LENGTH_4
+#define WORK_LENGTH_4 1
+#endif
+
+#define WORK_STRIDE_4 1
+#define WORK_STRIDE_3 (WORK_LENGTH_4 * WORK_STRIDE_4)
+#define WORK_STRIDE_2 (WORK_LENGTH_3 * WORK_STRIDE_3)
+#define WORK_STRIDE_1 (WORK_LENGTH_2 * WORK_STRIDE_2)
+#define WORK_STRIDE_0 (WORK_LENGTH_1 * WORK_STRIDE_1)
+
+#ifndef SUBTENSOR_OP_WITH_SCALAR
+#define SUBTENSOR_OP_WITH_SCALAR BREAK_COMPILE_INTENTIONALLY
+#endif
+
+#define SUBTENSOR_OP_WITH_SCALAR_SET(t, a) (t = a)
+#define SUBTENSOR_OP_WITH_SCALAR_MULTIPLY(t, a) (t *= a)
+
+__kernel void SubTensorOpWithScalar1d(global _FLOAT* __restrict dst,
+                                      const _FLOAT alpha,
+                                      const int offset,
+                                      const int stride0,
+                                      const int len0)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    for(uint did0 = did0_begin; did0 < len0; did0 += WORK_LENGTH_0)
+    {
+        const uint i = stride0 * did0;
+
+        SUBTENSOR_OP_WITH_SCALAR(dst[i + offset], alpha);
+    }
+}
+
+__kernel void SubTensorOpWithScalar2d(global _FLOAT* __restrict dst,
+                                      const _FLOAT alpha,
+                                      const int offset,
+                                      const int stride0,
+                                      const int stride1,
+                                      const int len0,
+                                      const int len1)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    for(uint did0 = did0_begin; did0 < len0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < len1; did1 += WORK_LENGTH_1)
+        {
+            const uint i = stride0 * did0 + stride1 * did1;
+
+            SUBTENSOR_OP_WITH_SCALAR(dst[i + offset], alpha);
+        }
+    }
+}
+
+__kernel void SubTensorOpWithScalar3d(global _FLOAT* __restrict dst,
+                                      const _FLOAT alpha,
+                                      const int offset,
+                                      const int stride0,
+                                      const int stride1,
+                                      const int stride2,
+                                      const int len0,
+                                      const int len1,
+                                      const int len2)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    for(uint did0 = did0_begin; did0 < len0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < len1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < len2; did2 += WORK_LENGTH_2)
+            {
+                const uint i = stride0 * did0 + stride1 * did1 + stride2 * did2;
+
+                SUBTENSOR_OP_WITH_SCALAR(dst[i + offset], alpha);
+            }
+        }
+    }
+}
+
+__kernel void SubTensorOpWithScalar4d(global _FLOAT* __restrict dst,
+                                      const _FLOAT alpha,
+                                      const int offset,
+                                      const int stride0,
+                                      const int stride1,
+                                      const int stride2,
+                                      const int stride3,
+                                      const int len0,
+                                      const int len1,
+                                      const int len2,
+                                      const int len3)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    itmp -= did2_begin * WORK_STRIDE_2;
+
+    const uint did3_begin = itmp / WORK_STRIDE_3;
+
+    for(uint did0 = did0_begin; did0 < len0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < len1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < len2; did2 += WORK_LENGTH_2)
+            {
+                for(uint did3 = did3_begin; did3 < len3; did3 += WORK_LENGTH_3)
+                {
+                    const uint i =
+                        stride0 * did0 + stride1 * did1 + stride2 * did2 + stride3 * did3;
+
+                    SUBTENSOR_OP_WITH_SCALAR(dst[i + offset], alpha);
+                }
+            }
+        }
+    }
+}
+
+__kernel void SubTensorOpWithScalar5d(global _FLOAT* __restrict dst,
+                                      const _FLOAT alpha,
+                                      const int offset,
+                                      const int stride0,
+                                      const int stride1,
+                                      const int stride2,
+                                      const int stride3,
+                                      const int stride4,
+                                      const int len0,
+                                      const int len1,
+                                      const int len2,
+                                      const int len3,
+                                      const int len4)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    itmp -= did2_begin * WORK_STRIDE_2;
+
+    const uint did3_begin = itmp / WORK_STRIDE_3;
+
+    itmp -= did3_begin * WORK_STRIDE_3;
+
+    const uint did4_begin = itmp / WORK_STRIDE_4;
+
+    for(uint did0 = did0_begin; did0 < len0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < len1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < len2; did2 += WORK_LENGTH_2)
+            {
+                for(uint did3 = did3_begin; did3 < len3; did3 += WORK_LENGTH_3)
+                {
+                    for(uint did4 = did4_begin; did4 < len4; did4 += WORK_LENGTH_4)
+                    {
+                        const uint i = stride0 * did0 + stride1 * did1 + stride2 * did2 +
+                                       stride3 * did3 + stride4 * did4;
+
+                        SUBTENSOR_OP_WITH_SCALAR(dst[i + offset], alpha);
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/src/kernels/MIOpenSubTensorOpWithSubTensorKernel.cl b/src/kernels/MIOpenSubTensorOpWithSubTensorKernel.cl
new file mode 100644
index 0000000..11dc80f
--- /dev/null
+++ b/src/kernels/MIOpenSubTensorOpWithSubTensorKernel.cl
@@ -0,0 +1,318 @@
+/*******************************************************************************
+ *
+ * MIT License
+ *
+ * Copyright (c) 2017 Advanced Micro Devices, Inc.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *******************************************************************************/
+
+#define PPCAT_NX(A, B) A##B
+#define PPCAT(A, B) PPCAT_NX(A, B)
+#define TWO 2
+#define FOUR 4
+#define EIGHT 8
+
+#ifndef MIOPEN_USE_FP32
+#define MIOPEN_USE_FP32 0
+#endif
+
+#ifndef MIOPEN_USE_FP16
+#define MIOPEN_USE_FP16 0
+#endif
+
+#ifndef MIOPEN_USE_INTE8
+#define MIOPEN_USE_INTE8 0
+#endif
+
+#if MIOPEN_USE_INTE8 == 1
+#define _FLOAT char
+#ifndef FLT_MAX
+#define MAX_VAL 127 /* max value */
+#else
+#define MAX_VAL FLT_MAX
+#endif
+#endif
+#if MIOPEN_USE_FP16 == 1
+#pragma OPENCL EXTENSION cl_khr_fp16 : enable
+#define _FLOAT half
+#ifndef HALF_MAX
+#define MAX_VAL 65504 /* max value */
+#else
+#define MAX_VAL HALF_MAX
+#endif
+#endif
+#if MIOPEN_USE_FP32 == 1
+#define _FLOAT float
+#ifndef FLT_MAX
+#define MAX_VAL 3.402823466e+38F /* max value */
+#else
+#define MAX_VAL FLT_MAX
+#endif
+#endif
+
+#define _FLOAT2 PPCAT(_FLOAT, TWO)
+#define _FLOAT4 PPCAT(_FLOAT, FOUR)
+#define _FLOAT8 PPCAT(_FLOAT, EIGHT)
+#define _AS_FLOAT PPCAT(as_, _FLOAT)
+
+#ifndef WORK_LENGTH_0
+#define WORK_LENGTH_0 1
+#endif
+
+#ifndef WORK_LENGTH_1
+#define WORK_LENGTH_1 1
+#endif
+
+#ifndef WORK_LENGTH_2
+#define WORK_LENGTH_2 1
+#endif
+
+#ifndef WORK_LENGTH_3
+#define WORK_LENGTH_3 1
+#endif
+
+#ifndef WORK_LENGTH_4
+#define WORK_LENGTH_4 1
+#endif
+
+#define WORK_STRIDE_4 1
+#define WORK_STRIDE_3 (WORK_LENGTH_4 * WORK_STRIDE_4)
+#define WORK_STRIDE_2 (WORK_LENGTH_3 * WORK_STRIDE_3)
+#define WORK_STRIDE_1 (WORK_LENGTH_2 * WORK_STRIDE_2)
+#define WORK_STRIDE_0 (WORK_LENGTH_1 * WORK_STRIDE_1)
+
+#ifndef SUBTENSOR_OP_WITH_SUBTENSOR
+#define SUBTENSOR_OP_WITH_SUBTENSOR BREAK_COMPILE_INTENTIONALLY
+#endif
+
+#define SUBTENSOR_OP_WITH_SUBTENSOR_COPY(dst, src) (dst = src)
+
+__kernel void SubTensorOpWithSubTensor1d(const global _FLOAT* __restrict src,
+                                         const int srcOffset,
+                                         const int srcStride0,
+                                         const int srcLen0,
+                                         global _FLOAT* __restrict dst,
+                                         const int dstOffset,
+                                         const int dstStride0)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    for(uint did0 = did0_begin; did0 < srcLen0; did0 += WORK_LENGTH_0)
+    {
+        const uint sindex = srcStride0 * did0;
+        const uint dindex = dstStride0 * did0;
+
+        SUBTENSOR_OP_WITH_SUBTENSOR(dst[dindex + dstOffset], src[sindex + srcOffset]);
+    }
+}
+
+__kernel void SubTensorOpWithSubTensor2d(const global _FLOAT* __restrict src,
+                                         const int srcOffset,
+                                         const int srcStride0,
+                                         const int srcStride1,
+                                         const int srcLen0,
+                                         const int srcLen1,
+                                         global _FLOAT* __restrict dst,
+                                         const int dstOffset,
+                                         const int dstStride0,
+                                         const int dstStride1)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    for(uint did0 = did0_begin; did0 < srcLen0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < srcLen1; did1 += WORK_LENGTH_1)
+        {
+            const uint sindex = srcStride0 * did0 + srcStride1 * did1;
+            const uint dindex = dstStride0 * did0 + dstStride1 * did1;
+
+            SUBTENSOR_OP_WITH_SUBTENSOR(dst[dindex + dstOffset], src[sindex + srcOffset]);
+        }
+    }
+}
+
+__kernel void SubTensorOpWithSubTensor3d(const global _FLOAT* __restrict src,
+                                         const int srcOffset,
+                                         const int srcStride0,
+                                         const int srcStride1,
+                                         const int srcStride2,
+                                         const int srcLen0,
+                                         const int srcLen1,
+                                         const int srcLen2,
+                                         global _FLOAT* __restrict dst,
+                                         const int dstOffset,
+                                         const int dstStride0,
+                                         const int dstStride1,
+                                         const int dstStride2)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    for(uint did0 = did0_begin; did0 < srcLen0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < srcLen1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < srcLen2; did2 += WORK_LENGTH_2)
+            {
+                const uint sindex = srcStride0 * did0 + srcStride1 * did1 + srcStride2 * did2;
+                const uint dindex = dstStride0 * did0 + dstStride1 * did1 + dstStride2 * did2;
+
+                SUBTENSOR_OP_WITH_SUBTENSOR(dst[dindex + dstOffset], src[sindex + srcOffset]);
+            }
+        }
+    }
+}
+
+__kernel void SubTensorOpWithSubTensor4d(const global _FLOAT* __restrict src,
+                                         const int srcOffset,
+                                         const int srcStride0,
+                                         const int srcStride1,
+                                         const int srcStride2,
+                                         const int srcStride3,
+                                         const int srcLen0,
+                                         const int srcLen1,
+                                         const int srcLen2,
+                                         const int srcLen3,
+                                         global _FLOAT* __restrict dst,
+                                         const int dstOffset,
+                                         const int dstStride0,
+                                         const int dstStride1,
+                                         const int dstStride2,
+                                         const int dstStride3)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    itmp -= did2_begin * WORK_STRIDE_2;
+
+    const uint did3_begin = itmp / WORK_STRIDE_3;
+
+    for(uint did0 = did0_begin; did0 < srcLen0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < srcLen1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < srcLen2; did2 += WORK_LENGTH_2)
+            {
+                for(uint did3 = did3_begin; did3 < srcLen3; did3 += WORK_LENGTH_3)
+                {
+                    const uint sindex = srcStride0 * did0 + srcStride1 * did1 + srcStride2 * did2 +
+                                        srcStride3 * did3;
+                    const uint dindex = dstStride0 * did0 + dstStride1 * did1 + dstStride2 * did2 +
+                                        dstStride3 * did3;
+
+                    SUBTENSOR_OP_WITH_SUBTENSOR(dst[dindex + dstOffset], src[sindex + srcOffset]);
+                }
+            }
+        }
+    }
+}
+
+__kernel void SubTensorOpWithSubTensor5d(const global _FLOAT* __restrict src,
+                                         const int srcOffset,
+                                         const int srcStride0,
+                                         const int srcStride1,
+                                         const int srcStride2,
+                                         const int srcStride3,
+                                         const int srcStride4,
+                                         const int srcLen0,
+                                         const int srcLen1,
+                                         const int srcLen2,
+                                         const int srcLen3,
+                                         const int srcLen4,
+                                         global _FLOAT* __restrict dst,
+                                         const int dstOffset,
+                                         const int dstStride0,
+                                         const int dstStride1,
+                                         const int dstStride2,
+                                         const int dstStride3,
+                                         const int dstStride4)
+{
+    uint itmp = get_global_id(0);
+
+    const uint did0_begin = itmp / WORK_STRIDE_0;
+
+    itmp -= did0_begin * WORK_STRIDE_0;
+
+    const uint did1_begin = itmp / WORK_STRIDE_1;
+
+    itmp -= did1_begin * WORK_STRIDE_1;
+
+    const uint did2_begin = itmp / WORK_STRIDE_2;
+
+    itmp -= did2_begin * WORK_STRIDE_2;
+
+    const uint did3_begin = itmp / WORK_STRIDE_3;
+
+    itmp -= did3_begin * WORK_STRIDE_3;
+
+    const uint did4_begin = itmp / WORK_STRIDE_4;
+
+    for(uint did0 = did0_begin; did0 < srcLen0; did0 += WORK_LENGTH_0)
+    {
+        for(uint did1 = did1_begin; did1 < srcLen1; did1 += WORK_LENGTH_1)
+        {
+            for(uint did2 = did2_begin; did2 < srcLen2; did2 += WORK_LENGTH_2)
+            {
+                for(uint did3 = did3_begin; did3 < srcLen3; did3 += WORK_LENGTH_3)
+                {
+                    for(uint did4 = did4_begin; did4 < srcLen4; did4 += WORK_LENGTH_4)
+                    {
+                        const uint sindex = srcStride0 * did0 + srcStride1 * did1 +
+                                            srcStride2 * did2 + srcStride3 * did3 +
+                                            srcStride4 * did4;
+                        const uint dindex = dstStride0 * did0 + dstStride1 * did1 +
+                                            dstStride2 * did2 + dstStride3 * did3 +
+                                            dstStride4 * did4;
+
+                        SUBTENSOR_OP_WITH_SUBTENSOR(dst[dindex + dstOffset],
+                                                    src[sindex + srcOffset]);
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/src/kernels/MIOpenTensorKernels.cl b/src/kernels/MIOpenTensorKernels.cl
index a9b878b..a5581d1 100644
--- a/src/kernels/MIOpenTensorKernels.cl
+++ b/src/kernels/MIOpenTensorKernels.cl
@@ -23,6 +23,30 @@
  * SOFTWARE.
  *
  *******************************************************************************/
+
+#if MIOPEN_USE_FP16 == 1
+#pragma OPENCL EXTENSION cl_khr_fp16 : enable
+#define _FLOAT half
+#ifndef HALF_MAX
+#define MAX_VAL 65504 /* max value */
+#else
+#define MAX_VAL HALF_MAX
+#endif
+#endif
+#if MIOPEN_USE_FP32 == 1
+#define _FLOAT float
+#ifndef FLT_MAX
+#define MAX_VAL 3.402823466e+38F /* max value */
+#else
+#define MAX_VAL FLT_MAX
+#endif
+#endif
+
+#if MIOPEN_USE_LDS == 1
+#define LDS_SIZE 256
+#define WARP_SIZE 64
+#endif
+
 /* Only works for NCHW
  * bitmap tracks which dims are the same between 'a' and 'c'.
  * Example: 0, 1, 1, 0 means that C and H dims are the same and the rest are ones
@@ -37,10 +61,6 @@
 #define MIOPEN_TENSOR_OP miopenMul
 #endif
 
-#ifndef MIOPEN_TENSOR_DIMS
-#define MIOPEN_TENSOR_DIMS 4
-#endif
-
 #define UNUSED __attribute__((__unused__))
 
 MIOPEN_TYPE miopenAdd(MIOPEN_TYPE a, MIOPEN_TYPE b) { return a + b; }
@@ -51,6 +71,8 @@ MIOPEN_TYPE miopenMax(MIOPEN_TYPE a, MIOPEN_TYPE b) { return ((a > b) ? a : b);
 
 MIOPEN_TYPE miopenMin(MIOPEN_TYPE a, MIOPEN_TYPE b) { return ((a < b) ? a : b); }
 
+#ifdef USE_FWD_BIAS
+
 __kernel void OpTensorFwdBias(global MIOPEN_TYPE* a,
                               global MIOPEN_TYPE* b,
 #if INCR_WG == 0
@@ -65,9 +87,9 @@ __kernel void OpTensorFwdBias(global MIOPEN_TYPE* a,
                               const int c_nstride,
                               const int c_cstride,
                               const int work_per_wg,
-                              const float alpha0,
-                              const float alpha1,
-                              const float beta,
+                              const MIOPEN_TYPE alpha0,
+                              const MIOPEN_TYPE alpha1,
+                              const MIOPEN_TYPE beta,
                               const long Aoffset,
                               const long Boffset,
                               const long Coffset,
@@ -78,12 +100,12 @@ __kernel void OpTensorFwdBias(global MIOPEN_TYPE* a,
     global MIOPEN_TYPE* c_off = c + Coffset;
 
     int gid = get_group_id(0);
-    int lid = get_local_id(0);
 
     // num_wg: the number of workgroups should be launched
     // MAX_NUM_WG: the maximum number of workgroups actually launched
     for(; gid < num_wg; gid += MAX_NUM_WG)
     {
+        int lid = get_local_id(0);
 
 #if INCR_WG == 1
         int o_n             = gid / b_c;
@@ -116,6 +138,10 @@ __kernel void OpTensorFwdBias(global MIOPEN_TYPE* a,
     }
 }
 
+#endif
+
+#ifdef USE_FWD_BIAS_GENERIC
+
 __kernel void OpTensorFwdBiasGeneric(global MIOPEN_TYPE* a,
                                      const int a_nstride,
                                      const int a_cstride,
@@ -135,9 +161,9 @@ __kernel void OpTensorFwdBiasGeneric(global MIOPEN_TYPE* a,
                                      const int c_nstride,
                                      const int c_cstride,
                                      const int c_hstride,
-                                     const float alpha0,
-                                     const float alpha1,
-                                     const float beta,
+                                     const MIOPEN_TYPE alpha0,
+                                     const MIOPEN_TYPE alpha1,
+                                     const MIOPEN_TYPE beta,
                                      const int work_per_wg,
                                      const long Aoffset,
                                      const long Boffset,
@@ -197,6 +223,8 @@ __kernel void OpTensorFwdBiasGeneric(global MIOPEN_TYPE* a,
     }
 }
 
+#endif // USE_FWD_BIAS_GENERIC
+
 // DLOWELL : cutting out this section
 #if(FIRST_NOT_ONE < 4 && MIOPEN_TENSOR_DIMS == 4)
 
@@ -224,9 +252,9 @@ __kernel void OpTensorLeadingOnes(global MIOPEN_TYPE* a,
                                   UNUSED
 #endif
                                   const int work_per_wg,
-                                  const float alpha0,
-                                  const float alpha1,
-                                  const float beta,
+                                  const MIOPEN_TYPE alpha0,
+                                  const MIOPEN_TYPE alpha1,
+                                  const MIOPEN_TYPE beta,
                                   const long Aoffset,
                                   const long Boffset,
                                   const long Coffset,
@@ -323,7 +351,7 @@ __kernel void OpTensorLeadingOnes(global MIOPEN_TYPE* a,
 #endif
 
 // DLOWELL : cutting out this section
-#if(FIRST_NOT_ONE < 4 && MIOPEN_TENSOR_DIMS == 4)
+#ifdef USE_LEADING_ONES_GENERIC
 
 __kernel void OpTensorLeadingOnesGeneric(global MIOPEN_TYPE* a,
                                          const int a_nstride,
@@ -352,9 +380,9 @@ __kernel void OpTensorLeadingOnesGeneric(global MIOPEN_TYPE* a,
                                          const int c_nstride,
                                          const int c_cstride,
                                          const int c_hstride,
-                                         const float alpha0,
-                                         const float alpha1,
-                                         const float beta,
+                                         const MIOPEN_TYPE alpha0,
+                                         const MIOPEN_TYPE alpha1,
+                                         const MIOPEN_TYPE beta,
 #if FIRST_NOT_ONE == 3
                                          UNUSED
 #endif
@@ -471,6 +499,8 @@ __kernel void OpTensorLeadingOnesGeneric(global MIOPEN_TYPE* a,
 
 #endif
 
+#ifdef USE_4D_TENSOR_GENERIC
+
 __kernel void Op4dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int a_nstride,
                                 const int a_cstride,
@@ -489,9 +519,9 @@ __kernel void Op4dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int c_nstride,
                                 const int c_cstride,
                                 const int c_hstride,
-                                const float alpha0,
-                                const float alpha1,
-                                const float beta,
+                                const MIOPEN_TYPE alpha0,
+                                const MIOPEN_TYPE alpha1,
+                                const MIOPEN_TYPE beta,
                                 const unsigned int bitmap,
                                 const int work_per_wg,
                                 const long Aoffset,
@@ -542,6 +572,10 @@ __kernel void Op4dTensorGeneric(global MIOPEN_TYPE* a,
     }
 }
 
+#endif
+
+#ifdef USE_5D_TENSOR_GENERIC
+
 // NCDHW
 // (samples, color_depth, frames, width, height )
 __kernel void Op5dTensorGeneric(global MIOPEN_TYPE* a,
@@ -567,9 +601,9 @@ __kernel void Op5dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int c_cstride,
                                 const int c_dstride,
                                 const int c_hstride,
-                                const float alpha0,
-                                const float alpha1,
-                                const float beta,
+                                const MIOPEN_TYPE alpha0,
+                                const MIOPEN_TYPE alpha1,
+                                const MIOPEN_TYPE beta,
                                 const unsigned int bitmap,
                                 const int work_per_wg,
                                 const long Aoffset,
@@ -627,6 +661,10 @@ __kernel void Op5dTensorGeneric(global MIOPEN_TYPE* a,
     }
 }
 
+#endif
+
+#ifdef USE_3D_TENSOR_GENERIC
+
 // NCH
 __kernel void Op3dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int a_nstride,
@@ -641,9 +679,9 @@ __kernel void Op3dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int c_h,
                                 const int c_nstride,
                                 const int c_cstride,
-                                const float alpha0,
-                                const float alpha1,
-                                const float beta,
+                                const MIOPEN_TYPE alpha0,
+                                const MIOPEN_TYPE alpha1,
+                                const MIOPEN_TYPE beta,
                                 const unsigned int bitmap,
                                 const int work_per_wg,
                                 const long Aoffset,
@@ -691,6 +729,73 @@ __kernel void Op3dTensorGeneric(global MIOPEN_TYPE* a,
     }
 }
 
+#endif
+
+#ifdef USE_2D_TENSOR_LITE
+__kernel void Op2dTensorLite(const global MIOPEN_TYPE* a,
+                             const int a_nstride,
+                             const global MIOPEN_TYPE* b,
+#ifdef BIAS
+                             UNUSED
+#endif
+                             const int b_nstride,
+                             global MIOPEN_TYPE* c,
+                             const int c_nstride,
+                             const MIOPEN_TYPE alpha0,
+                             const MIOPEN_TYPE alpha1,
+#ifndef BETA
+                             UNUSED
+#endif
+                             const MIOPEN_TYPE beta,
+                             const long Aoffset,
+                             const long Boffset,
+                             const long Coffset,
+                             const int num_wg)
+{
+    int gid0 = get_global_id(0);
+    int gid1 = get_global_id(1);
+
+    MIOPEN_TYPE a_dat[RD_BLCK];
+    MIOPEN_TYPE b_dat[RD_BLCK];
+    MIOPEN_TYPE c_dat[RD_BLCK];
+
+#ifdef BIAS
+    int b_index          = gid0 * RD_BLCK;
+    *((READ_TYPE*)b_dat) = *((const global READ_TYPE*)(b + Boffset + b_index));
+#endif
+
+    for(; gid1 < num_wg; gid1 += MAX_NUM_WG)
+    {
+        int a_index = gid1 * a_nstride + gid0 * RD_BLCK;
+        int c_index = gid1 * c_nstride + gid0 * RD_BLCK;
+
+        *((READ_TYPE*)a_dat) = *((const global READ_TYPE*)(a + Aoffset + a_index));
+#ifdef BETA
+        *((READ_TYPE*)c_dat) = *((const global READ_TYPE*)(c + Coffset + c_index));
+#endif
+
+#ifndef BIAS
+        int b_index          = gid1 * b_nstride + gid0 * RD_BLCK;
+        *((READ_TYPE*)b_dat) = *((const global READ_TYPE*)(b + Boffset + b_index));
+#endif
+
+        for(int i = 0; i < RD_BLCK; ++i)
+        {
+            c_dat[i] = MIOPEN_TENSOR_OP(a_dat[i] * alpha0, b_dat[i] * alpha1)
+#ifdef BETA
+                       + beta * c_dat[i]
+#endif
+                ;
+        }
+
+        *((global READ_TYPE*)(c + Coffset + c_index)) = *((READ_TYPE*)c_dat);
+    }
+}
+
+#endif
+
+#ifdef USE_2D_TENSOR_GENERIC
+
 // NC
 __kernel void Op2dTensorGeneric(global MIOPEN_TYPE* a,
                                 const int a_nstride,
@@ -700,9 +805,9 @@ __kernel void Op2dTensorGeneric(global MIOPEN_TYPE* a,
                                 global MIOPEN_TYPE* c,
                                 const int c_c,
                                 const int c_nstride,
-                                const float alpha0,
-                                const float alpha1,
-                                const float beta,
+                                const MIOPEN_TYPE alpha0,
+                                const MIOPEN_TYPE alpha1,
+                                const MIOPEN_TYPE beta,
                                 const unsigned int bitmap,
                                 const int work_per_wg,
                                 const long Aoffset,
@@ -743,15 +848,18 @@ __kernel void Op2dTensorGeneric(global MIOPEN_TYPE* a,
     }
 }
 
+#endif
+
+#ifdef USE_1D_TENSOR_GENERIC
 // N
 __kernel void Op1dTensorGeneric(global MIOPEN_TYPE* a,
                                 global MIOPEN_TYPE* b,
                                 const int b_n,
                                 global MIOPEN_TYPE* c,
                                 const int c_n,
-                                const float alpha0,
-                                const float alpha1,
-                                const float beta,
+                                const MIOPEN_TYPE alpha0,
+                                const MIOPEN_TYPE alpha1,
+                                const MIOPEN_TYPE beta,
                                 const unsigned int bitmap,
                                 const int work_per_wg,
                                 const long Aoffset,
@@ -781,3 +889,57 @@ __kernel void Op1dTensorGeneric(global MIOPEN_TYPE* a,
         }
     }
 }
+
+#endif
+
+#ifdef USE_4D_TENSOR_LITE
+// N - batch size
+// C - # of maps
+// H - map height
+// W - map width
+// TENS_LEN = (N*C*H*W);
+// RD_BLCK = (TENS_LEN%4==0) ? 4 : (TENS_LEN%3==0)? 3 : (TENS_LEN%2==0)? 2 : 1;
+// READ_TYPE = (RD_BLCK==4) ? "float4" : (RD_BLCK == 3) ? "float3" : (RD_BLC==2) ? "float2" :
+// "float";
+// local size = (256, 1, 1)
+// global size = ((TENS_LEN/RD_BLCK), 1, 1)
+__kernel void Op4dTensorLite(const global MIOPEN_TYPE* a,
+                             const global MIOPEN_TYPE* b,
+                             global MIOPEN_TYPE* c,
+                             const MIOPEN_TYPE alpha0,
+                             const MIOPEN_TYPE alpha1,
+#ifndef BETA
+                             UNUSED
+#endif
+                             const MIOPEN_TYPE beta,
+                             const long Aoffset,
+                             const long Boffset,
+                             const long Coffset)
+{
+    int gid0 = get_global_id(0);
+
+    int index = gid0 * RD_BLCK;
+
+    MIOPEN_TYPE a_dat[RD_BLCK];
+    MIOPEN_TYPE b_dat[RD_BLCK];
+    MIOPEN_TYPE c_dat[RD_BLCK];
+
+    *((READ_TYPE*)a_dat) = *((const global READ_TYPE*)(a + index + Aoffset));
+    *((READ_TYPE*)b_dat) = *((const global READ_TYPE*)(b + index + Boffset));
+#ifdef BETA
+    *((READ_TYPE*)c_dat) = *((const global READ_TYPE*)(c + index + Coffset));
+#endif
+
+    for(int i = 0; i < RD_BLCK; ++i)
+    {
+        c_dat[i] = MIOPEN_TENSOR_OP(a_dat[i] * alpha0, b_dat[i] * alpha1)
+#ifdef BETA
+                   + beta * c_dat[i]
+#endif
+            ;
+    }
+
+    *((global READ_TYPE*)(c + index + Coffset)) = *((READ_TYPE*)c_dat);
+}
+
+#endif
diff --git a/src/kernels/conv3x3.s b/src/kernels/conv3x3.s
index b00dfb9..260dd79 100644
--- a/src/kernels/conv3x3.s
+++ b/src/kernels/conv3x3.s
@@ -25,7 +25,8 @@
  *******************************************************************************/
 
 .hsa_code_object_version 2,1
-.hsa_code_object_isa 8, 0, 3, "AMD", "AMDGPU"
+//.hsa_code_object_isa 8, 0, 3, "AMD", "AMDGPU"
+.hsa_code_object_isa 8, 0, 1, "AMD", "AMDGPU"
 
 .text
 .globl gcnAsmConv3x3U
diff --git a/src/ocl/gcn_asm_utils.cpp b/src/ocl/gcn_asm_utils.cpp
index f8bc8f6..ecdae34 100644
--- a/src/ocl/gcn_asm_utils.cpp
+++ b/src/ocl/gcn_asm_utils.cpp
@@ -136,6 +136,11 @@ std::string GetGcnAssemblerPath()
 bool ValidateGcnAssemblerImpl()
 {
 #ifdef __linux__
+  // ** TEST
+  // clang doesn't properly detect that we have the assembler installed,
+  // but we do, so just return true
+  return true;
+  /*
     const auto path = GetGcnAssemblerPath();
     if(path.empty())
     {
@@ -163,10 +168,14 @@ bool ValidateGcnAssemblerImpl()
             std::getline(clang_stdout, clang_result_line);
             if(clang_result_line.find("Target: ") != std::string::npos)
             {
+                bool foundAMDGcn = clang_result_line.find("amdgcn") != std::string::npos;
+                std::cout << "Found amdgcn in clang version output?: "
+                          << foundAMDGcn << std::endl; // ** TEMP: DEBUG ONLY
                 return clang_result_line.find("amdgcn") != std::string::npos;
             }
         }
     }
+  */
 #endif // __linux__
     return false;
 }
@@ -186,6 +195,7 @@ static int ExecuteGcnAssembler(const std::string& p, std::istream* in, std::ostr
     assert(!(redirect_stdin && redirect_stdout));
 
     const auto file_mode = redirect_stdout ? "r" : "w";
+    std::cout << "ExecuteGcnAssembler(): p: " << p << std::endl; // ** TEMP: DEBUG ONLY
     MIOPEN_MANAGE_PTR(FILE*, pclose) pipe{popen(p.c_str(), file_mode)};
 
     if(!pipe)
@@ -308,6 +318,7 @@ void AmdgcnAssemble(std::string& source, const std::string& params)
 
 static void AmdgcnAssemble4BugDetection(std::string& source, const std::string& params)
 {
+    std::cout << "Checking for bug detection\n"; // ** TEMP: DEBUG ONLY
 #ifdef __linux__
     std::stringstream clang_stdout_unused;
     const auto clang_path = GetGcnAssemblerPath();
@@ -332,7 +343,8 @@ static bool GcnAssemblerHasBug34765Impl()
     auto src = p.string();
     try
     {
-        AmdgcnAssemble4BugDetection(src, "-mcpu=gfx900");
+//        AmdgcnAssemble4BugDetection(src, "-mcpu=gfx900");
+        AmdgcnAssemble4BugDetection(src, "-mcpu=gfx801");
         return false;
     }
     catch(...)
@@ -344,7 +356,12 @@ static bool GcnAssemblerHasBug34765Impl()
 
 bool GcnAssemblerHasBug34765()
 {
+
+    /*
+      // ** TEST: We're using ROCm 1.6, so we have the bug
     const static bool b = GcnAssemblerHasBug34765Impl();
+    */
+    const static bool b = true;
     return b;
 }
 
diff --git a/src/ocl/rnnocl.cpp b/src/ocl/rnnocl.cpp
index 2332a18..36f2d58 100644
--- a/src/ocl/rnnocl.cpp
+++ b/src/ocl/rnnocl.cpp
@@ -33,12 +33,15 @@
 #include <numeric>
 #include <algorithm>
 
+#if MIOPEN_USE_ROCBLAS
+#include <miopen/gemm_v2.hpp>
+#endif
+
 #if MIOPEN_USE_MIOPENGEMM
 #include <miopen/gemm.hpp>
 #endif
 
 //#define MIO_RNN_OCL_DEBUG 1
-#define MIO_RNN_FINDSOL_TIMEOUT 0.003
 
 namespace miopen {
 
@@ -62,7 +65,6 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                         Data_t workSpace,
                                         size_t workSpaceSize) const
 {
-
     if(x == nullptr || w == nullptr || y == nullptr)
     {
         MIOPEN_THROW(miopenStatusBadParm);
@@ -156,6 +158,14 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
         x_stride(3, 1), y_size(3, 1), y_stride(3, 1), hx_size(3, 1), hx_stride(3, 1);
     miopen::TensorDescriptor sp_desc, w_desc, x_desc, y_desc, hx_desc;
 
+    sp_size[2] = workSpaceSize / GetTypeSize(wDesc.GetType());
+    sp_stride[0] = sp_size[2];
+    sp_stride[1] = sp_size[2];
+    sp_desc = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+    SetTensor(handle, sp_desc, workSpace, &beta);
+    // Update time
+    profileRNNkernels(handle, 0, ctime);
+
     sp_stride[0] = batch_n * hy_stride;
     sp_stride[1] = hy_stride;
     w_stride[0]  = wei_stride;
@@ -164,36 +174,50 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
     x_stride[1]  = in_stride;
     y_stride[0]  = batch_n * out_stride;
     y_stride[1]  = out_stride;
+    if(hy != nullptr || (rnnMode == miopenLSTM && cy != nullptr))
+    {
+        hx_size[2]   = hy_d * hy_n * hy_h;
+        hx_stride[0] = hx_size[2];
+        hx_stride[1] = hx_size[2];
+        hx_desc      = miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
+        if(hy != nullptr)
+        {
+            SetTensor(handle, hx_desc, hy, &beta);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+        if(rnnMode == miopenLSTM && cy != nullptr)
+        {
+            SetTensor(handle, hx_desc, cy, &beta);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+    }
     hx_stride[0] = in_n[0] * uni_stride;
     hx_stride[1] = uni_stride;
 
-#if MIOPEN_USE_MIOPENGEMM
-
+#if MIOPEN_USE_ROCBLAS
     int wei_shift, prelayer_shift;
-    int wei_len   = 0;
-    int wei_len_t = 0;
-    int hid_off   = 0;
+    int wei_len = 0;
+    int hid_off = 0;
 
     switch(rnnMode)
     {
     case miopenRNNRELU:
     case miopenRNNTANH:
         // printf("run rnn gpu inference \n");
-        wei_len   = hy_h;
-        wei_len_t = hy_h;
-        hid_off   = 0;
+        wei_len = hy_h;
+        hid_off = 0;
         break;
     case miopenLSTM:
         // printf("run lstm gpu inference \n");
-        wei_len   = hy_h * 4;
-        wei_len_t = hy_h * 4;
-        hid_off   = bi * hy_h * 5;
+        wei_len = hy_h * 4;
+        hid_off = bi * hy_h * 5;
         break;
     case miopenGRU:
         // printf("run gru gpu inference \n");
-        wei_len   = hy_h * 3;
-        wei_len_t = hy_h * 2;
-        hid_off   = bi * hy_h * 3;
+        wei_len = hy_h * 3;
+        hid_off = bi * hy_h * 3;
         break;
     }
 
@@ -213,9 +237,7 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
     {
         int hid_shift           = li * batch_n * hy_stride;
         int hx_shift            = li * hy_n * bi_stride;
-        int wei_shift_bias_temp = inputMode == miopenRNNskip
-                                      ? (wei_shift_bias + wei_stride + (li - 1) * 2 * wei_stride)
-                                      : (wei_shift_bias + li * 2 * wei_stride);
+        int wei_shift_bias_temp = wei_shift_bias + li * 2 * wei_stride;
 
         // from input
         if(li == 0)
@@ -234,35 +256,37 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                 {
                     CopyTensor(handle, x_desc, x, sp_desc, workSpace, 0, gi * hy_h);
                     // Update time
-                    profileRNNkernels(handle, (gi == 0) ? 0 : 1, ctime);
+                    profileRNNkernels(handle, 1, ctime);
                 }
             }
             else
             {
-
-                auto gg = ScanGemmGeometryRNN(handle,
-                                              x,
-                                              w,
-                                              workSpace,
-                                              batch_n,
-                                              wei_len * bi,
-                                              in_h,
-                                              1,
-                                              1,
-                                              false,
-                                              true,
-                                              false,
-                                              in_stride,
-                                              in_stride,
-                                              hy_stride,
-                                              false,
-                                              network_config,
-                                              MIO_RNN_FINDSOL_TIMEOUT);
-
-                gg.RunGemm(handle, x, w, workSpace, 0, 0, hid_shift);
-
+                miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                  false,
+                                                                  true,
+                                                                  batch_n,
+                                                                  wei_len * bi,
+                                                                  in_h,
+                                                                  in_stride,
+                                                                  in_stride,
+                                                                  hy_stride,
+                                                                  1, // batch count
+                                                                  0, // Stride A
+                                                                  0, // Stride B
+                                                                  0, // Stride C
+                                                                  1, // alpha
+                                                                  1, // beta
+                                                                  xDesc[0].GetType()};
+
+                miopenStatus_t gemm_status =
+                    CallGemm(handle, gemm_desc, x, 0, w, 0, workSpace, hid_shift, nullptr, false, GemmBackend_t::rocblas);
+
+                if(gemm_status != miopenStatusSuccess)
+                {
+                    MIOPEN_LOG_E("GEMM failed");
+                }
                 // Update time
-                profileRNNkernels(handle, 0, ctime);
+                profileRNNkernels(handle, 1, ctime);
             }
         }
         else
@@ -270,40 +294,44 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
             wei_shift = (in_h + hy_h) * wei_stride + (li - 1) * (bi * hy_h + hy_h) * wei_stride;
             prelayer_shift = (li - 1) * batch_n * hy_stride + hid_off;
 
-            auto gg = ScanGemmGeometryRNN(handle,
-                                          workSpace,
-                                          w,
-                                          workSpace,
-                                          batch_n,
-                                          wei_len * bi,
-                                          hy_h * bi,
-                                          1,
-                                          1,
-                                          false,
-                                          true,
-                                          false,
-                                          hy_stride,
-                                          bi_stride,
-                                          hy_stride,
-                                          false,
-                                          network_config,
-                                          MIO_RNN_FINDSOL_TIMEOUT);
-
-            gg.RunGemm(handle, workSpace, w, workSpace, prelayer_shift, wei_shift, hid_shift);
-
+            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                              false,
+                                                              true,
+                                                              batch_n,
+                                                              wei_len * bi,
+                                                              hy_h * bi,
+                                                              hy_stride,
+                                                              bi_stride,
+                                                              hy_stride,
+                                                              1, // batch count
+                                                              0, // Stride A
+                                                              0, // Stride B
+                                                              0, // Stride C
+                                                              1, // alpha
+                                                              1, // beta
+                                                              xDesc[0].GetType()};
+            miopenStatus_t gemm_status = CallGemm(handle,
+                                                  gemm_desc,
+                                                  workSpace,
+                                                  prelayer_shift,
+                                                  w,
+                                                  wei_shift,
+                                                  workSpace,
+                                                  hid_shift,
+                                                  nullptr,
+                                                  false,
+                                                  GemmBackend_t::rocblas);
+
+            if(gemm_status != miopenStatusSuccess)
+            {
+                MIOPEN_LOG_E("GEMM failed");
+            }
             // Update time
             profileRNNkernels(handle, 1, ctime);
         }
 
-        if(biasMode)
+        if(biasMode != 0u)
         {
-            int wn = rnnMode == miopenGRU ? 1 : 2;
-            if(inputMode == miopenRNNskip && li == 0)
-            {
-                wei_shift_bias_temp = wei_shift_bias;
-                wn                  = rnnMode == miopenGRU ? 0 : 1;
-            }
-
             alpha0 = 1;
             alpha1 = 1;
             beta_t = 0;
@@ -315,34 +343,78 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
             w_desc     = miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
             sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
 
-            for(int bs = 0; bs < wn; bs++)
+            OpTensor(handle,
+                     miopenTensorOpAdd,
+                     &alpha0,
+                     sp_desc,
+                     workSpace,
+                     &alpha1,
+                     w_desc,
+                     w,
+                     &beta_t,
+                     sp_desc,
+                     workSpace,
+                     hid_shift,
+                     wei_shift_bias_temp,
+                     hid_shift);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+
+        if(rnnMode == miopenGRU)
+        {
+            sp_size[1] = batch_n;
+            sp_size[2] = hy_h;
+            sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+            alpha0 = 0;
+            alpha1 = 0;
+            beta_t = 0;
+            for(int bs = 0; bs < bi; bs++)
             {
+                CopyTensor(handle,
+                           sp_desc,
+                           workSpace,
+                           sp_desc,
+                           workSpace,
+                           hid_shift + bs * wei_len + 2 * hy_h,
+                           hid_shift + hid_off + bs * hy_h);
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
+
                 OpTensor(handle,
                          miopenTensorOpAdd,
                          &alpha0,
                          sp_desc,
                          workSpace,
                          &alpha1,
-                         w_desc,
-                         w,
+                         sp_desc,
+                         workSpace,
                          &beta_t,
                          sp_desc,
                          workSpace,
-                         hid_shift,
-                         wei_shift_bias_temp + bs * wei_stride,
-                         hid_shift);
+                         hid_shift + bs * wei_len + 2 * hy_h,
+                         hid_shift + bs * wei_len + 2 * hy_h,
+                         hid_shift + bs * wei_len + 2 * hy_h);
                 // Update time
                 profileRNNkernels(handle, 1, ctime);
             }
+        }
+
+        if(biasMode != 0u)
+        {
+            wei_shift_bias_temp += wei_stride;
+
+            alpha0 = 1;
+            alpha1 = 1;
+            beta_t = 0;
 
-            if(rnnMode == miopenGRU)
+            if(hx != nullptr)
             {
-                for(int bs = 0; bs < bi; bs++)
+                for(int i = 1; i < bi; i++)
                 {
-                    w_size[2]  = 2 * hy_h;
-                    sp_size[2] = 2 * hy_h;
-                    w_desc =
-                        miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
+                    sp_size[1] = batch_n;
+                    sp_size[2] = wei_stride;
                     sp_desc =
                         miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
 
@@ -357,35 +429,95 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                              &beta_t,
                              sp_desc,
                              workSpace,
-                             hid_shift + bs * 3 * hy_h,
-                             wei_shift_bias_temp + wn * wei_stride + bs * 3 * hy_h,
-                             hid_shift + bs * 3 * hy_h);
+                             hid_shift,
+                             wei_shift_bias_temp + (i-1)*wei_stride,
+                             hid_shift);
                     // Update time
                     profileRNNkernels(handle, 1, ctime);
+                }
+            }
+            else
+            {
+                sp_size[1] = batch_n - in_n.at(0);
+                sp_size[2] = wei_len;
+                sp_desc =
+                    miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                w_size[1] = 1;
+                w_size[2] = wei_len;
+                w_desc = miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
 
-                    w_size[2]  = hy_h;
-                    sp_size[2] = hy_h;
-                    w_desc =
-                        miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
-                    sp_desc =
-                        miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                OpTensor(handle,
+                         miopenTensorOpAdd,
+                         &alpha0,
+                         sp_desc,
+                         workSpace,
+                         &alpha1,
+                         w_desc,
+                         w,
+                         &beta_t,
+                         sp_desc,
+                         workSpace,
+                         hid_shift + in_n.at(0) * hy_stride,
+                         wei_shift_bias_temp,
+                         hid_shift + in_n.at(0) * hy_stride);
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
 
-                    OpTensor(handle,
-                             miopenTensorOpAdd,
-                             &alpha0,
-                             sp_desc,
-                             workSpace,
-                             &alpha1,
-                             w_desc,
-                             w,
-                             &beta_t,
-                             sp_desc,
-                             workSpace,
-                             hid_shift + bi * 3 * hy_h + bs * hy_h,
-                             wei_shift_bias_temp + wn * wei_stride + 2 * hy_h + bs * 3 * hy_h,
-                             hid_shift + bi * 3 * hy_h + bs * hy_h);
-                    // Update time
-                    profileRNNkernels(handle, 1, ctime);
+                if(dirMode != 0u)
+                {
+                    if(in_n.at(0) == in_n.at(seqLen - 1))
+                    {
+                        OpTensor(handle,
+                                 miopenTensorOpAdd,
+                                 &alpha0,
+                                 sp_desc,
+                                 workSpace,
+                                 &alpha1,
+                                 w_desc,
+                                 w,
+                                 &beta_t,
+                                 sp_desc,
+                                 workSpace,
+                                 hid_shift + wei_len,
+                                 wei_shift_bias_temp + wei_len,
+                                 hid_shift + wei_len);
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+                    }
+                    else
+                    {
+                        int cur_batch = 0;
+                        for(int ti = 0; ti < seqLen; ti++)
+                        {
+                            if(ti != (seqLen - 1))
+                            {
+                                offset = hid_shift + cur_batch * hy_stride;
+
+                                sp_size[1] = in_n.at(ti + 1);
+                                sp_size[2] = wei_len;
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpAdd,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         w_desc,
+                                         w,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + wei_len,
+                                         wei_shift_bias_temp + wei_len,
+                                         offset + wei_len);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
+                            cur_batch += in_n.at(ti);
+                        }
+                    }
                 }
             }
         }
@@ -395,160 +527,153 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
         int baccbi = batch_n;
         for(int ti = 0; ti < seqLen; ti++)
         {
-            baccbi -= in_n[seqLen - 1 - ti];
-            wei_shift = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
+            baccbi -= in_n.at(seqLen - 1 - ti);
+            wei_shift         = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
+            int pretime_shift = 0;
+            int use_time      = 0;
 
             for(int ri = 0; ri < bi; ri++)
             {
                 int cur_time  = ri == 0 ? ti : seqLen - 1 - ti;
                 int cur_batch = ri == 0 ? bacc : baccbi;
                 offset        = hid_shift + cur_batch * hy_stride;
+                if(ti > 0)
+                {
+                    pretime_shift =
+                        ri == 0 ? hid_shift + (bacc - in_n.at(ti - 1)) * hy_stride
+                                : hid_shift + (baccbi + in_n.at(seqLen - 1 - ti)) * hy_stride;
+                    use_time = ri == 0 ? ti : seqLen - ti;
+                }
 
-                if(in_n[cur_time] > 0)
+                if(in_n.at(cur_time) > 0)
                 {
                     if(ti == 0)
                     {
-
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      hx,
-                                                      w,
-                                                      workSpace,
-                                                      in_n.at(cur_time),
-                                                      wei_len_t,
-                                                      hy_h,
-                                                      1,
-                                                      1,
-                                                      false,
-                                                      true,
-                                                      false,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      hy_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   hx,
-                                   w,
-                                   workSpace,
-                                   hx_shift + ri * hy_n * hy_h,
-                                   wei_shift + ri * wei_len * uni_stride,
-                                   offset + ri * wei_len);
-
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-
-                        if(rnnMode == miopenGRU)
+                        if(hx != nullptr)
                         {
+                            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                              false,
+                                                                              true,
+                                                                              in_n.at(cur_time),
+                                                                              wei_len,
+                                                                              hy_h,
+                                                                              uni_stride,
+                                                                              uni_stride,
+                                                                              hy_stride,
+                                                                              1, // batch count
+                                                                              0, // Stride A
+                                                                              0, // Stride B
+                                                                              0, // Stride C
+                                                                              1, // alpha
+                                                                              1, // beta
+                                                                              xDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         hx,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         workSpace,
+                                         offset + ri * wei_len,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                            auto gg2 = ScanGemmGeometryRNN(handle,
-                                                           hx,
-                                                           w,
-                                                           workSpace,
-                                                           in_n.at(cur_time),
-                                                           hy_h,
-                                                           hy_h,
-                                                           1,
-                                                           1,
-                                                           false,
-                                                           true,
-                                                           false,
-                                                           uni_stride,
-                                                           uni_stride,
-                                                           hy_stride,
-                                                           false,
-                                                           network_config,
-                                                           MIO_RNN_FINDSOL_TIMEOUT);
-                            gg2.RunGemm(handle,
-                                        hx,
-                                        w,
-                                        workSpace,
-                                        hx_shift + ri * hy_n * hy_h,
-                                        wei_shift + 2 * hy_h * uni_stride +
-                                            ri * 3 * hy_h * uni_stride,
-                                        offset + bi * 3 * hy_h + ri * hy_h);
-
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
                         }
                     }
                     else
                     {
+                        if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                        {
+                            miopen::GemmDescriptor gemm_desc =
+                                GemmDescriptor{false,
+                                               false,
+                                               true,
+                                               (in_n.at(cur_time) - in_n.at(use_time)),
+                                               wei_len,
+                                               hy_h,
+                                               uni_stride,
+                                               uni_stride,
+                                               hy_stride,
+                                               1, // batch count
+                                               0, // Stride A
+                                               0, // Stride B
+                                               0, // Stride C
+                                               1, // alpha
+                                               1, // beta
+                                               xDesc[0].GetType()};
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         hx,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         workSpace,
+                                         offset + ri * wei_len + in_n.at(use_time) * hy_stride,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      hy,
-                                                      w,
-                                                      workSpace,
-                                                      in_n.at(cur_time),
-                                                      wei_len_t,
-                                                      hy_h,
-                                                      1,
-                                                      1,
-                                                      false,
-                                                      true,
-                                                      false,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      hy_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   hy,
-                                   w,
-                                   workSpace,
-                                   hx_shift + ri * hy_n * hy_h,
-                                   wei_shift + ri * wei_len * uni_stride,
-                                   offset + ri * wei_len);
-
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
 
-                        if(rnnMode == miopenGRU)
+                        if(in_n.at(use_time) > 0)
                         {
+                            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                              false,
+                                                                              true,
+                                                                              in_n.at(use_time),
+                                                                              wei_len,
+                                                                              hy_h,
+                                                                              hy_stride,
+                                                                              uni_stride,
+                                                                              hy_stride,
+                                                                              1, // batch count
+                                                                              0, // Stride A
+                                                                              0, // Stride B
+                                                                              0, // Stride C
+                                                                              1, // alpha
+                                                                              1, // beta
+                                                                              xDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         workSpace,
+                                         pretime_shift + hid_off + ri * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         workSpace,
+                                         offset + ri * wei_len,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                            auto gg2 = ScanGemmGeometryRNN(handle,
-                                                           hy,
-                                                           w,
-                                                           workSpace,
-                                                           in_n.at(cur_time),
-                                                           hy_h,
-                                                           hy_h,
-                                                           1,
-                                                           1,
-                                                           false,
-                                                           true,
-                                                           false,
-                                                           uni_stride,
-                                                           uni_stride,
-                                                           hy_stride,
-                                                           false,
-                                                           network_config,
-                                                           MIO_RNN_FINDSOL_TIMEOUT);
-
-                            gg2.RunGemm(handle,
-                                        hy,
-                                        w,
-                                        workSpace,
-                                        hx_shift + ri * hy_n * hy_h,
-                                        wei_shift + 2 * hy_h * uni_stride +
-                                            ri * 3 * hy_h * uni_stride,
-                                        offset + bi * 3 * hy_h + ri * hy_h);
-
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
                         }
                     }
 
                     // update hidden status
-                    hx_size[1] = in_n[cur_time];
-                    hx_size[2] = hy_h;
-                    hx_desc =
-                        miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
-
-                    sp_size[1] = in_n[cur_time];
+                    sp_size[1] = in_n.at(cur_time);
                     if(rnnMode == miopenRNNRELU || rnnMode == miopenRNNTANH)
                     {
                         sp_size[2] = hy_h;
@@ -562,8 +687,8 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                           &beta,
                                           sp_desc,
                                           workSpace,
-                                          offset + ri * hy_h,
-                                          offset + ri * hy_h);
+                                          offset + ri * wei_len,
+                                          offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
                     }
@@ -581,8 +706,8 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                         &beta,
                                         sp_desc,
                                         workSpace,
-                                        offset + ri * 4 * hy_h,
-                                        offset + ri * 4 * hy_h);
+                                        offset + ri * wei_len,
+                                        offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -598,8 +723,8 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                          &beta,
                                          sp_desc,
                                          workSpace,
-                                         offset + 3 * hy_h + ri * 4 * hy_h,
-                                         offset + 3 * hy_h + ri * 4 * hy_h);
+                                         offset + 3 * hy_h + ri * wei_len,
+                                         offset + 3 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -619,59 +744,110 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + ri * 4 * hy_h,
-                                 offset + 3 * hy_h + ri * 4 * hy_h,
-                                 offset + bi * 4 * hy_h + ri * hy_h);
+                                 offset + ri * wei_len,
+                                 offset + 3 * hy_h + ri * wei_len,
+                                 offset + bi * wei_len + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         if(ti == 0)
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     cx,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + hy_h + ri * 4 * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
+                            if(cx != nullptr)
+                            {
+                                hx_size[1] = in_n.at(cur_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         cx,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + hy_h + ri * wei_len,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + bi * wei_len + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     cy,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + hy_h + ri * 4 * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
-                        }
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                            if(ri == 1 && cx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
 
-                        // update cy
-                        CopyTensor(handle,
-                                   sp_desc,
-                                   workSpace,
-                                   hx_desc,
-                                   cy,
-                                   offset + bi * 4 * hy_h + ri * hy_h,
-                                   hx_shift + ri * hy_n * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         cx,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + hy_h + ri * wei_len +
+                                             in_n.at(use_time) * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         offset + bi * wei_len + ri * hy_h +
+                                             in_n.at(use_time) * hy_stride);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                            }
+
+                            if(in_n.at(use_time) > 0)
+                            {
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(use_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         workSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + hy_h + ri * wei_len,
+                                         pretime_shift + bi * wei_len + ri * hy_h,
+                                         offset + bi * wei_len + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(cur_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+                            }
+                        }
 
                         // active cell state
                         tanhDesc.Forward(handle,
@@ -681,12 +857,13 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                          &beta,
                                          sp_desc,
                                          workSpace,
-                                         offset + bi * 4 * hy_h + ri * hy_h,
-                                         offset + bi * 4 * hy_h + ri * hy_h);
+                                         offset + bi * wei_len + ri * hy_h,
+                                         offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         // update hidden state
+                        beta_t = 0;
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
@@ -698,9 +875,9 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + 2 * hy_h + ri * 4 * hy_h,
-                                 offset + bi * 4 * hy_h + ri * hy_h,
-                                 offset + bi * 5 * hy_h + ri * hy_h);
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hid_off + ri * hy_h,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
                     }
@@ -718,8 +895,8 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                         &beta,
                                         sp_desc,
                                         workSpace,
-                                        offset + ri * 3 * hy_h,
-                                        offset + ri * 3 * hy_h);
+                                        offset + ri * wei_len,
+                                        offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -730,7 +907,7 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
 
                         alpha0 = 1;
                         alpha1 = 1;
-                        beta_t = 1;
+                        beta_t = 0;
 
                         OpTensor(handle,
                                  miopenTensorOpMul,
@@ -743,9 +920,26 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + hy_h + ri * 3 * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + 2 * hy_h + ri * 3 * hy_h);
+                                 offset + hy_h + ri * wei_len,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + 2 * hy_h + ri * wei_len);
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+
+                        OpTensor(handle,
+                                 miopenTensorOpAdd,
+                                 &alpha0,
+                                 sp_desc,
+                                 workSpace,
+                                 &alpha1,
+                                 sp_desc,
+                                 workSpace,
+                                 &beta_t,
+                                 sp_desc,
+                                 workSpace,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hid_off + ri * hy_h,
+                                 offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -757,8 +951,8 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                          &beta,
                                          sp_desc,
                                          workSpace,
-                                         offset + 2 * hy_h + ri * 3 * hy_h,
-                                         offset + 2 * hy_h + ri * 3 * hy_h);
+                                         offset + 2 * hy_h + ri * wei_len,
+                                         offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -777,15 +971,15 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + ri * 3 * hy_h,
-                                 offset + 2 * hy_h + ri * 3 * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h);
+                                 offset + ri * wei_len,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         alpha0 = 1;
-                        alpha1 = 0;
-                        beta_t = 1;
+                        alpha1 = 1;
+                        beta_t = 0;
 
                         OpTensor(handle,
                                  miopenTensorOpAdd,
@@ -798,9 +992,9 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + 2 * hy_h + ri * 3 * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h);
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hid_off + ri * hy_h,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -809,104 +1003,164 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
                         beta_t = 1;
                         if(ti == 0)
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     hx,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + ri * 3 * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 3 * hy_h + ri * hy_h);
+                            if(hx != nullptr)
+                            {
+                                hx_size[1] = in_n.at(cur_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         hx,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + ri * wei_len,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + hid_off + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     hy,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + ri * 3 * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 3 * hy_h + ri * hy_h);
+                            if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         hx,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + ri * wei_len + in_n.at(use_time) * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         offset + hid_off + ri * hy_h +
+                                             in_n.at(use_time) * hy_stride);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                            }
+
+                            if(in_n.at(use_time) > 0)
+                            {
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(use_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         workSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + ri * wei_len,
+                                         pretime_shift + hid_off + ri * hy_h,
+                                         offset + hid_off + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
                     }
-
-                    // update hy
-                    CopyTensor(handle,
-                               sp_desc,
-                               workSpace,
-                               hx_desc,
-                               hy,
-                               offset + hid_off + ri * hy_h,
-                               hx_shift + ri * hy_n * hy_h);
-                    // Update time
-                    profileRNNkernels(handle, 1, ctime);
                 }
             }
 
-            bacc += in_n[ti];
+            bacc += in_n.at(ti);
         }
 
-        // hy, cy clean
-        if(in_n[0] - in_n[seqLen - 1] > 0)
+        // update hy, cy
+        if(hy != nullptr || (rnnMode == miopenLSTM && cy != nullptr))
         {
-            hx_size[1] = in_n[0] - in_n[seqLen - 1];
             hx_size[2] = hy_h;
-            hx_desc    = miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
+            sp_size[2] = hy_h;
 
-            alpha0 = 0;
-            alpha1 = 0;
-            beta_t = 0;
+            bacc   = batch_n;
+            baccbi = 0;
+            for(int ti = seqLen - 1; ti >= 0; ti--)
+            {
+                bacc -= in_n.at(ti);
+                for(int ri = 0; ri < bi; ri++)
+                {
+                    int cur_time  = ri == 0 ? ti : seqLen - 1 - ti;
+                    int cur_batch = ri == 0 ? bacc : baccbi;
+                    int use_batch = 0;
 
-            OpTensor(handle,
-                     miopenTensorOpMul,
-                     &alpha0,
-                     hx_desc,
-                     hy,
-                     &alpha1,
-                     hx_desc,
-                     hy,
-                     &beta_t,
-                     hx_desc,
-                     hy,
-                     hx_shift + in_n[seqLen - 1] * uni_stride,
-                     hx_shift + in_n[seqLen - 1] * uni_stride,
-                     hx_shift + in_n[seqLen - 1] * uni_stride);
-            // Update time
-            profileRNNkernels(handle, 1, ctime);
+                    if(ti < seqLen - 1)
+                    {
+                        int use_time = ri == 0 ? ti + 1 : seqLen - 2 - ti;
+                        use_batch    = in_n.at(use_time);
+                    }
 
-            if(rnnMode == miopenLSTM)
-            {
-                OpTensor(handle,
-                         miopenTensorOpMul,
-                         &alpha0,
-                         hx_desc,
-                         cy,
-                         &alpha1,
-                         hx_desc,
-                         cy,
-                         &beta_t,
-                         hx_desc,
-                         cy,
-                         hx_shift + in_n[seqLen - 1] * uni_stride,
-                         hx_shift + in_n[seqLen - 1] * uni_stride,
-                         hx_shift + in_n[seqLen - 1] * uni_stride);
-                // Update time
-                profileRNNkernels(handle, 1, ctime);
+                    if(in_n.at(cur_time) > use_batch)
+                    {
+                        offset = hid_shift + cur_batch * hy_stride;
+
+                        sp_size[1] = in_n.at(cur_time) - use_batch;
+                        sp_desc    = miopen::TensorDescriptor(
+                            miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                        hx_size[1] = sp_size[1];
+                        hx_desc    = miopen::TensorDescriptor(
+                            miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                        if(hy != nullptr)
+                        {
+                            CopyTensor(handle,
+                                       sp_desc,
+                                       workSpace,
+                                       hx_desc,
+                                       hy,
+                                       offset + hid_off + ri * hy_h + use_batch * hy_stride,
+                                       hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+
+                        if(rnnMode == miopenLSTM && cy != nullptr)
+                        {
+                            CopyTensor(handle,
+                                       sp_desc,
+                                       workSpace,
+                                       hx_desc,
+                                       cy,
+                                       offset + bi * wei_len + ri * hy_h + use_batch * hy_stride,
+                                       hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+                    }
+                }
+                baccbi += in_n.at(seqLen - 1 - ti);
             }
         }
     }
@@ -926,16 +1180,19 @@ void RNNDescriptor::RNNForwardInference(Handle& handle,
     profileRNNkernels(handle, 2, ctime);
 
 #else
+    (void)hx;
+    (void)cx;
+    (void)offset;
+    (void)alpha0;
+    (void)alpha1;
+    (void)beta_t;
+    (void)alpha;
+    (void)bi_stride;
+    (void)wei_shift_bias;
     MIOPEN_THROW("GEMM is not supported");
 #endif
 
     // Suppress warning
-    (void)cxDesc;
-    (void)cyDesc;
-    (void)hxDesc;
-    (void)hyDesc;
-    (void)wDesc;
-    (void)workSpaceSize;
 }
 
 void RNNDescriptor::RNNForwardTraining(Handle& handle,
@@ -959,6 +1216,7 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                        Data_t reserveSpace,
                                        size_t reserveSpaceSize) const
 {
+    (void)workSpace;
 
     if(x == nullptr || w == nullptr || y == nullptr)
     {
@@ -986,7 +1244,7 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
     int hy_h  = hyDesc.GetLengths()[2];   // hidden size
     int out_h = yDesc[0].GetLengths()[1]; // output vector size
 
-    if(in_h == 0 || hy_h == 0 || hy_n == 0 || hy_d == 0 || out_h == 0)
+    if(in_h == 0 || hy_h == 0 || hy_n == 0 || hy_d == 0 || out_h == 0 || seqLen <= 0)
     {
         MIOPEN_THROW(miopenStatusBadParm);
     }
@@ -1057,6 +1315,14 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
         x_stride(3, 1), y_size(3, 1), y_stride(3, 1), hx_size(3, 1), hx_stride(3, 1);
     miopen::TensorDescriptor sp_desc, w_desc, x_desc, y_desc, hx_desc;
 
+    sp_size[2]   = reserveSpaceSize / GetTypeSize(wDesc.GetType());
+    sp_stride[0] = sp_size[2];
+    sp_stride[1] = sp_size[2];
+    sp_desc      = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+    SetTensor(handle, sp_desc, reserveSpace, &beta);
+    // Update time
+    profileRNNkernels(handle, 0, ctime);
+
     sp_stride[0] = batch_n * hy_stride;
     sp_stride[1] = hy_stride;
     w_stride[0]  = wei_stride;
@@ -1065,35 +1331,50 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
     x_stride[1]  = in_stride;
     y_stride[0]  = batch_n * out_stride;
     y_stride[1]  = out_stride;
+    if(hy != nullptr || (rnnMode == miopenLSTM && cy != nullptr))
+    {
+        hx_size[2]   = hy_d * hy_n * hy_h;
+        hx_stride[0] = hx_size[2];
+        hx_stride[1] = hx_size[2];
+        hx_desc      = miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
+        if(hy != nullptr)
+        {
+            SetTensor(handle, hx_desc, hy, &beta);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+        if(rnnMode == miopenLSTM && cy != nullptr)
+        {
+            SetTensor(handle, hx_desc, cy, &beta);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+    }
     hx_stride[0] = in_n[0] * uni_stride;
     hx_stride[1] = uni_stride;
 
-#if MIOPEN_USE_MIOPENGEMM
+#if MIOPEN_USE_ROCBLAS
 
     int wei_shift, prelayer_shift;
     int wei_len   = 0;
-    int wei_len_t = 0;
     int hid_off   = 0;
 
     switch(rnnMode)
     {
     case miopenRNNRELU:
     case miopenRNNTANH:
-        // printf("run rnn gpu fwd \n");
+        printf("run rnn gpu fwd \n");
         wei_len   = hy_h;
-        wei_len_t = hy_h;
         hid_off   = nLayers * batch_n * hy_stride;
         break;
     case miopenLSTM:
-        // printf("run lstm gpu fwd \n");
+        printf("run lstm gpu fwd \n");
         wei_len   = hy_h * 4;
-        wei_len_t = hy_h * 4;
         hid_off   = bi * hy_h * 5;
         break;
     case miopenGRU:
-        // printf("run gru gpu fwd \n");
+        printf("run gru gpu fwd \n");
         wei_len   = hy_h * 3;
-        wei_len_t = hy_h * 2;
         hid_off   = bi * hy_h * 3;
         break;
     }
@@ -1114,9 +1395,7 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
     {
         int hid_shift           = li * batch_n * hy_stride;
         int hx_shift            = li * hy_n * bi_stride;
-        int wei_shift_bias_temp = inputMode == miopenRNNskip
-                                      ? (wei_shift_bias + wei_stride + (li - 1) * 2 * wei_stride)
-                                      : (wei_shift_bias + li * 2 * wei_stride);
+        int wei_shift_bias_temp = wei_shift_bias + li * 2 * wei_stride;
 
         // from input
         if(li == 0)
@@ -1140,27 +1419,39 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
             }
             else
             {
-                auto gg = ScanGemmGeometryRNN(handle,
-                                              x,
-                                              w,
-                                              reserveSpace,
-                                              batch_n,
-                                              wei_len * bi,
-                                              in_h,
-                                              1,
-                                              1,
-                                              false,
-                                              true,
-                                              false,
-                                              in_stride,
-                                              in_stride,
-                                              hy_stride,
-                                              false,
-                                              network_config,
-                                              MIO_RNN_FINDSOL_TIMEOUT);
-
-                gg.RunGemm(handle, x, w, reserveSpace, 0, 0, hid_shift);
+                miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                  false,
+                                                                  true,
+                                                                  batch_n,
+                                                                  wei_len * bi,
+                                                                  in_h,
+                                                                  in_stride,
+                                                                  in_stride,
+                                                                  hy_stride,
+                                                                  1,
+                                                                  0,
+                                                                  0,
+                                                                  0,
+                                                                  1,
+                                                                  1,
+                                                                  xDesc[0].GetType()};
+
+                miopenStatus_t gemm_status = CallGemm(handle,
+                                                      gemm_desc,
+                                                      x,
+                                                      0,
+                                                      w,
+                                                      0,
+                                                      reserveSpace,
+                                                      hid_shift,
+                                                      nullptr,
+                                                      false,
+                                                      GemmBackend_t::rocblas);
 
+                if(gemm_status != miopenStatusSuccess)
+                {
+                    MIOPEN_LOG_E("GEMM failed");
+                }
                 // Update time
                 profileRNNkernels(handle, 0, ctime);
             }
@@ -1170,40 +1461,45 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
             wei_shift = (in_h + hy_h) * wei_stride + (li - 1) * (bi * hy_h + hy_h) * wei_stride;
             prelayer_shift = (li - 1) * batch_n * hy_stride + hid_off;
 
-            auto gg = ScanGemmGeometryRNN(handle,
-                                          reserveSpace,
-                                          w,
-                                          reserveSpace,
-                                          batch_n,
-                                          wei_len * bi,
-                                          hy_h * bi,
-                                          1,
-                                          1,
-                                          false,
-                                          true,
-                                          false,
-                                          hy_stride,
-                                          bi_stride,
-                                          hy_stride,
-                                          false,
-                                          network_config,
-                                          MIO_RNN_FINDSOL_TIMEOUT);
-
-            gg.RunGemm(handle, reserveSpace, w, reserveSpace, prelayer_shift, wei_shift, hid_shift);
+            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                               false,
+                                                               true,
+                                                               batch_n,
+                                                               wei_len * bi,
+                                                               hy_h * bi,
+                                                               hy_stride,
+                                                               bi_stride,
+                                                               hy_stride,
+                                                               1, // batch count
+                                                               0, // Stride A
+                                                               0, // Stride B
+                                                               0, // Stride C
+                                                               1, // alpha
+                                                               1, // beta
+                                                               xDesc[0].GetType()};
+
+            miopenStatus_t gemm_status = CallGemm(handle,
+                                                  gemm_desc,
+                                                  workSpace,
+                                                  prelayer_shift,
+                                                  w,
+                                                  wei_shift,
+                                                  reserveSpace,
+                                                  hid_shift,
+                                                  nullptr,
+                                                  false,
+                                                  GemmBackend_t::rocblas);
+            if(gemm_status != miopenStatusSuccess)
+            {
+                MIOPEN_LOG_E("GEMM failed");
+            }
 
             // Update time
             profileRNNkernels(handle, 1, ctime);
         }
 
-        if(biasMode)
+        if(biasMode != 0u)
         {
-            int wn = rnnMode == miopenGRU ? 1 : 2;
-            if(inputMode == miopenRNNskip && li == 0)
-            {
-                wei_shift_bias_temp = wei_shift_bias;
-                wn                  = rnnMode == miopenGRU ? 0 : 1;
-            }
-
             alpha0 = 1;
             alpha1 = 1;
             beta_t = 0;
@@ -1215,10 +1511,84 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
             w_desc     = miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
             sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
 
-            for(int bs = 0; bs < wn; bs++)
+            OpTensor(handle,
+                     miopenTensorOpAdd,
+                     &alpha0,
+                     sp_desc,
+                     reserveSpace,
+                     &alpha1,
+                     w_desc,
+                     w,
+                     &beta_t,
+                     sp_desc,
+                     reserveSpace,
+                     hid_shift,
+                     wei_shift_bias_temp,
+                     hid_shift);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+
+        if(rnnMode == miopenGRU)
+        {
+            sp_size[1] = batch_n;
+            sp_size[2] = hy_h;
+            sp_desc =
+                miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+            alpha0 = 0;
+            alpha1 = 0;
+            beta_t = 0;
+
+            for(int bs = 0; bs < bi; bs++)
             {
-                OpTensor(handle,
-                         miopenTensorOpAdd,
+                CopyTensor(handle,
+                           sp_desc,
+                           reserveSpace,
+                           sp_desc,
+                           reserveSpace,
+                           hid_shift + bs * wei_len + 2 * hy_h,
+                           hid_shift + hid_off + bs * hy_h);
+
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
+
+                OpTensor(handle,
+                         miopenTensorOpAdd,
+                         &alpha0,
+                         sp_desc,
+                         reserveSpace,
+                         &alpha1,
+                         sp_desc,
+                         reserveSpace,
+                         &beta_t,
+                         sp_desc,
+                         reserveSpace,
+                         hid_shift + bs * wei_len + 2 * hy_h,
+                         hid_shift + bs * wei_len + 2 * hy_h,
+                         hid_shift + bs * wei_len + 2 * hy_h);
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
+            }
+        }
+
+        if(biasMode != 0u)
+        {
+            wei_shift_bias_temp += wei_stride;
+
+            alpha0 = 1;
+            alpha1 = 1;
+            beta_t = 0;
+
+            if(hx != nullptr)
+            {
+                sp_size[1] = batch_n;
+                sp_size[2] = wei_stride;
+                sp_desc =
+                    miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+                OpTensor(handle,
+                         miopenTensorOpAdd,
                          &alpha0,
                          sp_desc,
                          reserveSpace,
@@ -1229,63 +1599,94 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                          sp_desc,
                          reserveSpace,
                          hid_shift,
-                         wei_shift_bias_temp + bs * wei_stride,
+                         wei_shift_bias_temp,
                          hid_shift);
                 // Update time
                 profileRNNkernels(handle, 1, ctime);
             }
-
-            if(rnnMode == miopenGRU)
+            else
             {
-                for(int bs = 0; bs < bi; bs++)
-                {
-                    w_size[2]  = 2 * hy_h;
-                    sp_size[2] = 2 * hy_h;
-                    w_desc =
-                        miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
-                    sp_desc =
-                        miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                sp_size[1] = batch_n - in_n.at(0);
+                sp_size[2] = wei_len;
+                sp_desc =
+                    miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                w_size[1] = 1;
+                w_size[2] = wei_len;
+                w_desc =
+                    miopen::TensorDescriptor(wDesc.GetType(), w_size.data(), w_stride.data(), 3);
 
-                    OpTensor(handle,
-                             miopenTensorOpAdd,
-                             &alpha0,
-                             sp_desc,
-                             reserveSpace,
-                             &alpha1,
-                             w_desc,
-                             w,
-                             &beta_t,
-                             sp_desc,
-                             reserveSpace,
-                             hid_shift + bs * 3 * hy_h,
-                             wei_shift_bias_temp + wn * wei_stride + bs * 3 * hy_h,
-                             hid_shift + bs * 3 * hy_h);
-                    // Update time
-                    profileRNNkernels(handle, 1, ctime);
+                OpTensor(handle,
+                         miopenTensorOpAdd,
+                         &alpha0,
+                         sp_desc,
+                         reserveSpace,
+                         &alpha1,
+                         w_desc,
+                         w,
+                         &beta_t,
+                         sp_desc,
+                         reserveSpace,
+                         hid_shift + in_n.at(0) * hy_stride,
+                         wei_shift_bias_temp,
+                         hid_shift + in_n.at(0) * hy_stride);
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
 
-                    w_size[2]  = hy_h;
-                    sp_size[2] = hy_h;
-                    w_desc =
-                        miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
-                    sp_desc =
-                        miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                if(dirMode != 0u)
+                {
+                    if(in_n.at(0) == in_n.at(seqLen - 1))
+                    {
+                        OpTensor(handle,
+                                 miopenTensorOpAdd,
+                                 &alpha0,
+                                 sp_desc,
+                                 reserveSpace,
+                                 &alpha1,
+                                 w_desc,
+                                 w,
+                                 &beta_t,
+                                 sp_desc,
+                                 reserveSpace,
+                                 hid_shift + wei_len,
+                                 wei_shift_bias_temp + wei_len,
+                                 hid_shift + wei_len);
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+                    }
+                    else
+                    {
+                        int cur_batch = 0;
+                        for(int ti = 0; ti < seqLen; ti++)
+                        {
+                            if(ti != (seqLen - 1))
+                            {
+                                offset = hid_shift + cur_batch * hy_stride;
 
-                    OpTensor(handle,
-                             miopenTensorOpAdd,
-                             &alpha0,
-                             sp_desc,
-                             reserveSpace,
-                             &alpha1,
-                             w_desc,
-                             w,
-                             &beta_t,
-                             sp_desc,
-                             reserveSpace,
-                             hid_shift + bi * 3 * hy_h + bs * hy_h,
-                             wei_shift_bias_temp + wn * wei_stride + 2 * hy_h + bs * 3 * hy_h,
-                             hid_shift + bi * 3 * hy_h + bs * hy_h);
-                    // Update time
-                    profileRNNkernels(handle, 1, ctime);
+                                sp_size[1] = in_n.at(ti + 1);
+                                sp_size[2] = wei_len;
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpAdd,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         w_desc,
+                                         w,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         static_cast<int>(offset) + wei_len,
+                                         wei_shift_bias_temp + wei_len,
+                                         static_cast<int>(offset) + wei_len);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
+                            cur_batch += in_n.at(ti);
+                        }
+                    }
                 }
             }
         }
@@ -1297,6 +1698,8 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
         {
             baccbi -= in_n[seqLen - 1 - ti];
             wei_shift = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
+            int pretime_shift = 0;
+            int use_time = 0;
 
             for(int ri = 0; ri < bi; ri++)
             {
@@ -1308,146 +1711,130 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                 {
                     if(ti == 0)
                     {
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      hx,
-                                                      w,
-                                                      reserveSpace,
-                                                      in_n.at(cur_time),
-                                                      wei_len_t,
-                                                      hy_h,
-                                                      1,
-                                                      1,
-                                                      false,
-                                                      true,
-                                                      false,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      hy_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   hx,
-                                   w,
-                                   reserveSpace,
-                                   hx_shift + ri * hy_n * hy_h,
-                                   wei_shift + ri * wei_len * uni_stride,
-                                   offset + ri * wei_len);
-
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-
-                        if(rnnMode == miopenGRU)
+                        if(hx != nullptr)
                         {
+                            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                              false,
+                                                                              true,
+                                                                              in_n.at(cur_time),
+                                                                              wei_len,
+                                                                              hy_h,
+                                                                              uni_stride,
+                                                                              uni_stride,
+                                                                              hy_stride,
+                                                                              1, // batch count
+                                                                              0, // Stride A
+                                                                              0, // Stride B
+                                                                              0, // Stride C
+                                                                              1, // alpha
+                                                                              1, // beta
+                                                                              xDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         hx,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         reserveSpace,
+                                         static_cast<int>(offset) + ri * wei_len,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                            auto gg2 = ScanGemmGeometryRNN(handle,
-                                                           hx,
-                                                           w,
-                                                           reserveSpace,
-                                                           in_n.at(cur_time),
-                                                           hy_h,
-                                                           hy_h,
-                                                           1,
-                                                           1,
-                                                           false,
-                                                           true,
-                                                           false,
-                                                           uni_stride,
-                                                           uni_stride,
-                                                           hy_stride,
-                                                           false,
-                                                           network_config,
-                                                           MIO_RNN_FINDSOL_TIMEOUT);
-
-                            gg2.RunGemm(handle,
-                                        hx,
-                                        w,
-                                        reserveSpace,
-                                        hx_shift + ri * hy_n * hy_h,
-                                        wei_shift + 2 * hy_h * uni_stride +
-                                            ri * 3 * hy_h * uni_stride,
-                                        offset + bi * 3 * hy_h + ri * hy_h);
-
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
                         }
                     }
                     else
                     {
+                        if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                        {
+                            miopen::GemmDescriptor gemm_desc =
+                                GemmDescriptor{false,
+                                               false,
+                                               true,
+                                               (in_n.at(cur_time) - in_n.at(use_time)),
+                                               wei_len,
+                                               hy_h,
+                                               uni_stride,
+                                               uni_stride,
+                                               hy_stride,
+                                               1, // batch count
+                                               0, // Stride A
+                                               0, // Stride B
+                                               0, // Stride C
+                                               1, // alpha
+                                               1, // beta
+                                               xDesc[0].GetType()};
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         hx,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         reserveSpace,
+                                         offset + ri * wei_len + in_n.at(use_time) * hy_stride,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      hx,
-                                                      w,
-                                                      reserveSpace,
-                                                      in_n.at(cur_time),
-                                                      wei_len_t,
-                                                      hy_h,
-                                                      1,
-                                                      1,
-                                                      false,
-                                                      true,
-                                                      false,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      hy_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   hy,
-                                   w,
-                                   reserveSpace,
-                                   hx_shift + ri * hy_n * hy_h,
-                                   wei_shift + ri * wei_len * uni_stride,
-                                   offset + ri * wei_len);
-
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
 
-                        if(rnnMode == miopenGRU)
+                        if(in_n.at(use_time) > 0)
                         {
+                            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                              false,
+                                                                              true,
+                                                                              in_n.at(use_time),
+                                                                              wei_len,
+                                                                              hy_h,
+                                                                              hy_stride,
+                                                                              uni_stride,
+                                                                              hy_stride,
+                                                                              1, // batch count
+                                                                              0, // Stride A
+                                                                              0, // Stride B
+                                                                              0, // Stride C
+                                                                              1, // alpha
+                                                                              1, // beta
+                                                                              xDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         reserveSpace,
+                                         pretime_shift + hid_off + ri * hy_h,
+                                         w,
+                                         wei_shift + ri * wei_len * uni_stride,
+                                         reserveSpace,
+                                         offset + ri * wei_len,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                            auto gg2 = ScanGemmGeometryRNN(handle,
-                                                           hy,
-                                                           w,
-                                                           reserveSpace,
-                                                           in_n.at(cur_time),
-                                                           hy_h,
-                                                           hy_h,
-                                                           1,
-                                                           1,
-                                                           false,
-                                                           true,
-                                                           false,
-                                                           uni_stride,
-                                                           uni_stride,
-                                                           hy_stride,
-                                                           false,
-                                                           network_config,
-                                                           MIO_RNN_FINDSOL_TIMEOUT);
-
-                            gg2.RunGemm(handle,
-                                        hy,
-                                        w,
-                                        reserveSpace,
-                                        hx_shift + ri * hy_n * hy_h,
-                                        wei_shift + 2 * hy_h * uni_stride +
-                                            ri * 3 * hy_h * uni_stride,
-                                        offset + bi * 3 * hy_h + ri * hy_h);
-
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
                         }
                     }
 
                     // update hidden status
-                    hx_size[1] = in_n[cur_time];
-                    hx_size[2] = hy_h;
-                    hx_desc =
-                        miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
-
                     sp_size[1] = in_n[cur_time];
                     if(rnnMode == miopenRNNRELU || rnnMode == miopenRNNTANH)
                     {
@@ -1481,8 +1868,8 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                         &beta,
                                         sp_desc,
                                         reserveSpace,
-                                        offset + ri * 4 * hy_h,
-                                        offset + ri * 4 * hy_h + nLayers * batch_n * hy_stride);
+                                        offset + ri * wei_len,
+                                        offset + ri * wei_len + nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -1498,8 +1885,8 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                          &beta,
                                          sp_desc,
                                          reserveSpace,
-                                         offset + 3 * hy_h + ri * 4 * hy_h,
-                                         offset + 3 * hy_h + ri * 4 * hy_h +
+                                         offset + 3 * hy_h + ri * wei_len,
+                                         offset + 3 * hy_h + ri * wei_len +
                                              nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
@@ -1520,59 +1907,108 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  reserveSpace,
-                                 offset + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + 3 * hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 4 * hy_h + ri * hy_h);
+                                 offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + 3 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + bi * wei_len + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         if(ti == 0)
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     reserveSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     cx,
-                                     &beta_t,
-                                     sp_desc,
-                                     reserveSpace,
-                                     offset + hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
+                            if(cx != nullptr){
+                                hx_size[1] = in_n.at(cur_time);
+                                hx_size[2] = hy_h;
+                                hx_desc = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         cx,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + bi * wei_len + ri * hy_h);
+
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     reserveSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     cy,
-                                     &beta_t,
-                                     sp_desc,
-                                     reserveSpace,
-                                     offset + hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
-                        }
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                            if(ri == 1 && cx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
 
-                        // update cy
-                        CopyTensor(handle,
-                                   sp_desc,
-                                   reserveSpace,
-                                   hx_desc,
-                                   cy,
-                                   offset + bi * 4 * hy_h + ri * hy_h,
-                                   hx_shift + ri * hy_n * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         cx,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + hy_h + ri * wei_len + in_n.at(use_time) * hy_stride + nLayers * batch_n * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         offset + bi * wei_len + ri * hy_h + in_n.at(use_time) * hy_stride);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                            }
+
+                            if(in_n.at(use_time) > 0)
+                            {
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(use_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + hy_h + ri * wei_len +
+                                             nLayers * batch_n * hy_stride,
+                                         pretime_shift + bi * wei_len + ri * hy_h,
+                                         offset + bi * wei_len + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(cur_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+                            }
+                        }
 
                         // active cell state
                         tanhDesc.Forward(handle,
@@ -1582,8 +2018,8 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                          &beta,
                                          sp_desc,
                                          reserveSpace,
-                                         offset + bi * 4 * hy_h + ri * hy_h,
-                                         offset + bi * 4 * hy_h + ri * hy_h +
+                                         offset + bi * wei_len + ri * hy_h,
+                                         offset + bi * wei_len + ri * hy_h +
                                              nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
@@ -1600,9 +2036,9 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  reserveSpace,
-                                 offset + 2 * hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 4 * hy_h + ri * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 5 * hy_h + ri * hy_h);
+                                 offset + 2 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + bi * wei_len + ri * hy_h + nLayers * batch_n * hy_stride,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
                     }
@@ -1620,8 +2056,8 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                         &beta,
                                         sp_desc,
                                         reserveSpace,
-                                        offset + ri * 3 * hy_h,
-                                        offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride);
+                                        offset + ri * wei_len,
+                                        offset + ri * wei_len + nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -1630,9 +2066,20 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                         sp_desc    = miopen::TensorDescriptor(
                             miopenFloat, sp_size.data(), sp_stride.data(), 3);
 
+                        CopyTensor(handle,
+                                   sp_desc,
+                                   reserveSpace,
+                                   sp_desc,
+                                   reserveSpace,
+                                   static_cast<int>(offset) + 2 * hy_h + ri * wei_len,
+                                   static_cast<int>(offset) + hid_off + ri * hy_h + static_cast<int>(nLayers) * batch_n * hy_stride);
+
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+
                         alpha0 = 1;
                         alpha1 = 1;
-                        beta_t = 1;
+                        beta_t = 0;
 
                         OpTensor(handle,
                                  miopenTensorOpMul,
@@ -1645,22 +2092,40 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  reserveSpace,
-                                 offset + hy_h + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + 2 * hy_h + ri * 3 * hy_h);
+                                 offset + hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        // active c gate
-                        tanhDesc.Forward(handle,
-                                         &alpha,
-                                         sp_desc,
+                        OpTensor(handle,
+                                 miopenTensorOpAdd,
+                                 &alpha0,
+                                 sp_desc,
+                                 reserveSpace,
+                                 &alpha1,
+                                 sp_desc,
+                                 reserveSpace,
+                                 &beta_t,
+                                 sp_desc,
+                                 reserveSpace,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hid_off + ri * hy_h,
+                                 offset + 2 * hy_h + ri * wei_len);
+
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+
+                        // active c gate
+                        tanhDesc.Forward(handle,
+                                         &alpha,
+                                         sp_desc,
                                          reserveSpace,
                                          &beta,
                                          sp_desc,
                                          reserveSpace,
-                                         offset + 2 * hy_h + ri * 3 * hy_h,
-                                         offset + 2 * hy_h + ri * 3 * hy_h +
+                                         offset + 2 * hy_h + ri * wei_len,
+                                         offset + 2 * hy_h + ri * wei_len +
                                              nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
@@ -1680,15 +2145,15 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  reserveSpace,
-                                 offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + 2 * hy_h + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 3 * hy_h + ri * hy_h);
+                                 offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + 2 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         alpha0 = 1;
-                        alpha1 = 0;
-                        beta_t = 1;
+                        alpha1 = 1;
+                        beta_t = 0;
 
                         OpTensor(handle,
                                  miopenTensorOpAdd,
@@ -1701,9 +2166,9 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  reserveSpace,
-                                 offset + 2 * hy_h + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h);
+                                 offset + 2 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + hid_off + ri * hy_h,
+                                 offset + hid_off + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -1712,104 +2177,166 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
                         beta_t = 1;
                         if(ti == 0)
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     reserveSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     hx,
-                                     &beta_t,
-                                     sp_desc,
-                                     reserveSpace,
-                                     offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 3 * hy_h + ri * hy_h);
+                            if(hx != nullptr)
+                            {
+                                hx_size[1] = in_n.at(cur_time);
+                                hx_size[2] = hy_h;
+                                hx_desc = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         hx,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + hid_off + ri * hy_h);
+
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     reserveSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     hy,
-                                     &beta_t,
-                                     sp_desc,
-                                     reserveSpace,
-                                     offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 3 * hy_h + ri * hy_h);
+                            if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
+
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         hy,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + ri * wei_len + in_n.at(use_time) * hy_stride + nLayers * batch_n * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         offset + hid_off + ri * hy_h + in_n.at(use_time) * hy_stride);
+
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                            }
+
+                            if(in_n.at(use_time) > 0)
+                            {
+                                if(in_n.at(use_time) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(use_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                }
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                         pretime_shift + hid_off + ri * hy_h,
+                                         offset + hid_off + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
                     }
-
-                    // update hy
-                    CopyTensor(handle,
-                               sp_desc,
-                               reserveSpace,
-                               hx_desc,
-                               hy,
-                               offset + hid_off + ri * hy_h,
-                               hx_shift + ri * hy_n * hy_h);
-                    // Update time
-                    profileRNNkernels(handle, 1, ctime);
                 }
             }
 
             bacc += in_n[ti];
         }
 
-        // hy, cy clean
-        if(in_n[0] - in_n[seqLen - 1] > 0)
+        if(hy != nullptr || (rnnMode == miopenLSTM && cy != nullptr))
         {
-            hx_size[1] = in_n[0] - in_n[seqLen - 1];
             hx_size[2] = hy_h;
-            hx_desc    = miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
+            sp_size[2] = hy_h;
 
-            alpha0 = 0;
-            alpha1 = 0;
-            beta_t = 0;
+            bacc = batch_n;
+            baccbi = 0;
+            for(int ti = seqLen - 1; ti >= 0; ti--)
+            {
+                bacc -= in_n.at(ti);
+                for(int ri = 0; ri < bi; ri++)
+                {
+                    int cur_time  = ri == 0 ? ti : seqLen - 1 - ti;
+                    int cur_batch = ri == 0 ? bacc : baccbi;
+                    int use_batch = 0;
 
-            OpTensor(handle,
-                     miopenTensorOpMul,
-                     &alpha0,
-                     hx_desc,
-                     hy,
-                     &alpha1,
-                     hx_desc,
-                     hy,
-                     &beta_t,
-                     hx_desc,
-                     hy,
-                     hx_shift + in_n[seqLen - 1] * uni_stride,
-                     hx_shift + in_n[seqLen - 1] * uni_stride,
-                     hx_shift + in_n[seqLen - 1] * uni_stride);
-            // Update time
-            profileRNNkernels(handle, 1, ctime);
+                    if(ti < seqLen - 1)
+                    {
+                        int use_time = ri == 0 ? ti + 1 : seqLen - 2 - ti;
+                        use_batch    = in_n.at(use_time);
+                    }
 
-            if(rnnMode == miopenLSTM)
-            {
-                OpTensor(handle,
-                         miopenTensorOpMul,
-                         &alpha0,
-                         hx_desc,
-                         cy,
-                         &alpha1,
-                         hx_desc,
-                         cy,
-                         &beta_t,
-                         hx_desc,
-                         cy,
-                         hx_shift + in_n[seqLen - 1] * uni_stride,
-                         hx_shift + in_n[seqLen - 1] * uni_stride,
-                         hx_shift + in_n[seqLen - 1] * uni_stride);
-                // Update time
-                profileRNNkernels(handle, 1, ctime);
+                    if(in_n.at(cur_time) > use_batch)
+                    {
+                        offset = hid_shift + cur_batch * hy_stride;
+
+                        sp_size[1] = in_n.at(cur_time) - use_batch;
+                        sp_desc    = miopen::TensorDescriptor(
+                            wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+                        hx_size[1] = sp_size[1];
+                        hx_desc    = miopen::TensorDescriptor(
+                            wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+
+                        if(hy != nullptr)
+                        {
+                            CopyTensor(handle,
+                                       sp_desc,
+                                       reserveSpace,
+                                       hx_desc,
+                                       hy,
+                                       static_cast<int>(offset) + hid_off + ri * hy_h +
+                                           use_batch * hy_stride,
+                                       hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+
+                        if(rnnMode == miopenLSTM && cy != nullptr)
+                        {
+                            CopyTensor(handle,
+                                       sp_desc,
+                                       reserveSpace,
+                                       hx_desc,
+                                       cy,
+                                       static_cast<int>(offset) + bi * wei_len + ri * hy_h +
+                                           use_batch * hy_stride,
+                                       hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+                    }
+                }
+                baccbi += in_n.at(seqLen - 1 - ti);
             }
         }
     }
@@ -1829,18 +2356,17 @@ void RNNDescriptor::RNNForwardTraining(Handle& handle,
     profileRNNkernels(handle, 2, ctime);
 
 #else
+    (void)bi_stride;
+    (void)alpha;
+    (void)offset;
+    (void)alpha0;
+    (void)alpha1;
+    (void)beta_t;
+    (void)hx;
+    (void)cx;
+    (void)wei_shift_bias;
     MIOPEN_THROW("GEMM is not supported");
 #endif
-
-    // Suppress warning
-    (void)cxDesc;
-    (void)cyDesc;
-    (void)hxDesc;
-    (void)hyDesc;
-    (void)wDesc;
-    (void)workSpace;
-    (void)workSpaceSize;
-    (void)reserveSpaceSize;
 };
 
 void RNNDescriptor::RNNBackwardData(Handle& handle,
@@ -1870,6 +2396,17 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                     Data_t reserveSpace,
                                     size_t reserveSpaceSize) const
 {
+    // Suppress warning
+    (void)y;
+    (void)yDesc;
+    (void)hxDesc;
+    (void)cxDesc;
+    (void)dcxDesc;
+    (void)dcyDesc;
+    (void)dhyDesc;
+    (void)wDesc;
+    (void)workSpaceSize;
+    (void)reserveSpaceSize;
 
     if(dx == nullptr || w == nullptr || dy == nullptr)
     {
@@ -1966,16 +2503,45 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
         y_stride(3, 1), hx_size(3, 1), hx_stride(3, 1);
     miopen::TensorDescriptor sp_desc, x_desc, y_desc, hx_desc;
 
+    sp_size[2] = workSpaceSize / GetTypeSize(wDesc.GetType());
+    sp_stride[0] = sp_size[2];
+    sp_stride[1] = sp_size[2];
+    sp_desc = miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+    SetTensor(handle, sp_desc, workSpace, &beta);
+    // Update time
+    profileRNNkernels(handle, 0, ctime);
+
     sp_stride[0] = batch_n * hy_stride;
     sp_stride[1] = hy_stride;
+    sp_size[2] = 1;
     x_stride[0]  = batch_n * in_stride;
     x_stride[1]  = in_stride;
     y_stride[0]  = batch_n * out_stride;
     y_stride[1]  = out_stride;
+    if(dhx != nullptr || (rnnMode == miopenLSTM && dcx != nullptr))
+    {
+        hx_size[2] = hy_d * hy_n * hy_h;
+        hx_stride[0] = hx_size[2];
+        hx_stride[1] = hx_size[2];
+        hx_desc = miopen::TensorDescriptor(wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+        if(dhx != nullptr)
+        {
+            SetTensor(handle, hx_desc, dhx, &beta);
+            // Update time
+            //profileRNNkernels(handle, 1, ctime);
+        }
+        if(rnnMode == miopenLSTM && dcx != nullptr)
+        {
+            SetTensor(handle, hx_desc, dcx, &beta);
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+        }
+    }
+
     hx_stride[0] = in_n[0] * uni_stride;
     hx_stride[1] = uni_stride;
 
-#if MIOPEN_USE_MIOPENGEMM
+#if MIOPEN_USE_ROCBLAS
 
     int prelayer_shift, pretime_shift, cur_time, cur_batch;
     int wei_len    = 0;
@@ -2021,7 +2587,7 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
         activDesc = {miopenActivationTANH, 1, 1, 1};
     }
 
-    for(int li = nLayers - 1; li >= 0; li--)
+    for(int li = static_cast<int>(nLayers) - 1; li >= 0; li--)
     {
         int wei_shift     = (in_h + hy_h) * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
         int hid_shift     = li * batch_n * hy_stride;
@@ -2035,42 +2601,58 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
             y_size[2]  = out_h;
             sp_size[1] = batch_n;
             sp_size[2] = hy_h * bi;
-            y_desc     = miopen::TensorDescriptor(miopenFloat, y_size.data(), y_stride.data(), 3);
-            sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
-
-            alpha0 = 1;
-            alpha1 = 0;
-            beta_t = 1;
+            y_desc     = miopen::TensorDescriptor(wDesc.GetType(), y_size.data(), y_stride.data(), 3);
+            sp_desc    = miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
             CopyTensor(handle, y_desc, dy, sp_desc, workSpace, 0, hid_shift + dhd_off);
             // Update time
-            profileRNNkernels(handle, 0, ctime); // start timing
+            profileRNNkernels(handle, 1, ctime); // start timing
         }
         else
         {
             prelayer_shift = (li + 1) * batch_n * hy_stride;
 
-            auto gg = ScanGemmGeometryRNN(handle,
-                                          workSpace,
-                                          w,
-                                          workSpace,
-                                          batch_n,
-                                          hy_h * bi,
-                                          wei_len * bi,
-                                          1,
-                                          1,
-                                          false,
-                                          false,
-                                          false,
-                                          hy_stride,
-                                          bi_stride,
-                                          hy_stride,
-                                          false,
-                                          network_config,
-                                          MIO_RNN_FINDSOL_TIMEOUT);
-            gg.RunGemm(
-                handle, workSpace, w, workSpace, prelayer_shift, wei_shift, hid_shift + dhd_off);
-
+            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                              false,
+                                                              false,
+                                                              batch_n,
+                                                              hy_h * bi,
+                                                              wei_len * bi,
+                                                              hy_stride,
+                                                              bi_stride,
+                                                              hy_stride,
+                                                              1,
+                                                              0,
+                                                              0,
+                                                              0,
+                                                              1,
+                                                              1,
+                                                              yDesc[0].GetType()};
+
+            miopenStatus_t gemm_status = CallGemm(handle,
+                                                  gemm_desc,
+                                                  workSpace,
+                                                  prelayer_shift,
+                                                  w,
+                                                  wei_shift,
+                                                  workSpace,
+                                                  hid_shift + dhd_off,
+                                                  nullptr,
+                                                  false,
+                                                  GemmBackend_t::rocblas);
+
+
+            if(gemm_status != miopenStatusSuccess)
+            {
+                if(gemm_status == miopenStatusNotImplemented)
+                {
+                    MIOPEN_LOG_E("GEMM not implemented");
+                }
+                else
+                {
+                    MIOPEN_LOG_E("GEMM failed");
+                }
+            }
             // Update time
             profileRNNkernels(handle, 1, ctime);
         }
@@ -2101,195 +2683,195 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
 
                 if(in_n[cur_time] > 0)
                 {
-                    alpha0 = 1;
-                    alpha1 = 0;
-                    beta_t = 1;
-
                     if(ti == seqLen - 1)
                     {
-                        hx_size[1] = in_n[cur_time];
-                        hx_size[2] = hy_h;
-                        sp_size[1] = in_n[cur_time];
-                        sp_size[2] = hy_h;
-                        hx_desc    = miopen::TensorDescriptor(
-                            miopenFloat, hx_size.data(), hx_stride.data(), 3);
-                        sp_desc = miopen::TensorDescriptor(
-                            miopenFloat, sp_size.data(), sp_stride.data(), 3);
-
-                        OpTensor(handle,
-                                 miopenTensorOpAdd,
-                                 &alpha0,
-                                 hx_desc,
-                                 dhy,
-                                 &alpha1,
-                                 hx_desc,
-                                 dhy,
-                                 &beta_t,
-                                 sp_desc,
-                                 workSpace,
-                                 hx_shift + ri * hy_n * hy_h,
-                                 hx_shift + ri * hy_n * hy_h,
-                                 offset + dhd_off + ri * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-                    }
-                    else
-                    {
-                        pretime_shift =
-                            li * batch_n * hy_stride + pre_batch * hy_stride + ri * wei_len;
-
-                        if(rnnMode == miopenRNNRELU || rnnMode == miopenRNNTANH)
+                        if(dhy != nullptr)
                         {
+                            alpha0 = 1;
+                            alpha1 = 1;
+                            beta_t = 0;
+
                             hx_size[1] = in_n[cur_time];
                             hx_size[2] = hy_h;
                             sp_size[1] = in_n[cur_time];
                             sp_size[2] = hy_h;
                             hx_desc    = miopen::TensorDescriptor(
-                                miopenFloat, hx_size.data(), hx_stride.data(), 3);
+                                wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
                             sp_desc = miopen::TensorDescriptor(
-                                miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
                             OpTensor(handle,
                                      miopenTensorOpAdd,
                                      &alpha0,
                                      hx_desc,
-                                     dhx,
+                                     dhy,
                                      &alpha1,
-                                     hx_desc,
-                                     dhx,
+                                     sp_desc,
+                                     workSpace,
                                      &beta_t,
                                      sp_desc,
                                      workSpace,
                                      hx_shift + ri * hy_n * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + ri * hy_h);
+                                     offset + dhd_off + ri * hy_h,
+                                     offset + dhd_off + ri * hy_h);
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
                         }
-                        else if(rnnMode == miopenLSTM || rnnMode == miopenGRU)
-                        {
-                            if(in_n[use_time] > 0)
-                            {
 
-                                auto gg = ScanGemmGeometryRNN(handle,
-                                                              workSpace,
-                                                              w,
-                                                              workSpace,
-                                                              in_n.at(use_time),
-                                                              hy_h,
-                                                              wei_len_t,
-                                                              1,
-                                                              1,
-                                                              false,
-                                                              false,
-                                                              false,
-                                                              hy_stride,
-                                                              uni_stride,
-                                                              hy_stride,
-                                                              false,
-                                                              network_config,
-                                                              MIO_RNN_FINDSOL_TIMEOUT);
+                    }
+                    else
+                    {
+                        if(ri == 0 && dhy != nullptr && in_n[cur_time] > in_n[use_time])
+                        {
+                            alpha0 = 1;
+                            alpha1 = 1;
+                            beta_t = 1;
 
-                                gg.RunGemm(handle,
-                                           workSpace,
-                                           w,
-                                           workSpace,
-                                           pretime_shift,
-                                           weitime_shift + ri * wei_len * uni_stride,
-                                           offset + dhd_off + ri * hy_h);
+                            hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                            hx_size[2] = hy_h;
+                            sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                            sp_size[2] = hy_h;
+                            hx_desc    = miopen::TensorDescriptor(
+                                wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+                            sp_desc = miopen::TensorDescriptor(
+                                wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
-                                // Update time
-                                profileRNNkernels(handle, 1, ctime);
+                            OpTensor(handle,
+                                     miopenTensorOpAdd,
+                                     &alpha0,
+                                     hx_desc,
+                                     dhy,
+                                     &alpha1,
+                                     sp_desc,
+                                     workSpace,
+                                     &beta_t,
+                                     sp_desc,
+                                     workSpace,
+                                     hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                     offset + dhd_off + ri * hy_h + in_n.at(use_time) * hy_stride,
+                                     offset + dhd_off + ri * hy_h + in_n.at(use_time) * hy_stride);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
 
-                                if(rnnMode == miopenGRU)
-                                {
-                                    sp_size[1] = in_n[use_time];
-                                    sp_size[2] = hy_h;
-                                    sp_desc    = miopen::TensorDescriptor(
-                                        miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                        pretime_shift =
+                            li * batch_n * hy_stride + pre_batch * hy_stride + ri * wei_len;
 
-                                    alpha0 = 1;
-                                    alpha1 = 1;
-                                    beta_t = 1;
+                        if(in_n.at(use_time) > 0)
+                        {
+                            if(rnnMode == miopenGRU)
+                            {
+                                sp_size[1] = in_n.at(use_time);
+                                sp_size[2] = hy_h;
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
-                                    OpTensor(handle,
-                                             miopenTensorOpMul,
-                                             &alpha0,
-                                             sp_desc,
-                                             workSpace,
-                                             &alpha1,
-                                             sp_desc,
-                                             reserveSpace,
-                                             &beta_t,
-                                             sp_desc,
-                                             workSpace,
-                                             pretime_shift + bi * 3 * hy_h - ri * 2 * hy_h,
-                                             pretime_shift + nLayers * batch_n * hy_stride,
-                                             offset + bi * 3 * hy_h + ri * hy_h);
-                                    // Update time
-                                    profileRNNkernels(handle, 1, ctime);
+                                alpha0 = 1;
+                                alpha1 = 1;
+                                beta_t = 1;
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         pretime_shift - ri * 2 * hy_h + dhd_off,
+                                         pretime_shift + nLayers * batch_n * hy_stride,
+                                         offset + dhd_off + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
 
-                                    alpha0 = 1;
-                                    alpha1 = 1;
-                                    beta_t = 0;
+                                CopyTensor(handle,
+                                           sp_desc,
+                                           workSpace,
+                                           sp_desc,
+                                           workSpace,
+                                           pretime_shift + 2 * hy_h,
+                                           static_cast<int>(offset) + ri * wei_len + 2 * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
 
-                                    OpTensor(handle,
-                                             miopenTensorOpMul,
-                                             &alpha0,
-                                             sp_desc,
-                                             workSpace,
-                                             &alpha1,
-                                             sp_desc,
-                                             reserveSpace,
-                                             &beta_t,
-                                             sp_desc,
-                                             workSpace,
-                                             pretime_shift + 2 * hy_h,
-                                             pretime_shift + hy_h + nLayers * batch_n * hy_stride,
-                                             offset + 2 * hy_h + ri * 3 * hy_h);
-                                    // Update time
-                                    profileRNNkernels(handle, 1, ctime);
+                                CopyTensor(handle,
+                                           sp_desc,
+                                           reserveSpace,
+                                           sp_desc,
+                                           workSpace,
+                                           pretime_shift - ri * 2 * hy_h + dhd_off +
+                                               static_cast<int>(nLayers) * batch_n * hy_stride,
+                                           pretime_shift + 2 * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
+                            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                              false,
+                                                                              false,
+                                                                              in_n.at(use_time),
+                                                                              hy_h,
+                                                                              wei_len,
+                                                                              hy_stride,
+                                                                              uni_stride,
+                                                                              hy_stride,
+                                                                              1, // batch count
+                                                                              0, // Stride A
+                                                                              0, // Stride B
+                                                                              0, // Stride C
+                                                                              1, // alpha
+                                                                              1, // beta
+                                                                              yDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         workSpace,
+                                         pretime_shift,
+                                         w,
+                                         weitime_shift + ri * wei_len * uni_stride,
+                                         workSpace,
+                                         static_cast<int>(offset) + dhd_off + ri * hy_h,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
 
-                                    auto gg2 = ScanGemmGeometryRNN(handle,
-                                                                   workSpace,
-                                                                   w,
-                                                                   workSpace,
-                                                                   in_n.at(use_time),
-                                                                   hy_h,
-                                                                   hy_h,
-                                                                   1,
-                                                                   1,
-                                                                   false,
-                                                                   false,
-                                                                   false,
-                                                                   hy_stride,
-                                                                   uni_stride,
-                                                                   hy_stride,
-                                                                   false,
-                                                                   network_config,
-                                                                   MIO_RNN_FINDSOL_TIMEOUT);
-
-                                    gg2.RunGemm(handle,
-                                                workSpace,
-                                                w,
-                                                workSpace,
-                                                offset + 2 * hy_h + ri * 3 * hy_h,
-                                                weitime_shift + 2 * hy_h * uni_stride +
-                                                    ri * 3 * hy_h * uni_stride,
-                                                offset + bi * 3 * hy_h + ri * hy_h);
-
-                                    // Update time
-                                    profileRNNkernels(handle, 1, ctime);
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                if(gemm_status == miopenStatusNotImplemented)
+                                {
+                                    MIOPEN_LOG_E("GEMM not implemented");
                                 }
+                                else
+                                {
+                                    MIOPEN_LOG_E("GEMM failed");
+                                }
+                            }
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+
+                            if(rnnMode == miopenGRU)
+                            {
+                                CopyTensor(handle,
+                                           sp_desc,
+                                           workSpace,
+                                           sp_desc,
+                                           workSpace,
+                                           static_cast<int>(offset) + ri * wei_len + 2 * hy_h,
+                                           pretime_shift + 2 * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
                             }
                         }
                     }
 
                     // update hidden status
-                    sp_size[1] = in_n[cur_time];
+                    sp_size[1] = in_n.at(cur_time);
                     sp_size[2] = hy_h;
-                    sp_desc =
-                        miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                    sp_desc    = miopen::TensorDescriptor(
+                        wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
                     if(rnnMode == miopenRNNRELU || rnnMode == miopenRNNTANH)
                     {
@@ -2305,69 +2887,20 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                            &beta,
                                            sp_desc,
                                            workSpace,
-                                           offset + ri * hy_h + nLayers * batch_n * hy_stride,
-                                           offset + ri * hy_h,
-                                           offset + ri * hy_h,
-                                           offset + ri * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      workSpace,
-                                                      w,
-                                                      dhx,
-                                                      in_n.at(cur_time),
-                                                      hy_h,
-                                                      hy_h,
-                                                      1,
-                                                      0,
-                                                      false,
-                                                      false,
-                                                      false,
-                                                      hy_stride,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   workSpace,
-                                   w,
-                                   dhx,
-                                   offset + ri * hy_h,
-                                   weitime_shift + ri * wei_len * uni_stride,
-                                   hx_shift + ri * hy_n * hy_h);
-
+                                           offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                           offset + ri * wei_len,
+                                           offset + ri * wei_len,
+                                           offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
                     }
                     else if(rnnMode == miopenLSTM)
                     {
-                        // update cell state
-                        tanhDesc.Backward(handle,
-                                          &alpha,
-                                          sp_desc,
-                                          reserveSpace,
-                                          sp_desc,
-                                          workSpace,
-                                          sp_desc,
-                                          reserveSpace,
-                                          &beta,
-                                          sp_desc,
-                                          workSpace,
-                                          offset + bi * 4 * hy_h + ri * hy_h +
-                                              nLayers * batch_n * hy_stride,
-                                          offset + bi * 5 * hy_h + ri * hy_h,
-                                          offset + bi * 4 * hy_h + ri * hy_h,
-                                          offset + bi * 4 * hy_h + ri * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-
                         alpha0 = 1;
                         alpha1 = 1;
                         beta_t = 0;
 
+                        // update cell state
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
@@ -2379,57 +2912,106 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + bi * 4 * hy_h + ri * hy_h,
-                                 offset + 2 * hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + bi * 4 * hy_h + ri * hy_h);
+                                 offset + dhd_off + ri * hy_h,
+                                 offset + 2 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + bi * wei_len + ri * hy_h);
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+
+                        tanhDesc.Backward(handle,
+                                          &alpha,
+                                          sp_desc,
+                                          reserveSpace,
+                                          sp_desc,
+                                          workSpace,
+                                          sp_desc,
+                                          reserveSpace,
+                                          &beta,
+                                          sp_desc,
+                                          workSpace,
+                                          offset + bi * 4 * wei_len + ri * hy_h +
+                                              nLayers * batch_n * hy_stride,
+                                          offset + bi * 5 * wei_len + ri * hy_h,
+                                          offset + bi * 4 * wei_len + ri * hy_h,
+                                          offset + bi * 4 * wei_len + ri * hy_h);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         if(ti == seqLen - 1)
                         {
-                            alpha0 = 1;
-                            alpha1 = 0;
-                            beta_t = 1;
-
-                            hx_size[1] = in_n[cur_time];
-                            hx_size[2] = hy_h;
-                            sp_size[1] = in_n[cur_time];
-                            sp_size[2] = hy_h;
-                            hx_desc    = miopen::TensorDescriptor(
-                                miopenFloat, hx_size.data(), hx_stride.data(), 3);
-                            sp_desc = miopen::TensorDescriptor(
-                                miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                            if(dcy != nullptr)
+                            {
+                                hx_size[1] = in_n[cur_time];
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    miopenFloat, hx_size.data(), hx_stride.data(), 3);
 
-                            OpTensor(handle,
-                                     miopenTensorOpAdd,
-                                     &alpha0,
-                                     hx_desc,
-                                     dcy,
-                                     &alpha1,
-                                     hx_desc,
-                                     dcy,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
+                                OpTensor(handle,
+                                         miopenTensorOpAdd,
+                                         &alpha0,
+                                         hx_desc,
+                                         dcy,
+                                         &alpha1,
+                                         sp_desc,
+                                         workSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + bi * 4 * hy_h + ri * hy_h,
+                                         offset + bi * 4 * hy_h + ri * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
+                            if(ri == 0 && dcy != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                hx_size[2] = hy_h;
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time);
+                                sp_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+                                sp_desc = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+                                OpTensor(handle,
+                                         miopenTensorOpAdd,
+                                         &alpha0,
+                                         hx_desc,
+                                         dcy,
+                                         &alpha1,
+                                         sp_desc,
+                                         workSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                         offset + bi * wei_len + ri * hy_h +
+                                             in_n.at(use_time) * hy_stride,
+                                         offset + bi * wei_len + ri * hy_h +
+                                             in_n.at(use_time) * hy_stride);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                            }
+
                             pretime_shift = li * batch_n * hy_stride + pre_batch * hy_stride;
+                            alpha0 = 1;
+                            alpha1 = 1;
+                            beta_t = 1;
+
 
                             sp_size[1] = in_n[use_time];
                             sp_size[2] = hy_h;
                             sp_desc    = miopen::TensorDescriptor(
                                 miopenFloat, sp_size.data(), sp_stride.data(), 3);
 
-                            alpha0 = 1;
-                            alpha1 = 1;
-                            beta_t = 1;
-
                             OpTensor(handle,
                                      miopenTensorOpMul,
                                      &alpha0,
@@ -2441,101 +3023,63 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                      &beta_t,
                                      sp_desc,
                                      workSpace,
-                                     pretime_shift + bi * 4 * hy_h + ri * hy_h,
-                                     pretime_shift + hy_h + ri * 4 * hy_h +
+                                     pretime_shift + bi * wei_len + ri * hy_h,
+                                     pretime_shift + hy_h + ri * wei_len +
                                          nLayers * batch_n * hy_stride,
-                                     offset + bi * 4 * hy_h + ri * hy_h);
+                                     offset + bi * wei_len + ri * hy_h);
                             // Update time
                             profileRNNkernels(handle, 1, ctime);
+
+                            if(in_n[cur_time] != in_n[use_time])
+                            {
+                                sp_size[1] = in_n[cur_time];
+                                sp_desc = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                            }
                         }
 
                         // update forget gate
-                        sp_size[1] = in_n[cur_time];
-                        sp_size[2] = hy_h;
-                        sp_desc    = miopen::TensorDescriptor(
-                            miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                        alpha0 = 1;
+                        alpha1 = 1;
+                        beta_t = 0;
 
                         if(ti == 0)
                         {
-                            sigDesc.Backward(handle,
-                                             &alpha,
-                                             sp_desc,
-                                             reserveSpace,
-                                             sp_desc,
-                                             workSpace,
-                                             sp_desc,
-                                             reserveSpace,
-                                             &beta,
-                                             sp_desc,
-                                             workSpace,
-                                             offset + hy_h + ri * 4 * hy_h +
-                                                 nLayers * batch_n * hy_stride,
-                                             offset + bi * 4 * hy_h + ri * hy_h,
-                                             offset + hy_h + ri * 4 * hy_h,
-                                             offset + hy_h + ri * 4 * hy_h);
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
-
-                            hx_size[1] = in_n[cur_time];
-                            hx_size[2] = hy_h;
-                            hx_desc    = miopen::TensorDescriptor(
-                                miopenFloat, hx_size.data(), hx_stride.data(), 3);
-
-                            alpha0 = 1;
-                            alpha1 = 1;
-                            beta_t = 0;
-
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     hx_desc,
-                                     cx,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + hy_h + ri * 4 * hy_h,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + hy_h + ri * 4 * hy_h);
+                            if(cx != nullptr)
+                            {
+                                hx_size[1] = in_n[cur_time];
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
 
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         hx_desc,
+                                         cx,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + bi * wei_len + ri * hy_h,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + hy_h + ri * wei_len);
+                            }
                         }
                         else
                         {
-                            if(in_n[use_time2] > 0)
+                            if(ri == 1 && cx != nullptr && in_n.at(cur_time) > in_n.at(use_time2))
                             {
-                                pretime_shift = li * batch_n * hy_stride + pre_batch2 * hy_stride;
-
-                                sp_size[1] = in_n[use_time2];
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time2);
+                                hx_size[2] = hy_h;
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time2);
                                 sp_size[2] = hy_h;
-                                sp_desc    = miopen::TensorDescriptor(
-                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
-
-                                alpha0 = 1;
-                                alpha1 = 1;
-                                beta_t = 0;
-
-                                sigDesc.Backward(handle,
-                                                 &alpha,
-                                                 sp_desc,
-                                                 reserveSpace,
-                                                 sp_desc,
-                                                 workSpace,
-                                                 sp_desc,
-                                                 reserveSpace,
-                                                 &beta,
-                                                 sp_desc,
-                                                 workSpace,
-                                                 offset + hy_h + ri * 4 * hy_h +
-                                                     nLayers * batch_n * hy_stride,
-                                                 offset + bi * 4 * hy_h + ri * hy_h,
-                                                 offset + hy_h + ri * 4 * hy_h,
-                                                 offset + hy_h + ri * 4 * hy_h);
-                                // Update time
-                                profileRNNkernels(handle, 1, ctime);
+                                hx_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+                                sp_desc = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
                                 OpTensor(handle,
                                          miopenTensorOpMul,
@@ -2543,47 +3087,60 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                          sp_desc,
                                          workSpace,
                                          &alpha1,
-                                         sp_desc,
-                                         reserveSpace,
+                                         hx_desc,
+                                         cx,
                                          &beta_t,
                                          sp_desc,
                                          workSpace,
-                                         offset + hy_h + ri * 4 * hy_h,
-                                         pretime_shift + bi * 4 * hy_h + ri * hy_h,
-                                         offset + hy_h + ri * 4 * hy_h);
-                                // Update time
-                                profileRNNkernels(handle, 1, ctime);
+                                         offset + bi * wei_len + ri * hy_h +
+                                             in_n.at(use_time2) * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time2) * hy_h,
+                                         offset + hy_h + ri * wei_len +
+                                             in_n.at(use_time2) * hy_stride);
+
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
                             }
-                        }
 
-                        // update input gate
-                        sp_size[1] = in_n[cur_time];
-                        sp_size[2] = hy_h;
-                        sp_desc    = miopen::TensorDescriptor(
-                            miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                            if(in_n[use_time2] > 0)
+                            {
+                                pretime_shift = li * batch_n * hy_stride + pre_batch2 * hy_stride;
 
-                        sigDesc.Backward(handle,
-                                         &alpha,
-                                         sp_desc,
-                                         reserveSpace,
+                                if(in_n[cur_time] != in_n[use_time2])
+                                {
+                                    sp_size[1] = in_n[use_time2];
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                                }
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
                                          sp_desc,
                                          workSpace,
+                                         &alpha1,
                                          sp_desc,
                                          reserveSpace,
-                                         &beta,
+                                         &beta_t,
                                          sp_desc,
                                          workSpace,
-                                         offset + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                         offset + bi * 4 * hy_h + ri * hy_h,
-                                         offset + ri * 4 * hy_h,
-                                         offset + ri * 4 * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                                         offset + bi * wei_len + ri * hy_h,
+                                         pretime_shift + bi * wei_len + ri * hy_h,
+                                         offset + hy_h + ri * wei_len);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
 
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 0;
+                                if(in_n[cur_time] != in_n[use_time2])
+                                {
+                                    sp_size[1] = in_n[cur_time];
+                                    sp_desc = miopen::TensorDescriptor(
+                                        wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                                }
+                            }
+                        }
 
+                        // update input gate
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
@@ -2595,36 +3152,31 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + ri * 4 * hy_h,
-                                 offset + 3 * hy_h + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + ri * 4 * hy_h);
+                                 offset + bi * wei_len + ri * hy_h,
+                                 offset + 3 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         // update output gate
-                        sigDesc.Backward(handle,
-                                         &alpha,
-                                         sp_desc,
-                                         reserveSpace,
-                                         sp_desc,
-                                         workSpace,
-                                         sp_desc,
-                                         reserveSpace,
-                                         &beta,
-                                         sp_desc,
-                                         workSpace,
-                                         offset + 2 * hy_h + ri * 4 * hy_h +
-                                             nLayers * batch_n * hy_stride,
-                                         offset + bi * 5 * hy_h + ri * hy_h,
-                                         offset + 2 * hy_h + ri * 4 * hy_h,
-                                         offset + 2 * hy_h + ri * 4 * hy_h);
+                        OpTensor(handle,
+                                 miopenTensorOpMul,
+                                 &alpha0,
+                                 sp_desc,
+                                 workSpace,
+                                 &alpha1,
+                                 sp_desc,
+                                 reserveSpace,
+                                 &beta_t,
+                                 sp_desc,
+                                 workSpace,
+                                 offset + dhd_off + ri * hy_h,
+                                 offset + bi * wei_len + ri * hy_h + nLayers * batch_n * hy_stride,
+                                 offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 0;
-
+                        // update c gate
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
@@ -2636,13 +3188,12 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + 2 * hy_h + ri * 4 * hy_h,
-                                 offset + bi * 4 * hy_h + ri * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + 2 * hy_h + ri * 4 * hy_h);
+                                 offset + bi * wei_len + ri * hy_h,
+                                 offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + 3 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        // update c gate
                         tanhDesc.Backward(handle,
                                           &alpha,
                                           sp_desc,
@@ -2654,32 +3205,33 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                           &beta,
                                           sp_desc,
                                           workSpace,
-                                          offset + 3 * hy_h + ri * 4 * hy_h +
+                                          offset + 3 * hy_h + ri * wei_len +
                                               nLayers * batch_n * hy_stride,
-                                          offset + bi * 4 * hy_h + ri * hy_h,
-                                          offset + 3 * hy_h + ri * 4 * hy_h,
-                                          offset + 3 * hy_h + ri * 4 * hy_h);
+                                          offset + 3 * hy_h + ri * wei_len,
+                                          offset + 3 * hy_h + ri * wei_len,
+                                          offset + 3 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 0;
+                        sp_size[2] = 3 * hy_h;
+                        sp_desc    = miopen::TensorDescriptor(
+                            wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
-                        OpTensor(handle,
-                                 miopenTensorOpMul,
-                                 &alpha0,
-                                 sp_desc,
-                                 workSpace,
-                                 &alpha1,
-                                 sp_desc,
-                                 reserveSpace,
-                                 &beta_t,
-                                 sp_desc,
-                                 workSpace,
-                                 offset + 3 * hy_h + ri * 4 * hy_h,
-                                 offset + ri * 4 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + 3 * hy_h + ri * 4 * hy_h);
+                        sigDesc.Backward(handle,
+                                         &alpha,
+                                         sp_desc,
+                                         reserveSpace,
+                                         sp_desc,
+                                         workSpace,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                         offset + ri * wei_len,
+                                         offset + ri * wei_len,
+                                         offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
                     }
@@ -2701,15 +3253,15 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 offset + 2 * hy_h + ri * 3 * hy_h);
+                                 offset + dhd_off + ri * hy_h,
+                                 offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         alpha0 = 1;
-                        alpha1 = 0;
-                        beta_t = 1;
+                        alpha1 = 1;
+                        beta_t = 0;
 
                         OpTensor(handle,
                                  miopenTensorOpAdd,
@@ -2722,9 +3274,9 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + bi * 3 * hy_h + ri * hy_h,
-                                 offset + 2 * hy_h + ri * 3 * hy_h);
+                                 offset + dhd_off + ri * hy_h,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
@@ -2739,92 +3291,15 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                           &beta,
                                           sp_desc,
                                           workSpace,
-                                          offset + 2 * hy_h + ri * 3 * hy_h +
+                                          offset + 2 * hy_h + ri * wei_len +
                                               nLayers * batch_n * hy_stride,
-                                          offset + 2 * hy_h + ri * 3 * hy_h,
-                                          offset + 2 * hy_h + ri * 3 * hy_h,
-                                          offset + 2 * hy_h + ri * 3 * hy_h);
+                                          offset + 2 * hy_h + ri * wei_len,
+                                          offset + 2 * hy_h + ri * wei_len,
+                                          offset + 2 * hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         // r gate
-                        if(ti == 0)
-                        {
-
-                            auto gg = ScanGemmGeometryRNN(handle,
-                                                          hx,
-                                                          w,
-                                                          workSpace,
-                                                          in_n.at(cur_time),
-                                                          hy_h,
-                                                          hy_h,
-                                                          1,
-                                                          1,
-                                                          false,
-                                                          true,
-                                                          false,
-                                                          uni_stride,
-                                                          uni_stride,
-                                                          hy_stride,
-                                                          false,
-                                                          network_config,
-                                                          MIO_RNN_FINDSOL_TIMEOUT);
-
-                            gg.RunGemm(handle,
-                                       hx,
-                                       w,
-                                       workSpace,
-                                       hx_shift + ri * hy_n * hy_h,
-                                       weitime_shift + 2 * hy_h * uni_stride +
-                                           ri * 3 * hy_h * uni_stride,
-                                       offset + hy_h + ri * 3 * hy_h);
-
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
-                        }
-                        else
-                        {
-                            if(in_n[use_time2] > 0)
-                            {
-
-                                auto gg = ScanGemmGeometryRNN(handle,
-                                                              reserveSpace,
-                                                              w,
-                                                              workSpace,
-                                                              in_n.at(use_time2),
-                                                              hy_h,
-                                                              hy_h,
-                                                              1,
-                                                              1,
-                                                              false,
-                                                              true,
-                                                              false,
-                                                              hy_stride,
-                                                              uni_stride,
-                                                              hy_stride,
-                                                              false,
-                                                              network_config,
-                                                              MIO_RNN_FINDSOL_TIMEOUT);
-
-                                gg.RunGemm(handle,
-                                           reserveSpace,
-                                           w,
-                                           workSpace,
-                                           hid_shift + pre_batch2 * hy_stride + bi * 3 * hy_h +
-                                               ri * hy_h,
-                                           weitime_shift + 2 * hy_h * uni_stride +
-                                               ri * 3 * hy_h * uni_stride,
-                                           offset + hy_h + ri * 3 * hy_h);
-
-                                // Update time
-                                profileRNNkernels(handle, 1, ctime);
-                            }
-                        }
-
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 0;
-
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
@@ -2832,365 +3307,385 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                                  workSpace,
                                  &alpha1,
                                  sp_desc,
-                                 workSpace,
+                                 reserveSpace,
                                  &beta_t,
                                  sp_desc,
                                  workSpace,
-                                 offset + 2 * hy_h + ri * 3 * hy_h,
-                                 offset + hy_h + ri * 3 * hy_h,
-                                 offset + hy_h + ri * 3 * hy_h);
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + dhd_off + ri * hy_h + nLayers * batch_n * hy_stride,
+                                 offset + hy_h + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        sigDesc.Backward(handle,
-                                         &alpha,
-                                         sp_desc,
-                                         reserveSpace,
-                                         sp_desc,
-                                         workSpace,
-                                         sp_desc,
-                                         reserveSpace,
-                                         &beta,
-                                         sp_desc,
-                                         workSpace,
-                                         offset + hy_h + ri * 3 * hy_h +
-                                             nLayers * batch_n * hy_stride,
-                                         offset + hy_h + ri * 3 * hy_h,
-                                         offset + hy_h + ri * 3 * hy_h,
-                                         offset + hy_h + ri * 3 * hy_h);
+                        OpTensor(handle,
+                                 miopenTensorOpMul,
+                                 &alpha0,
+                                 sp_desc,
+                                 workSpace,
+                                 &alpha1,
+                                 sp_desc,
+                                 reserveSpace,
+                                 &beta_t,
+                                 sp_desc,
+                                 reserveSpace,
+                                 offset + 2 * hy_h + ri * wei_len,
+                                 offset + hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + dhd_off + ri * hy_h + nLayers * batch_n * hy_stride);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
                         // z gate
-                        alpha0 = 1;
-                        alpha1 = -1;
-                        beta_t = 0;
-
                         if(ti == 0)
                         {
-                            hx_size[1] = in_n[cur_time];
-                            hx_size[2] = hy_h;
-                            hx_desc    = miopen::TensorDescriptor(
-                                miopenFloat, hx_size.data(), hx_stride.data(), 3);
-
-                            OpTensor(handle,
-                                     miopenTensorOpAdd,
-                                     &alpha0,
-                                     hx_desc,
-                                     hx,
-                                     &alpha1,
-                                     sp_desc,
-                                     reserveSpace,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     hx_shift + ri * hy_n * hy_h,
-                                     offset + 2 * hy_h + ri * 3 * hy_h +
-                                         nLayers * batch_n * hy_stride,
-                                     offset + ri * 3 * hy_h);
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
-
-                            alpha0 = 1;
-                            alpha1 = 1;
-                            beta_t = 0;
-
-                            OpTensor(handle,
-                                     miopenTensorOpMul,
-                                     &alpha0,
-                                     sp_desc,
-                                     workSpace,
-                                     &alpha1,
-                                     sp_desc,
-                                     workSpace,
-                                     &beta_t,
-                                     sp_desc,
-                                     workSpace,
-                                     offset + bi * 3 * hy_h + ri * hy_h,
-                                     offset + ri * 3 * hy_h,
-                                     offset + ri * 3 * hy_h);
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
+                            if(hx != nullptr)
+                            {
+                                hx_size[1] = in_n.at(cur_time);
+                                hx_size[2] = hy_h;
+                                hx_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
 
-                            sigDesc.Backward(handle,
-                                             &alpha,
-                                             sp_desc,
-                                             reserveSpace,
-                                             sp_desc,
-                                             workSpace,
-                                             sp_desc,
-                                             reserveSpace,
-                                             &beta,
-                                             sp_desc,
-                                             workSpace,
-                                             offset + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                             offset + ri * 3 * hy_h,
-                                             offset + ri * 3 * hy_h,
-                                             offset + ri * 3 * hy_h);
-                            // Update time
-                            profileRNNkernels(handle, 1, ctime);
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         hx_desc,
+                                         hx,
+                                         &alpha1,
+                                         sp_desc,
+                                         workSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         workSpace,
+                                         hx_shift + ri * hy_n * hy_h,
+                                         offset + dhd_off + ri * hy_h,
+                                         offset + ri * wei_len);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
                         }
                         else
                         {
-                            if(in_n[use_time2] > 0)
+                            if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time2))
                             {
-                                sp_size[1] = in_n[use_time2];
-                                sp_size[2] = hy_h;
-                                sp_desc    = miopen::TensorDescriptor(
-                                    miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                                hx_size[1] = in_n.at(cur_time) - in_n.at(use_time2);
+                                hx_size[2] = hy_h;
+                                sp_size[1] = in_n.at(cur_time) - in_n.at(use_time2);
+                                hx_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+                                sp_desc = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
                                 OpTensor(handle,
-                                         miopenTensorOpAdd,
+                                         miopenTensorOpMul,
                                          &alpha0,
-                                         sp_desc,
-                                         reserveSpace,
+                                         hx_desc,
+                                         hx,
                                          &alpha1,
                                          sp_desc,
-                                         reserveSpace,
+                                         workSpace,
                                          &beta_t,
                                          sp_desc,
                                          workSpace,
-                                         hid_shift + pre_batch2 * hy_stride + bi * 3 * hy_h +
-                                             ri * hy_h,
-                                         offset + 2 * hy_h + ri * 3 * hy_h +
-                                             nLayers * batch_n * hy_stride,
-                                         offset + ri * 3 * hy_h);
+                                         hx_shift + ri * hy_n * hy_h + in_n.at(use_time2) * hy_h,
+                                         offset + dhd_off + ri * hy_h +
+                                             in_n.at(use_time2) * hy_stride,
+                                         offset + ri * wei_len + in_n.at(use_time2) * hy_stride);
                                 // Update time
                                 profileRNNkernels(handle, 1, ctime);
 
-                                alpha0 = 1;
-                                alpha1 = 1;
-                                beta_t = 0;
+                                sp_size[1] = in_n.at(cur_time);
+                                sp_desc    = miopen::TensorDescriptor(
+                                    wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                            }
+
+                            if(in_n[use_time2] > 0)
+                            {
+                                if(in_n.at(use_time2) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(use_time2);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                                }
 
                                 OpTensor(handle,
                                          miopenTensorOpMul,
                                          &alpha0,
                                          sp_desc,
-                                         workSpace,
+                                         reserveSpace,
                                          &alpha1,
                                          sp_desc,
                                          workSpace,
                                          &beta_t,
                                          sp_desc,
                                          workSpace,
-                                         offset + bi * 3 * hy_h + ri * hy_h,
-                                         offset + ri * 3 * hy_h,
-                                         offset + ri * 3 * hy_h);
+                                         hid_shift + pre_batch2 * hy_stride + dhd_off + ri * hy_h,
+                                         offset + dhd_off + ri * hy_h,
+                                         offset + ri * wei_len);
                                 // Update time
                                 profileRNNkernels(handle, 1, ctime);
 
-                                sigDesc.Backward(handle,
-                                                 &alpha,
-                                                 sp_desc,
-                                                 reserveSpace,
-                                                 sp_desc,
-                                                 workSpace,
-                                                 sp_desc,
-                                                 reserveSpace,
-                                                 &beta,
-                                                 sp_desc,
-                                                 workSpace,
-                                                 offset + ri * 3 * hy_h +
-                                                     nLayers * batch_n * hy_stride,
-                                                 offset + ri * 3 * hy_h,
-                                                 offset + ri * 3 * hy_h,
-                                                 offset + ri * 3 * hy_h);
-                                // Update time
-                                profileRNNkernels(handle, 1, ctime);
+                                if(in_n.at(use_time2) != in_n.at(cur_time))
+                                {
+                                    sp_size[1] = in_n.at(cur_time);
+                                    sp_desc    = miopen::TensorDescriptor(
+                                        wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                                }
                             }
                         }
-                    }
-                }
-            }
 
-            baccbi += in_n[seqLen - 1 - ti];
-        }
-
-        // dcx, dhx
-        if(rnnMode == miopenLSTM || rnnMode == miopenGRU)
-        {
-            for(int ri = 0; ri < bi; ri++)
-            {
-                cur_time  = ri == 0 ? 0 : seqLen - 1;
-                cur_batch = ri == 0 ? 0 : batch_n - in_n[seqLen - 1];
-
-                if(in_n[cur_time] > 0)
-                {
-                    pretime_shift = li * batch_n * hy_stride + cur_batch * hy_stride;
-
-                    sp_size[1] = in_n[cur_time];
-                    sp_size[2] = hy_h;
-                    hx_size[1] = in_n[cur_time];
-                    hx_size[2] = hy_h;
-                    hx_desc =
-                        miopen::TensorDescriptor(miopenFloat, hx_size.data(), hx_stride.data(), 3);
-                    sp_desc =
-                        miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
-
-                    if(rnnMode == miopenLSTM)
-                    {
-
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      workSpace,
-                                                      w,
-                                                      dhx,
-                                                      in_n.at(cur_time),
-                                                      hy_h,
-                                                      hy_h * 4,
-                                                      1,
-                                                      1,
-                                                      false,
-                                                      false,
-                                                      false,
-                                                      hy_stride,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   workSpace,
-                                   w,
-                                   dhx,
-                                   pretime_shift + ri * 4 * hy_h,
-                                   weitime_shift + ri * 4 * hy_h * uni_stride,
-                                   hx_shift + ri * hy_n * hy_h);
-
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 1;
+                        alpha0 = -1;
+                        alpha1 = 1;
+                        beta_t = 1;
 
                         OpTensor(handle,
                                  miopenTensorOpMul,
                                  &alpha0,
                                  sp_desc,
-                                 workSpace,
-                                 &alpha1,
-                                 sp_desc,
                                  reserveSpace,
-                                 &beta_t,
-                                 hx_desc,
-                                 dcx,
-                                 pretime_shift + bi * 4 * hy_h + ri * hy_h,
-                                 pretime_shift + hy_h + ri * 4 * hy_h +
-                                     nLayers * batch_n * hy_stride,
-                                 hx_shift + ri * hy_n * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
-                    }
-                    else if(rnnMode == miopenGRU)
-                    {
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 0;
-
-                        OpTensor(handle,
-                                 miopenTensorOpMul,
-                                 &alpha0,
-                                 sp_desc,
-                                 workSpace,
                                  &alpha1,
                                  sp_desc,
-                                 reserveSpace,
+                                 workSpace,
                                  &beta_t,
                                  sp_desc,
-                                 reserveSpace,
-                                 pretime_shift + 2 * hy_h + ri * 3 * hy_h,
-                                 pretime_shift + hy_h + ri * 3 * hy_h +
-                                     nLayers * batch_n * hy_stride,
-                                 pretime_shift + bi * 3 * hy_h + ri * hy_h +
-                                     nLayers * batch_n * hy_stride);
+                                 workSpace,
+                                 offset + 2 * hy_h + ri * wei_len + nLayers * batch_n * hy_stride,
+                                 offset + dhd_off + ri * hy_h,
+                                 offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
 
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      reserveSpace,
-                                                      w,
-                                                      dhx,
-                                                      in_n.at(cur_time),
-                                                      hy_h,
-                                                      hy_h,
-                                                      1,
-                                                      0,
-                                                      false,
-                                                      false,
-                                                      false,
-                                                      hy_stride,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg.RunGemm(handle,
-                                   reserveSpace,
-                                   w,
-                                   dhx,
-                                   pretime_shift + bi * 3 * hy_h + ri * hy_h +
-                                       nLayers * batch_n * hy_stride,
-                                   weitime_shift + 2 * hy_h * uni_stride +
-                                       ri * 3 * hy_h * uni_stride,
-                                   hx_shift + ri * hy_n * hy_h);
+                        sp_size[2] = 2 * hy_h;
+                        sp_desc = miopen::TensorDescriptor(
+                            wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
+                        sigDesc.Backward(handle,
+                                         &alpha,
+                                         sp_desc,
+                                         reserveSpace,
+                                         sp_desc,
+                                         workSpace,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta,
+                                         sp_desc,
+                                         workSpace,
+                                         offset + ri * wei_len + nLayers * batch_n * hy_stride,
+                                         offset + ri * wei_len,
+                                         offset + ri * wei_len,
+                                         offset + ri * wei_len);
                         // Update time
                         profileRNNkernels(handle, 1, ctime);
+                    }
+                }
+            }
 
-                        alpha0 = 1;
-                        alpha1 = 1;
-                        beta_t = 1;
+            baccbi += in_n[seqLen - 1 - ti];
+        }
 
-                        OpTensor(handle,
-                                 miopenTensorOpMul,
-                                 &alpha0,
-                                 sp_desc,
-                                 workSpace,
-                                 &alpha1,
-                                 sp_desc,
-                                 reserveSpace,
-                                 &beta_t,
-                                 hx_desc,
-                                 dhx,
-                                 pretime_shift + bi * 3 * hy_h + ri * hy_h,
-                                 pretime_shift + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 hx_shift + ri * hy_n * hy_h);
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+        // dcx, dhx
+        if(dhx != nullptr || (rnnMode == miopenLSTM && dcx != nullptr))
+        {
+            hx_size[2] = hy_h;
+            sp_size[2] = hy_h;
 
-                        auto gg2 = ScanGemmGeometryRNN(handle,
-                                                       workSpace,
-                                                       w,
-                                                       dhx,
-                                                       in_n.at(cur_time),
-                                                       hy_h,
-                                                       hy_h * 2,
-                                                       1,
-                                                       1,
-                                                       false,
-                                                       false,
-                                                       false,
-                                                       hy_stride,
-                                                       uni_stride,
-                                                       uni_stride,
-                                                       false,
-                                                       network_config,
-                                                       MIO_RNN_FINDSOL_TIMEOUT);
-
-                        gg2.RunGemm(handle,
-                                    workSpace,
+            bacc = 0;
+            baccbi = batch_n;
+
+            for(int ti = 0; ti < seqLen; ti++)
+            {
+                baccbi -= in_n[seqLen - 1 - ti];
+                for(int ri = 0; ri < bi; ri++)
+                {
+                    cur_time  = ri == 0 ? ti : seqLen - 1 - ti;
+                    cur_batch = ri == 0 ? bacc : baccbi;
+                    use_time = 0;
+                    int use_batch = 0;
+
+                    if(ti > 0)
+                    {
+                        use_time = ri == 0 ? ti - 1 : seqLen - ti;
+                        use_batch = in_n[use_time];
+                    }
+
+                    if(in_n[cur_time] > use_batch)
+                    {
+                        pretime_shift = li * batch_n * hy_stride + cur_batch * hy_stride;
+
+                        if(rnnMode == miopenLSTM || rnnMode == miopenGRU)
+                        {
+                            sp_size[1] = in_n[cur_time];
+                            hx_size[1] = in_n[cur_time];
+                            hx_desc =
+                                miopen::TensorDescriptor(wDesc.GetType(), hx_size.data(), hx_stride.data(), 3);
+                            sp_desc =
+                                miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+                        }
+
+                        if(dhx != nullptr)
+                        {
+                            if(rnnMode == miopenGRU)
+                            {
+                                alpha0 = 1;
+                                alpha1 = 1;
+                                beta_t = 0;
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta_t,
+                                         sp_desc,
+                                         reserveSpace,
+                                         pretime_shift + 2 * hy_h + ri * wei_len + use_batch * hy_stride,
+                                         pretime_shift + hy_h + ri * wei_len +
+                                             use_batch * hy_stride + nLayers * batch_n * hy_stride,
+                                         pretime_shift + dhd_off + ri * hy_h +
+                                             use_batch * hy_stride + nLayers * batch_n * hy_stride);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                miopen::GemmDescriptor gemm_desc =
+                                    GemmDescriptor{false,
+                                                   false,
+                                                   false,
+                                                   in_n[cur_time] - use_batch,
+                                                   hy_h,
+                                                   hy_h,
+                                                   hy_stride,
+                                                   uni_stride,
+                                                   uni_stride,
+                                                   1,
+                                                   0,
+                                                   0,
+                                                   0,
+                                                   1,
+                                                   0,
+                                                   yDesc[0].GetType()};
+
+                                miopenStatus_t gemm_status = CallGemm(
+                                    handle,
+                                    gemm_desc,
+                                    reserveSpace,
+                                    pretime_shift + dhd_off + ri * hy_h + use_batch * hy_stride +
+                                        static_cast<int>(nLayers) * batch_n * hy_stride,
                                     w,
+                                    weitime_shift + 2 * hy_h * uni_stride +
+                                        ri * wei_len * uni_stride,
                                     dhx,
-                                    pretime_shift + ri * 3 * hy_h,
-                                    weitime_shift + ri * 3 * hy_h * uni_stride,
-                                    hx_shift + ri * hy_n * hy_h);
+                                    hx_shift + ri * hy_n * hy_h + use_batch * hy_h,
+                                    nullptr,
+                                    false,
+                                    GemmBackend_t::rocblas);
 
-                        // Update time
-                        profileRNNkernels(handle, 1, ctime);
+                                if(gemm_status != miopenStatusSuccess)
+                                {
+                                    if(gemm_status == miopenStatusNotImplemented)
+                                    {
+                                        MIOPEN_LOG_E("GEMM not implemented");
+                                    }
+                                    else
+                                    {
+                                        MIOPEN_LOG_E("GEMM failed");
+                                    }
+                                }
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+
+                                beta_t = 1;
+
+                                OpTensor(handle,
+                                         miopenTensorOpMul,
+                                         &alpha0,
+                                         sp_desc,
+                                         workSpace,
+                                         &alpha1,
+                                         sp_desc,
+                                         reserveSpace,
+                                         &beta_t,
+                                         hx_desc,
+                                         dhx,
+                                         pretime_shift + dhd_off + ri * hy_h + use_batch * hy_stride,
+                                         pretime_shift + ri * wei_len + use_batch * hy_stride + nLayers * batch_n * hy_stride,
+                                         hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
+
+                            miopen::GemmDescriptor gemm_desc =
+                                GemmDescriptor{false,
+                                               false,
+                                               false,
+                                               in_n[cur_time] - use_batch,
+                                               hy_h,
+                                               wei_len_t,
+                                               hy_stride,
+                                               uni_stride,
+                                               uni_stride,
+                                               1,
+                                               0,
+                                               0,
+                                               0,
+                                               1,
+                                               1,
+                                               yDesc[0].GetType()};
+
+                            miopenStatus_t gemm_status =
+                                CallGemm(handle,
+                                         gemm_desc,
+                                         workSpace,
+                                         pretime_shift + ri * wei_len + use_batch * hy_stride,
+                                         w,
+                                         weitime_shift + ri * wei_len * uni_stride,
+                                         dhx,
+                                         hx_shift + ri * hy_n * hy_h + use_batch * hy_h,
+                                         nullptr,
+                                         false,
+                                         GemmBackend_t::rocblas);
+                            if(gemm_status != miopenStatusSuccess)
+                            {
+                                if(gemm_status == miopenStatusNotImplemented)
+                                {
+                                    MIOPEN_LOG_E("GEMM not implemented");
+                                }
+                                else
+                                {
+                                    MIOPEN_LOG_E("GEMM failed");
+                                }
+                            }
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+
+                        if(rnnMode == miopenLSTM && dcx != nullptr)
+                        {
+                            alpha0 = 1;
+                            alpha1 = 1;
+                            beta_t = 1;
+
+                            OpTensor(handle,
+                                     miopenTensorOpMul,
+                                     &alpha0,
+                                     sp_desc,
+                                     workSpace,
+                                     &alpha1,
+                                     sp_desc,
+                                     reserveSpace,
+                                     &beta_t,
+                                     hx_desc,
+                                     dcx,
+                                     pretime_shift + bi * wei_len + ri * hy_h + use_batch * hy_stride,
+                                     pretime_shift + hy_h + ri * wei_len + use_batch * hy_stride +
+                                         nLayers * batch_n * hy_stride,
+                                     hx_shift + ri * hy_n * hy_h + use_batch * hy_h);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
                     }
                 }
+                bacc += in_n[ti];
             }
         }
     }
@@ -3202,12 +3697,12 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
         sp_size[2] = hy_h;
         x_size[1]  = batch_n;
         x_size[2]  = hy_h;
-        x_desc     = miopen::TensorDescriptor(miopenFloat, x_size.data(), x_stride.data(), 3);
-        sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+        x_desc     = miopen::TensorDescriptor(wDesc.GetType(), x_size.data(), x_stride.data(), 3);
+        sp_desc    = miopen::TensorDescriptor(wDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
         alpha0 = 1;
-        alpha1 = 0;
-        beta_t = 1;
+        alpha1 = 1;
+        beta_t = 0;
 
         for(int gi = 0; gi < nHiddenTensorsPerLayer * bi; gi++)
         {
@@ -3217,13 +3712,13 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
                      sp_desc,
                      workSpace,
                      &alpha1,
-                     sp_desc,
-                     workSpace,
+                     x_desc,
+                     dx,
                      &beta_t,
                      x_desc,
                      dx,
                      gi * hy_h,
-                     gi * hy_h,
+                     0,
                      0);
             // Update time
             profileRNNkernels(handle, (gi == nHiddenTensorsPerLayer * bi - 1) ? 2 : 1, ctime);
@@ -3231,46 +3726,64 @@ void RNNDescriptor::RNNBackwardData(Handle& handle,
     }
     else
     {
+        miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                          false,
+                                                          false,
+                                                          batch_n,
+                                                          in_h,
+                                                          wei_len * bi,
+                                                          hy_stride,
+                                                          in_stride,
+                                                          in_stride,
+                                                          1,
+                                                          0,
+                                                          0,
+                                                          0,
+                                                          1,
+                                                          0,
+                                                          yDesc[0].GetType()};
+        miopenStatus_t gemm_status = CallGemm(handle,
+                                              gemm_desc,
+                                              workSpace,
+                                              0,
+                                              w,
+                                              0,
+                                              dx,
+                                              0,
+                                              nullptr,
+                                              false,
+                                              GemmBackend_t::rocblas);
 
-        auto gg = ScanGemmGeometryRNN(handle,
-                                      workSpace,
-                                      w,
-                                      dx,
-                                      batch_n,
-                                      in_h,
-                                      wei_len * bi,
-                                      1,
-                                      1,
-                                      false,
-                                      false,
-                                      false,
-                                      hy_stride,
-                                      in_stride,
-                                      in_stride,
-                                      false,
-                                      network_config,
-                                      MIO_RNN_FINDSOL_TIMEOUT);
-
-        gg.RunGemm(handle, workSpace, w, dx, 0, 0, 0);
-
+        if(gemm_status != miopenStatusSuccess)
+        {
+            if(gemm_status == miopenStatusNotImplemented)
+            {
+                MIOPEN_LOG_E("GEMM not implemented");
+            }
+            else
+            {
+                MIOPEN_LOG_E("GEMM failed");
+            }
+        }
         // Update time
         profileRNNkernels(handle, 2, ctime);
     }
 #else
+    (void)wei_stride;
+    (void)bi_stride;
+    (void)alpha;
+    (void)offset;
+    (void)alpha0;
+    (void)alpha1;
+    (void)beta_t;
+    (void)hx;
+    (void)cx;
+    (void)dhy;
+    (void)dcy;
+    (void)reserveSpace;
+    (void)in_h;
     MIOPEN_THROW("GEMM is not supported");
 #endif
-
-    // Suppress warning
-    (void)y;
-    (void)yDesc;
-    (void)hxDesc;
-    (void)cxDesc;
-    (void)dcxDesc;
-    (void)dcyDesc;
-    (void)dhyDesc;
-    (void)wDesc;
-    (void)workSpaceSize;
-    (void)reserveSpaceSize;
 };
 
 void RNNDescriptor::RNNBackwardWeights(Handle& handle,
@@ -3310,7 +3823,7 @@ void RNNDescriptor::RNNBackwardWeights(Handle& handle,
     int hy_h  = hxDesc.GetLengths()[2];
     int out_h = dyDesc[0].GetLengths()[1];
 
-    if(in_h == 0 || hy_h == 0 || hy_n == 0 || hy_d == 0 || out_h == 0)
+    if(in_h == 0 || hy_h == 0 || hy_n == 0 || hy_d == 0 || out_h == 0 || seqLen <= 0)
     {
         MIOPEN_THROW(miopenStatusBadParm);
     }
@@ -3371,17 +3884,25 @@ void RNNDescriptor::RNNBackwardWeights(Handle& handle,
 
     size_t wei_shift_bias = (in_h + hy_h + (bi * hy_h + hy_h) * (nLayers - 1)) * wei_stride;
 
-    float alpha0, alpha1, beta_t;
+    float alpha0, alpha1, beta_t = 0;
 
     std::vector<int> sp_size(3, 1), sp_stride(3, 1), w_size(3, 1), w_stride(3, 1);
     miopen::TensorDescriptor sp_desc, w_desc;
 
     sp_stride[0] = batch_n * hy_stride;
     sp_stride[1] = hy_stride;
-    w_stride[0]  = wei_stride;
-    w_stride[1]  = wei_stride;
+    w_size[2] = dwDesc.GetElementSize();
+    w_stride[0]  = w_size[2];
+    w_stride[1]  = w_size[2];
+    w_desc = miopen::TensorDescriptor(dwDesc.GetType(), w_size.data(), w_stride.data(), 3);
+    SetTensor(handle, w_desc, dw, &beta_t);
+    // Update time
+    profileRNNkernels(handle, 0, ctime);
+    w_stride[0] = wei_stride;
+    w_stride[1] = wei_stride;
+    w_size[2] = 1;
 
-#if MIOPEN_USE_MIOPENGEMM
+#if MIOPEN_USE_ROCBLAS
 
     int wei_len   = 0;
     int hid_off   = 0;
@@ -3420,26 +3941,45 @@ void RNNDescriptor::RNNBackwardWeights(Handle& handle,
             if(inputMode == miopenRNNlinear)
             {
 
-                auto gg = ScanGemmGeometryRNN(handle,
-                                              workSpace,
-                                              x,
-                                              dw,
-                                              wei_len * bi,
-                                              in_h,
-                                              batch_n,
-                                              1,
-                                              1,
-                                              true,
-                                              false,
-                                              false,
-                                              hy_stride,
-                                              in_stride,
-                                              in_stride,
-                                              false,
-                                              network_config,
-                                              MIO_RNN_FINDSOL_TIMEOUT);
+                miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                  true,
+                                                                  false,
+                                                                  wei_len * bi,
+                                                                  in_h,
+                                                                  batch_n,
+                                                                  hy_stride,
+                                                                  in_stride,
+                                                                  in_stride,
+                                                                  1,
+                                                                  0,
+                                                                  0,
+                                                                  0,
+                                                                  1,
+                                                                  1,
+                                                                  xDesc[0].GetType()};
+                miopenStatus_t gemm_status = CallGemm(handle,
+                                                      gemm_desc,
+                                                      workSpace,
+                                                      0,
+                                                      x,
+                                                      0,
+                                                      dw,
+                                                      0,
+                                                      nullptr,
+                                                      false,
+                                                      GemmBackend_t::rocblas);
 
-                gg.RunGemm(handle, workSpace, x, dw, 0, 0, 0);
+                if(gemm_status != miopenStatusSuccess)
+                {
+                    if(gemm_status == miopenStatusNotImplemented)
+                    {
+                        MIOPEN_LOG_E("GEMM not implemented");
+                    }
+                    else
+                    {
+                        MIOPEN_LOG_E("GEMM failed");
+                    }
+                }
 
                 // Update time
                 profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
@@ -3449,26 +3989,46 @@ void RNNDescriptor::RNNBackwardWeights(Handle& handle,
         {
             int prelayer_shift = (li - 1) * batch_n * hy_stride + hid_off;
 
-            auto gg = ScanGemmGeometryRNN(handle,
-                                          workSpace,
-                                          reserveSpace,
-                                          dw,
-                                          wei_len * bi,
-                                          hy_h * bi,
-                                          batch_n,
-                                          1,
-                                          1,
-                                          true,
-                                          false,
-                                          false,
-                                          hy_stride,
-                                          hy_stride,
-                                          bi_stride,
-                                          false,
-                                          network_config,
-                                          MIO_RNN_FINDSOL_TIMEOUT);
-
-            gg.RunGemm(handle, workSpace, reserveSpace, dw, hid_shift, prelayer_shift, wei_shift);
+            miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                              true,
+                                                              false,
+                                                              wei_len * bi,
+                                                              hy_h * bi,
+                                                              batch_n,
+                                                              hy_stride,
+                                                              hy_stride,
+                                                              bi_stride,
+                                                              1,
+                                                              0,
+                                                              0,
+                                                              0,
+                                                              1,
+                                                              1,
+                                                              xDesc[0].GetType()};
+
+            miopenStatus_t gemm_status = CallGemm(handle,
+                                                  gemm_desc,
+                                                  workSpace,
+                                                  hid_shift,
+                                                  reserveSpace,
+                                                  prelayer_shift,
+                                                  dw,
+                                                  wei_shift,
+                                                  nullptr,
+                                                  false,
+                                                  GemmBackend_t::rocblas);
+
+            if(gemm_status != miopenStatusSuccess)
+            {
+                if(gemm_status == miopenStatusNotImplemented)
+                {
+                    MIOPEN_LOG_E("GEMM not implemented");
+                }
+                else
+                {
+                    MIOPEN_LOG_E("GEMM failed");
+                }
+            }
 
             // Update time
             profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
@@ -3476,256 +4036,564 @@ void RNNDescriptor::RNNBackwardWeights(Handle& handle,
 
         if(biasMode)
         {
-            if(li == 0 && inputMode == miopenRNNskip && rnnMode == miopenGRU)
-                ;
-            else
+            sp_size[1] = batch_n;
+            sp_size[2] = wei_stride;
+            w_size[1]  = 1;
+            w_size[2]  = wei_stride;
+            w_desc = miopen::TensorDescriptor(dwDesc.GetType(), w_size.data(), w_stride.data(), 3);
+            sp_desc =
+                miopen::TensorDescriptor(dwDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+            alpha0 = 0;
+            alpha1 = 1;
+            beta_t = 1;
+
+            OpTensor(handle,
+                     miopenTensorOpAdd,
+                     &alpha0,
+                     w_desc,
+                     dw,
+                     &alpha1,
+                     sp_desc,
+                     workSpace,
+                     &beta_t,
+                     w_desc,
+                     dw,
+                     wei_shift,
+                     hid_shift,
+                     wei_shift);
+
+            // Update time
+            profileRNNkernels(handle, 1, ctime);
+
+        }
+
+        // between time
+        if(rnnMode == miopenGRU)
+        {
+            sp_size[1] = batch_n;
+            sp_size[2] = hy_h;
+            sp_desc =
+                miopen::TensorDescriptor(dwDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+            for(int ri = 0; ri < bi; ri++)
             {
-                if(li == 0)
-                {
-                    wei_shift = wei_shift_bias;
-                }
-                else
-                {
-                    wei_shift = (inputMode == miopenRNNskip)
-                                    ? (wei_shift_bias + wei_stride + (li - 1) * 2 * wei_stride)
-                                    : (wei_shift_bias + li * 2 * wei_stride);
-                }
+                CopyTensor(handle,
+                           sp_desc,
+                           reserveSpace,
+                           sp_desc,
+                           workSpace,
+                           hid_shift + hid_off + ri * hy_h +
+                               static_cast<int>(nLayers) * batch_n * hy_stride,
+                           hid_shift + 2 * hy_h + ri * wei_len);
+                // Update time
+                profileRNNkernels(handle, 1, ctime);
+            }
+        }
 
-                sp_size[1] = 1;
-                sp_size[2] = wei_stride;
-                w_size[1]  = 1;
-                w_size[2]  = wei_stride;
-                w_desc = miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
-                sp_desc =
-                    miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+        if(biasMode != 0u)
+        {
+            wei_shift = static_cast<int>(wei_shift_bias) + li * 2 * wei_stride + wei_stride;
 
-                alpha0 = 1;
-                alpha1 = 0;
-                beta_t = 1;
+            alpha0 = 1;
+            alpha1 = 1;
+            beta_t = 0;
 
-                for(int bs = 0; bs < batch_n; bs++)
+            if(hx != nullptr)
+            {
+                if(rnnMode == miopenGRU)
                 {
+                    sp_size[1] = batch_n;
+                    sp_size[2] = wei_stride;
+                    w_size[1]  = 1;
+                    w_size[2]  = wei_stride;
+                    w_desc     = miopen::TensorDescriptor(
+                        dwDesc.GetType(), w_size.data(), w_stride.data(), 3);
+                    sp_desc = miopen::TensorDescriptor(
+                        dwDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
                     OpTensor(handle,
                              miopenTensorOpAdd,
                              &alpha0,
-                             sp_desc,
-                             workSpace,
+                             w_desc,
+                             dw,
                              &alpha1,
                              sp_desc,
                              workSpace,
                              &beta_t,
                              w_desc,
                              dw,
-                             hid_shift + bs * hy_stride,
-                             hid_shift + bs * hy_stride,
+                             wei_shift,
+                             hid_shift,
                              wei_shift);
 
                     // Update time
-                    profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
+                    profileRNNkernels(handle, 1, ctime);
                 }
-
-                if(rnnMode != miopenGRU && (!(li == 0 && inputMode == miopenRNNskip)))
+                else
                 {
-                    CopyTensor(handle, w_desc, dw, w_desc, dw, wei_shift, wei_shift + wei_stride);
+                    CopyTensor(handle, w_desc, dw, w_desc, dw, wei_shift - wei_stride, wei_shift);
                     // Update time
-                    profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
+                    profileRNNkernels(handle, 1, ctime);
                 }
             }
-        }
-
-        // between time
-        int bacc   = 0;
-        int baccbi = batch_n;
-        for(int ti = 0; ti < seqLen; ti++)
-        {
-            baccbi -= in_n[seqLen - 1 - ti];
-
-            int hx_shift = li * hy_n * bi_stride;
-            wei_shift    = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
-
-            for(int ri = 0; ri < bi; ri++)
+            else
             {
-                hid_shift = ri == 0 ? (li * batch_n * hy_stride + bacc * hy_stride)
-                                    : (li * batch_n * hy_stride + baccbi * hy_stride);
-                int cur_time = ri == 0 ? ti : seqLen - 1 - ti;
-                if(ti > 0)
-                {
-                    pre_batch = ri == 0 ? bacc - in_n[ti - 1] : baccbi + in_n[seqLen - 1 - ti];
-                    use_time  = ri == 0 ? ti : seqLen - ti;
-                }
+                sp_size[1] = 1;
+                sp_size[2] = wei_len;
+                w_size[1]  = 1;
+                w_size[2]  = wei_len;
+                w_desc =
+                    miopen::TensorDescriptor(dwDesc.GetType(), w_size.data(), w_stride.data(), 3);
+                sp_desc =
+                    miopen::TensorDescriptor(dwDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
 
-                if(in_n[cur_time] > 0)
+                for(int bs = 0; bs < batch_n; bs++)
                 {
-                    if(rnnMode == miopenGRU)
+                    if(!(hx == nullptr && bs < in_n.at(0)))
                     {
-                        if(ri == 0)
-                        {
-                            alpha0 = 1;
-                            alpha1 = 1;
-                            beta_t = 0;
-                        }
-
-                        sp_size[1] = in_n[cur_time];
-                        sp_size[2] = hy_h;
-                        sp_desc    = miopen::TensorDescriptor(
-                            miopenFloat, sp_size.data(), sp_stride.data(), 3);
-
                         OpTensor(handle,
-                                 miopenTensorOpMul,
+                                 miopenTensorOpAdd,
                                  &alpha0,
                                  sp_desc,
-                                 reserveSpace,
-                                 &alpha1,
-                                 sp_desc,
                                  workSpace,
+                                 &alpha1,
+                                 w_desc,
+                                 dw,
                                  &beta_t,
-                                 sp_desc,
-                                 workSpace,
-                                 hid_shift + hy_h + ri * 3 * hy_h + nLayers * batch_n * hy_stride,
-                                 hid_shift + 2 * hy_h + ri * 3 * hy_h,
-                                 hid_shift + 2 * hy_h + ri * 3 * hy_h);
+                                 w_desc,
+                                 dw,
+                                 hid_shift + bs * hy_stride,
+                                 wei_shift,
+                                 wei_shift);
+
                         // Update time
-                        profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
+                        profileRNNkernels(handle, 1, ctime);
                     }
+                }
 
-                    if(ti == 0)
+                if(dirMode != 0u)
+                {
+                    sp_size[1] = 1;
+                    sp_size[2] = wei_len;
+                    w_size[1]  = 1;
+                    w_size[2]  = wei_len;
+                    w_desc     = miopen::TensorDescriptor(
+                        dwDesc.GetType(), w_size.data(), w_stride.data(), 3);
+                    sp_desc = miopen::TensorDescriptor(
+                        dwDesc.GetType(), sp_size.data(), sp_stride.data(), 3);
+
+                    int cur_batch = 0;
+                    for(int ti = 0; ti < seqLen - 1; ti++)
                     {
+                        for(int bs = 0; bs < in_n.at(ti + 1); bs++)
+                        {
+                            OpTensor(handle,
+                                     miopenTensorOpAdd,
+                                     &alpha0,
+                                     sp_desc,
+                                     workSpace,
+                                     &alpha1,
+                                     w_desc,
+                                     dw,
+                                     &beta_t,
+                                     w_desc,
+                                     dw,
+                                     hid_shift + (cur_batch + bs) * hy_stride + wei_len,
+                                     wei_shift + wei_len,
+                                     wei_shift + wei_len);
 
-                        auto gg = ScanGemmGeometryRNN(handle,
-                                                      workSpace,
-                                                      hx,
-                                                      dw,
-                                                      wei_len,
-                                                      hy_h,
-                                                      in_n.at(cur_time),
-                                                      1,
-                                                      1,
-                                                      true,
-                                                      false,
-                                                      false,
-                                                      hy_stride,
-                                                      uni_stride,
-                                                      uni_stride,
-                                                      false,
-                                                      network_config,
-                                                      MIO_RNN_FINDSOL_TIMEOUT);
+                            // Update time
+                            profileRNNkernels(handle, 1, ctime);
+                        }
+                        cur_batch += in_n.at(ti);
+                    }
+                }
+            }
+        }
 
-                        gg.RunGemm(handle,
-                                   workSpace,
-                                   hx,
-                                   dw,
-                                   hid_shift + ri * wei_len,
-                                   hx_shift + ri * hy_n * hy_h,
-                                   wei_shift + ri * wei_len * uni_stride);
+        int pretime_shift, hx_shift, cur_time;
+        bool comb_check = true;
+        if(seqLen > 2)
+        {
+            if(in_n.at(0) != in_n.at(seqLen - 2))
+            {
+                comb_check = false;
+            }
+        }
 
-                        // Update time
-                        if(li == nLayers - 1 && ti == seqLen - 1 && ri == bi - 1 &&
-                           !(rnnMode == miopenGRU && biasMode))
-                            profileRNNkernels(handle, 2, ctime);
+        if(comb_check)
+        {
+            hx_shift  = li * hy_n * bi_stride;
+            wei_shift = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
+
+            for(int ri = 0; ri < bi; ri++)
+            {
+                hid_shift =
+                    ri == 0 ? li * batch_n * hy_stride
+                            : (li * batch_n * hy_stride + in_n.at(0) * (seqLen - 1) * hy_stride);
+                cur_time = ri == 0 ? 0 : seqLen - 1;
+
+                if(in_n.at(cur_time) > 0 && hx != nullptr)
+                {
+                    miopen::GemmDescriptor gemm_desc = GemmDescriptor{false,
+                                                                      true,
+                                                                      false,
+                                                                      wei_len,
+                                                                      hy_h,
+                                                                      in_n.at(cur_time),
+                                                                      hy_stride,
+                                                                      uni_stride,
+                                                                      uni_stride,
+                                                                      1, // batch count
+                                                                      0, // Stride A
+                                                                      0, // Stride B
+                                                                      0, // Stride C
+                                                                      1, // alpha
+                                                                      1, // beta
+                                                                      xDesc[0].GetType()};
+
+                    miopenStatus_t gemm_status = CallGemm(handle,
+                                                          gemm_desc,
+                                                          workSpace,
+                                                          hid_shift + ri * wei_len,
+                                                          hx,
+                                                          hx_shift + ri * hy_n * hy_h,
+                                                          dw,
+                                                          wei_shift + ri * wei_len * uni_stride,
+                                                          nullptr,
+                                                          false,
+                                                          GemmBackend_t::rocblas);
+
+                    if(gemm_status != miopenStatusSuccess)
+                    {
+                        if(gemm_status == miopenStatusNotImplemented)
+                        {
+                            MIOPEN_LOG_E("GEMM not implemented");
+                        }
                         else
-                            profileRNNkernels(handle, std::min(time_mark++, 1), ctime);
+                        {
+                            MIOPEN_LOG_E("GEMM failed");
+                        }
                     }
+
+                    // Update time
+                    if(li == nLayers - 1 && ri == bi - 1 && seqLen == 1)
+                        profileRNNkernels(handle, 2, ctime);
                     else
-                    {
-                        int pretime_shift =
-                            li * batch_n * hy_stride + pre_batch * hy_stride + hid_off;
+                        profileRNNkernels(handle, 1, ctime);
+                }
 
-                        if(in_n[use_time] > 0)
+                if(seqLen > 1)
+                {
+                    if(ri == 1 && hx != nullptr && in_n.at(0) > in_n.at(seqLen - 1))
+                    {
+                        miopen::GemmDescriptor gemm_desc =
+                            GemmDescriptor{false,
+                                           true,
+                                           false,
+                                           wei_len,
+                                           hy_h,
+                                           (in_n.at(0) - in_n.at(seqLen - 1)),
+                                           hy_stride,
+                                           uni_stride,
+                                           uni_stride,
+                                           1, // batch count
+                                           0, // Stride A
+                                           0, // Stride B
+                                           0, // Stride C
+                                           1, // alpha
+                                           1, // beta
+                                           xDesc[0].GetType()};
+
+                        miopenStatus_t gemm_status =
+                            CallGemm(handle,
+                                     gemm_desc,
+                                     workSpace,
+                                     hid_shift + ri * wei_len -
+                                         (in_n.at(0) - in_n.at(seqLen - 1)) * hy_stride,
+                                     hx,
+                                     hx_shift + ri * hy_n * hy_h + in_n.at(seqLen - 1) * hy_h,
+                                     dw,
+                                     wei_shift + ri * wei_len * uni_stride,
+                                     nullptr,
+                                     false,
+                                     GemmBackend_t::rocblas);
+
+                        if(gemm_status != miopenStatusSuccess)
                         {
+                            if(gemm_status == miopenStatusNotImplemented)
+                            {
+                                MIOPEN_LOG_E("GEMM not implemented");
+                            }
+                            else
+                            {
+                                MIOPEN_LOG_E("GEMM failed");
+                            }
+                        }
+                        // Update time
+                        profileRNNkernels(handle, 1, ctime);
+                    }
 
-                            auto gg = ScanGemmGeometryRNN(handle,
+                    hid_shift = ri == 0 ? (li * batch_n * hy_stride + in_n.at(0) * hy_stride)
+                                        : (li * batch_n * hy_stride);
+                    pretime_shift =
+                        ri == 0 ? li * batch_n * hy_stride + hid_off
+                                : li * batch_n * hy_stride + in_n.at(0) * hy_stride + hid_off;
+
+                    miopen::GemmDescriptor gemm_desc =
+                        GemmDescriptor{false,
+                                       true,
+                                       false,
+                                       wei_len,
+                                       hy_h,
+                                       in_n.at(0) * (seqLen - 2) + in_n.at(seqLen - 1),
+                                       hy_stride,
+                                       hy_stride,
+                                       uni_stride,
+                                       1, // batch count
+                                       0, // Stride A
+                                       0, // Stride B
+                                       0, // Stride C
+                                       1, // alpha
+                                       1, // beta
+                                       xDesc[0].GetType()};
+
+                    miopenStatus_t gemm_status = CallGemm(handle,
+                                                          gemm_desc,
                                                           workSpace,
+                                                          hid_shift + ri * wei_len,
                                                           reserveSpace,
+                                                          pretime_shift + ri * hy_h,
                                                           dw,
-                                                          wei_len,
-                                                          hy_h,
-                                                          in_n.at(use_time),
-                                                          1,
-                                                          1,
-                                                          true,
-                                                          false,
-                                                          false,
-                                                          hy_stride,
-                                                          hy_stride,
-                                                          uni_stride,
+                                                          wei_shift + ri * wei_len * uni_stride,
+                                                          nullptr,
                                                           false,
-                                                          network_config,
-                                                          MIO_RNN_FINDSOL_TIMEOUT);
-
-                            gg.RunGemm(handle,
-                                       workSpace,
-                                       reserveSpace,
-                                       dw,
-                                       hid_shift + ri * wei_len,
-                                       pretime_shift + ri * hy_h,
-                                       wei_shift + ri * wei_len * uni_stride);
+                                                          GemmBackend_t::rocblas);
 
-                            // Update time
-                            if(li == nLayers - 1 && ti == seqLen - 1 && ri == bi - 1 &&
-                               !(rnnMode == miopenGRU && biasMode))
-                                profileRNNkernels(handle, 2, ctime);
-                            else
-                                profileRNNkernels(handle, 1, ctime);
+                    if(gemm_status != miopenStatusSuccess)
+                    {
+                        if(gemm_status == miopenStatusNotImplemented)
+                        {
+                            MIOPEN_LOG_E("GEMM not implemented");
+                        }
+                        else
+                        {
+                            MIOPEN_LOG_E("GEMM failed");
                         }
                     }
+                    // Update time
+                    if(li == nLayers - 1 && ri == bi - 1)
+                        profileRNNkernels(handle, 2, ctime);
+                    else
+                        profileRNNkernels(handle, 1, ctime);
                 }
             }
-
-            bacc += in_n[ti];
         }
-
-        if(rnnMode == miopenGRU && biasMode)
+        else
         {
-            int in_bias_val = inputMode == miopenRNNskip ? 0 : wei_stride;
 
-            hid_shift = li * batch_n * hy_stride;
-            wei_shift = (li == 0) ? (wei_shift_bias + in_bias_val)
-                                  : (wei_shift_bias + in_bias_val + li * 2 * wei_stride);
+            int bacc   = 0;
+            int baccbi = batch_n;
+            for(int ti = 0; ti < seqLen; ti++)
+            {
+                baccbi -= in_n[seqLen - 1 - ti];
 
-            sp_size[1] = 1;
-            sp_size[2] = wei_stride;
-            w_size[1]  = 1;
-            w_size[2]  = wei_stride;
-            w_desc     = miopen::TensorDescriptor(miopenFloat, w_size.data(), w_stride.data(), 3);
-            sp_desc    = miopen::TensorDescriptor(miopenFloat, sp_size.data(), sp_stride.data(), 3);
+                hx_shift = li * hy_n * bi_stride;
+                wei_shift    = in_h * wei_stride + li * (bi * hy_h + hy_h) * wei_stride;
 
-            alpha0 = 1;
-            alpha1 = 0;
-            beta_t = 1;
+                for(int ri = 0; ri < bi; ri++)
+                {
+                    hid_shift = ri == 0 ? (li * batch_n * hy_stride + bacc * hy_stride)
+                                        : (li * batch_n * hy_stride + baccbi * hy_stride);
+                    cur_time = ri == 0 ? ti : seqLen - 1 - ti;
+                    if(ti > 0)
+                    {
+                        pre_batch = ri == 0 ? bacc - in_n[ti - 1] : baccbi + in_n[seqLen - 1 - ti];
+                        use_time  = ri == 0 ? ti : seqLen - ti;
+                    }
 
-            for(int bs = 0; bs < batch_n; bs++)
-            {
-                OpTensor(handle,
-                         miopenTensorOpAdd,
-                         &alpha0,
-                         sp_desc,
-                         workSpace,
-                         &alpha1,
-                         sp_desc,
-                         workSpace,
-                         &beta_t,
-                         w_desc,
-                         dw,
-                         hid_shift + bs * hy_stride,
-                         hid_shift + bs * hy_stride,
-                         wei_shift);
+                    if(in_n[cur_time] > 0)
+                    {
+                        if(ti == 0)
+                        {
+                            if(hx != nullptr)
+                            {
+                                miopen::GemmDescriptor gemm_desc =
+                                    GemmDescriptor{false,
+                                                   true,
+                                                   false,
+                                                   wei_len,
+                                                   hy_h,
+                                                   in_n.at(cur_time),
+                                                   hy_stride,
+                                                   uni_stride,
+                                                   uni_stride,
+                                                   1,
+                                                   0,
+                                                   0,
+                                                   0,
+                                                   1,
+                                                   1,
+                                                   xDesc[0].GetType()};
+
+                                miopenStatus_t gemm_status =
+                                    CallGemm(handle,
+                                             gemm_desc,
+                                             workSpace,
+                                             hid_shift = ri * wei_len,
+                                             hx,
+                                             hx_shift + ri * hy_n * hy_h,
+                                             dw,
+                                             wei_shift + ri * wei_len * uni_stride,
+                                             nullptr,
+                                             false,
+                                             GemmBackend_t::rocblas);
+
+                                if(gemm_status != miopenStatusSuccess)
+                                {
+                                    if(gemm_status == miopenStatusNotImplemented)
+                                    {
+                                        MIOPEN_LOG_E("GEMM not implemented");
+                                    }
+                                    else
+                                    {
+                                        MIOPEN_LOG_E("GEMM failed");
+                                    }
+                                }
 
-                // Update time
-                if(li == nLayers - 1 && bs == batch_n - 1)
-                    profileRNNkernels(handle, 2, ctime);
-                else
-                    profileRNNkernels(handle, 1, ctime);
+                                // Update time
+                                if(li == nLayers - 1 && ti == seqLen - 1 && ri == bi - 1)
+                                    profileRNNkernels(handle, 2, ctime);
+                                else
+                                    profileRNNkernels(handle, 1, ctime);
+                            }
+                        }
+                        else
+                        {
+                            if(ri == 1 && hx != nullptr && in_n.at(cur_time) > in_n.at(use_time))
+                            {
+                                miopen::GemmDescriptor gemm_desc =
+                                    GemmDescriptor{false,
+                                                   true,
+                                                   false,
+                                                   wei_len,
+                                                   hy_h,
+                                                   (in_n.at(cur_time) - in_n.at(use_time)),
+                                                   hy_stride,
+                                                   uni_stride,
+                                                   uni_stride,
+                                                   1, // batch count
+                                                   0, // Stride A
+                                                   0, // Stride B
+                                                   0, // Stride C
+                                                   1, // alpha
+                                                   1, // beta
+                                                   xDesc[0].GetType()};
+
+                                miopenStatus_t gemm_status = CallGemm(
+                                    handle,
+                                    gemm_desc,
+                                    workSpace,
+                                    hid_shift + ri * wei_len + in_n.at(use_time) * hy_stride,
+                                    hx,
+                                    hx_shift + ri * hy_n * hy_h + in_n.at(use_time) * hy_h,
+                                    dw,
+                                    wei_shift + ri * wei_len * uni_stride,
+                                    nullptr,
+                                    false,
+                                    GemmBackend_t::rocblas);
+
+                                if(gemm_status != miopenStatusSuccess)
+                                {
+                                    if(gemm_status == miopenStatusNotImplemented)
+                                    {
+                                        MIOPEN_LOG_E("GEMM not implemented");
+                                    }
+                                    else
+                                    {
+                                        MIOPEN_LOG_E("GEMM failed");
+                                    }
+                                }
+                                // Update time
+                                profileRNNkernels(handle, 1, ctime);
+                            }
+
+                            pretime_shift =
+                                li * batch_n * hy_stride + pre_batch * hy_stride + hid_off;
+
+                            if(in_n[use_time] > 0)
+                            {
+                                miopen::GemmDescriptor gemm_desc =
+                                    GemmDescriptor{false,
+                                                   true,
+                                                   false,
+                                                   wei_len,
+                                                   hy_h,
+                                                   in_n.at(use_time),
+                                                   hy_stride,
+                                                   hy_stride,
+                                                   uni_stride,
+                                                   1, // batch count
+                                                   0, // Stride A
+                                                   0, // Stride B
+                                                   0, // Stride C
+                                                   1, // alpha
+                                                   1, // beta
+                                                   xDesc[0].GetType()};
+
+                                miopenStatus_t gemm_status =
+                                    CallGemm(handle,
+                                             gemm_desc,
+                                             workSpace,
+                                             hid_shift + ri * wei_len,
+                                             reserveSpace,
+                                             pretime_shift + ri * hy_h,
+                                             dw,
+                                             wei_shift + ri * wei_len * uni_stride,
+                                             nullptr,
+                                             false,
+                                             GemmBackend_t::rocblas);
+
+                                if(gemm_status != miopenStatusSuccess)
+                                {
+                                    if(gemm_status == miopenStatusNotImplemented)
+                                    {
+                                        MIOPEN_LOG_E("GEMM not implemented");
+                                    }
+                                    else
+                                    {
+                                        MIOPEN_LOG_E("GEMM failed");
+                                    }
+                                }
+                                // Update time
+                                if(li == nLayers - 1 && ti == seqLen - 1 && ri == bi - 1 &&
+                                   !(rnnMode == miopenGRU && biasMode))
+                                    profileRNNkernels(handle, 2, ctime);
+                                else
+                                    profileRNNkernels(handle, 1, ctime);
+                            }
+                        }
+                    }
+                }
+
+                bacc += in_n[ti];
             }
+
         }
     }
 #else
+    (void)in_stride;
+    (void)alpha0;
+    (void)wei_shift_bias;
+    (void)alpha1;
+    (void)bi_stride;
+    (void)uni_stride;
+    (void)hx;
+    (void)workSpace;
+    (void)reserveSpace;
     MIOPEN_THROW("GEMM is not supported");
 #endif
-
-    // Suppress warning
-    (void)dwDesc;
-    (void)workSpaceSize;
-    (void)reserveSpaceSize;
 };
 
 } // namespace miopen
diff --git a/src/ocl/tensorocl.cpp b/src/ocl/tensorocl.cpp
index a63b6d5..95ec9e2 100644
--- a/src/ocl/tensorocl.cpp
+++ b/src/ocl/tensorocl.cpp
@@ -28,12 +28,122 @@
 #include <miopen/errors.hpp>
 #include <miopen/tensor.hpp>
 #include <miopen/tensor_ops.hpp>
+#include <miopen/float_equal.hpp>
 #include <numeric>
 
 #define MIO_TENSOROCL_DEBUG 0
 
 namespace miopen {
 
+struct two_exp_ceiling_t
+{
+    std::size_t operator()(std::size_t n) const
+    {
+        assert(n > 0);
+        std::size_t i = 1;
+        n--;
+        while(n != 0)
+        {
+            i *= 2;
+            n /= 2;
+        }
+
+        return i;
+    }
+};
+
+static std::string parms_half_or_float(const miopenDataType_t t)
+{
+    std::string s{};
+
+    switch(t)
+    {
+        case miopenHalf:
+        {
+            s = " -DMIOPEN_USE_FP16=1 -DMIOPEN_USE_FP32=0";
+            break;
+        }
+        case miopenFloat:
+        {
+            s = " -DMIOPEN_USE_FP16=0 -DMIOPEN_USE_FP32=1";
+            break;
+        }
+     }
+
+     return s;
+}
+
+TensorDescriptor GetFlattenedTensorDescriptor(const TensorDescriptor& desc)
+{
+    // is packed
+    if(desc.IsPacked())
+        return {desc.GetType(), {desc.GetElementSize()}, {1}};
+    // start flattening tensor
+    std::vector<std::size_t> flat_lengths;
+    std::vector<std::size_t> flat_strides;
+
+    auto non1_length_strides = boost::combine(desc.GetLengths(), desc.GetStrides()) |
+                               boost::adaptors::filtered(f_length_is_not_1_t());
+
+    auto i               = non1_length_strides.begin();
+    std::size_t flat_len = boost::get<0>(*i);
+    auto i_previous      = i++;
+
+    // the 0-th dimension full-length doesn't matter
+    for(; i != non1_length_strides.end(); ++i)
+    {
+        std::size_t len             = boost::get<0>(*i);
+        std::size_t stride          = boost::get<1>(*i);
+        std::size_t previous_stride = boost::get<1>(*i_previous);
+        std::size_t full_len        = previous_stride / stride;
+
+        if(len == full_len)
+        {
+            flat_len *= len;
+        }
+        else
+        {
+            flat_lengths.push_back(flat_len);
+            flat_strides.push_back(previous_stride);
+            flat_len = len;
+        }
+       i_previous = i;
+    }
+
+    flat_lengths.push_back(flat_len);
+    flat_strides.push_back(boost::get<1>(*i_previous));
+
+    return {desc.GetType(), std::move(flat_lengths), std::move(flat_strides)};
+}
+
+static std::vector<std::size_t> get_worker_sizes(const std::vector<std::size_t>& data_sizes)
+{
+    const std::size_t dim = data_sizes.size();
+
+    std::vector<std::size_t> worker_sizes(dim);
+
+    std::transform(data_sizes.begin(), data_sizes.end(), worker_sizes.begin(), two_exp_ceiling_t{});
+
+    std::size_t wgd = std::accumulate(
+        worker_sizes.begin(), worker_sizes.end(), std::size_t{1}, std::multiplies<std::size_t>());
+
+    if(wgd > 65536)
+    {
+        std::size_t n = wgd / 65536;
+
+        int i = 0;
+        while(n > 1 && i < dim)
+        {
+            std::size_t size_old = worker_sizes[i];
+            worker_sizes[i]      = (size_old - 1) / n + 1;
+            n /= size_old / worker_sizes[i];
+            ++i;
+        }
+    }
+
+    return worker_sizes;
+}
+
 void SetTensor(Handle& handle, const TensorDescriptor& yDesc, Data_t y, const void* alpha)
 {
 
@@ -42,28 +152,122 @@ void SetTensor(Handle& handle, const TensorDescriptor& yDesc, Data_t y, const vo
         MIOPEN_THROW(miopenStatusBadParm);
     }
 
-    size_t global_threads = yDesc.GetElementSize();
-    size_t local_threads  = 256;
-    const std::vector<size_t> vld{local_threads, 1, 1};
-    const std::vector<size_t> vgd{global_threads, 1, 1};
+    const TensorDescriptor yDesc_flat = GetFlattenedTensorDescriptor(yDesc);
 
-    std::string program_name = "MIOpenTensorScaleKernel.cl";
-    switch(yDesc.GetType())
+#ifndef NDEBUG
+    if(yDesc.GetSize() != yDesc_flat.GetSize())
     {
-    case miopenFloat:
-    case miopenHalf:
-    {
-        float miopen_alpha = *(static_cast<const float*>(alpha));
-        std::string parms =
-            " -DMIOPEN_TYPE=" + GetDataType(yDesc.GetType()) + " -DMIOPEN_ALPHA_TYPE=float";
+        std::cout << __func__ << std::endl
+                  << "real descritor: " << yDesc << std::endl
+                  << "flat descritor: " << yDesc_flat << std::endl;
+    }
+#endif
+    const std::size_t yDim_flat = yDesc_flat.GetSize();
+    assert(yDim_flat > 0 && yDim_flat <= 5);
+    std::string kernel_name = "SubTensorOpWithScalar" + std::to_string(yDim_flat) + "d";
+    const miopenDataType_t dataType = yDesc_flat.GetType();
 
-        handle.GetKernel("SetTensor", "", program_name, "SetTensor", vld, vgd, parms)(
-            y, miopen_alpha, global_threads);
+    std::string network_config = "set " + std::to_string(dataType);
+    for(auto& len : yDesc_flat.GetLengths())
+    {
+        network_config += " " + std::to_string(len);
     }
-    break;
+    std::string program_name = "MIOpenSubTensorOpWithScalarKernel.cl";
+    std::vector<std::size_t> worker_sizes = get_worker_sizes(yDesc_flat.GetLengths());
+    std::size_t wgd = std::accumulate(worker_sizes.begin(),
+                                      worker_sizes.end(),
+                                      std::size_t{1},
+                                      std::multiplies<std::size_t>());
+   
+   std::size_t wld = 256 < wgd ? 256 : wgd;
+
+    std::string parms = "-DSUBTENSOR_OP_WITH_SCALAR=SUBTENSOR_OP_WITH_SCALAR_SET" +
+                        parms_half_or_float(dataType);
+    for(int i = 0; i < yDim_flat; ++i)
+    {
+        parms += " -DWORK_LENGTH_" + std::to_string(i) + "=" + std::to_string(worker_sizes[i]);
     }
-}
 
+   switch(yDim_flat)
+    {
+        case 1:
+        {
+            handle.GetKernel(kernel_name, network_config, program_name,
+                             kernel_name, {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                             y,
+                             *(static_cast<const float*>(alpha)),
+                             0,
+                             int(yDesc_flat.GetStrides()[0]),
+                             int(yDesc_flat.GetLengths()[0]));
+            break;
+        }
+        case 2:
+        {
+            handle.GetKernel(kernel_name, network_config, program_name,
+                             kernel_name, {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                             y,
+                             *(static_cast<const float*>(alpha)),
+                             0,
+                             int(yDesc_flat.GetStrides()[0]),
+                             int(yDesc_flat.GetStrides()[1]),
+                             int(yDesc_flat.GetLengths()[0]),
+                             int(yDesc_flat.GetLengths()[1]));
+            break;
+        }
+       case 3:
+        {
+            handle.GetKernel(kernel_name, network_config, program_name,
+                             kernel_name, {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                             y,
+                             *(static_cast<const float*>(alpha)),
+                             0,
+                             int(yDesc_flat.GetStrides()[0]),
+                             int(yDesc_flat.GetStrides()[1]),
+                             int(yDesc_flat.GetStrides()[2]),
+                             int(yDesc_flat.GetLengths()[0]),
+                             int(yDesc_flat.GetLengths()[1]),
+                             int(yDesc_flat.GetLengths()[2]));
+            break;
+        }
+        case 4:
+        {
+            handle.GetKernel(kernel_name, network_config, program_name,
+                             kernel_name, {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                             y,
+                             *(static_cast<const float*>(alpha)),
+                             0,
+                             int(yDesc_flat.GetStrides()[0]),
+                             int(yDesc_flat.GetStrides()[1]),
+                             int(yDesc_flat.GetStrides()[2]),
+                             int(yDesc_flat.GetStrides()[3]),
+                             int(yDesc_flat.GetLengths()[0]),
+                             int(yDesc_flat.GetLengths()[1]),
+                             int(yDesc_flat.GetLengths()[2]),
+                             int(yDesc_flat.GetLengths()[3]));
+            break;
+        }
+       case 5:
+        {
+            handle.GetKernel(kernel_name, network_config, program_name,
+                             kernel_name, {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                             y,
+                             *(static_cast<const float*>(alpha)),
+                             0,
+                             int(yDesc_flat.GetStrides()[0]),
+                             int(yDesc_flat.GetStrides()[1]),
+                             int(yDesc_flat.GetStrides()[2]),
+                             int(yDesc_flat.GetStrides()[3]),
+                             int(yDesc_flat.GetStrides()[4]),
+                             int(yDesc_flat.GetLengths()[0]),
+                             int(yDesc_flat.GetLengths()[1]),
+                             int(yDesc_flat.GetLengths()[2]),
+                             int(yDesc_flat.GetLengths()[3]),
+                             int(yDesc_flat.GetLengths()[4]));
+            break;
+        }
+        default: assert(false);
+    }
+}
 void ScaleTensor(Handle& handle, const TensorDescriptor& yDesc, Data_t y, const void* alpha)
 {
 
@@ -143,60 +347,208 @@ static bool IsBitmapLeadingOnes(unsigned int& bitmap, int n_size, int first_not_
     return leading_ones;
 }
 
-void OpTensor(Handle& handle,
-              miopenTensorOp_t tensorOp,
-              const void* alpha0,
-              const TensorDescriptor& aTensorDesc,
-              ConstData_t ATensor,
-              const void* alpha1,
-              const TensorDescriptor& bTensorDesc,
-              ConstData_t BTensor,
-              const void* beta,
-              const TensorDescriptor& cTensorDesc,
-              Data_t CTensor,
-              const size_t Aoffset,
-              const size_t Boffset,
-              const size_t Coffset)
+void OpTensor3d(Handle& handle,
+                miopenTensorOp_t tensorOp,
+                const void* alpha0,
+                const TensorDescriptor& aTensorDesc,
+                ConstData_t ATensor,
+                const void* alpha1,
+                const TensorDescriptor& bTensorDesc,
+                ConstData_t BTensor,
+                const void* beta,
+                const TensorDescriptor& cTensorDesc,
+                Data_t CTensor,
+                const size_t Aoffset,
+                const size_t Boffset,
+                const size_t Coffset)
 {
+   auto alens = aTensorDesc.GetLengths();
+    auto blens = bTensorDesc.GetLengths();
+    auto clens = cTensorDesc.GetLengths();
 
-    if(ATensor == nullptr || BTensor == nullptr || CTensor == nullptr)
-    {
-        MIOPEN_THROW(miopenStatusBadParm);
-    }
+    auto astrides = aTensorDesc.GetStrides();
+    auto bstrides = bTensorDesc.GetStrides();
+    auto cstrides = cTensorDesc.GetStrides();
 
-    // if(aTensorDesc != cTensorDesc)
-    if(aTensorDesc.GetElementSize() != cTensorDesc.GetElementSize())
+    auto bsize = blens.size();
+    // first_not_one is incorrect if btensor size equal to 1
+    auto first_not_one = std::find_if(blens.rbegin(), blens.rend(), [](int i) { return i != 1; });
+    auto d             = std::distance(blens.begin(), first_not_one.base());
+
+    // quick fix
+    int num_wg = first_not_one != blens.rend() ? (*first_not_one == 0 ? 1 : *first_not_one) : 1;
+    int work_per_wg = std::accumulate(clens.begin() + d, clens.end(), 1, std::multiplies<int>());
+
+    unsigned int bitmap = 0;
+    // update bitmap for first_not_one
+    bitmap |= (1 << (bsize - d));
+
+    // (d-2) is because distance starts from 1 and 0
+    // also, we need to go past the "first_not_one" as that is already
+    // accounted for in the bitmap
+    CreateBitmapAndGrid(bitmap, blens, clens, num_wg, work_per_wg, (d - 2));
+
+#if(MIO_TENSOROCL_DEBUG == 1)
+    printf("bitmap: %u\n", bitmap);
+    printf("work_per_wg: %d, num_wg: %d\n", work_per_wg, num_wg);
+#endif
+
+    int num_wg_orig = num_wg;
+    int max_num_wg  = 4096;
+    num_wg          = num_wg > max_num_wg ? max_num_wg : num_wg;
+
+    size_t local_threads = 256;
+
+    std::string network_config{};
+
+    network_config = std::to_string(bTensorDesc.GetType()) + std::to_string(aTensorDesc.GetType()) +
+                     std::to_string(tensorOp);
+
+    float miopen_alpha0, miopen_alpha1, miopen_beta;
+    switch(bTensorDesc.GetType())
     {
-        MIOPEN_THROW("A and C Tensors do not match");
+       case miopenFloat:
+       case miopenHalf:
+       {
+           miopen_alpha0 = *(static_cast<const float*>(alpha0));
+           miopen_alpha1 = *(static_cast<const float*>(alpha1));
+           miopen_beta   = *(static_cast<const float*>(beta));
+       }
+       break;
     }
+   std::string parms = " -DMIOPEN_TYPE=" + GetDataType(bTensorDesc.GetType());
 
-    if(bTensorDesc.GetType() != cTensorDesc.GetType())
+    if(aTensorDesc.GetType() == miopenFloat)
     {
-        MIOPEN_THROW("Datatypes for B and C tensors do not match !");
+       parms += " -DMIOPEN_USE_FP16=0";
+        parms += " -DMIOPEN_USE_FP32=1";
     }
-
-    auto blens = bTensorDesc.GetLengths();
-    auto clens = cTensorDesc.GetLengths();
-    auto dims  = clens.size();
-
-    if(clens.size() > 5)
+    else if(aTensorDesc.GetType() == miopenHalf)
     {
-        MIOPEN_THROW("Tensor dimension larger than 5: " + std::to_string(clens.size()));
+       parms += " -DMIOPEN_USE_FP16=1";
+           parms += " -DMIOPEN_USE_FP32=0";
     }
 
-    if(blens.size() != clens.size())
+    parms += " -DMIOPEN_TENSOR_OP=";
+    switch(tensorOp)
     {
-        MIOPEN_THROW("Number of dims in B and C Tensors do not match: " +
-                     std::to_string(blens.size()) + ", " + std::to_string(clens.size()));
+       case 0: parms += "miopenAdd"; break;
+       case 1: parms += "miopenMul"; break;
+        case 2: parms += "miopenMin"; break;
+        case 3: parms += "miopenMax"; break;
     }
+       std::string program_name = "MIOpenTensorKernels.cl";
 
-    for(auto i = 0; i < clens.size(); i++)
+   const std::vector<size_t> vld{local_threads, 1, 1};
+
+   if(clens[0] == 1 && blens[0] == 1 && alens[0] == 1 &&
+           (blens[1] == clens[1] || blens[1] == 1) && blens[2] == clens[2])
     {
-        if(blens[i] != 1 && blens[i] != clens[i])
-        {
-            MIOPEN_THROW("BTensor dim != 1 && BTensor dim != CTensor dim: " + std::to_string(i));
-        }
-    }
+       parms += " -DUSE_2D_TENSOR_LITE";
+
+           // for naive tensor ops
+           size_t RD_BLCK              = (clens[2] % 4 == 0) ? 4 : (clens[2] % 2 == 0) ? 2 : 1;
+           const std::string data_type = GetDataType(bTensorDesc.GetType());
+           const std::string READ_TYPE =
+               (RD_BLCK == 1) ? data_type : data_type + std::to_string(RD_BLCK);
+
+       size_t MAP_RD = clens[2] / RD_BLCK;
+           parms += " -DRD_BLCK=" + std::to_string(RD_BLCK) + " -DMAP_RD=" +
+                     std::to_string(MAP_RD) + " -DREAD_TYPE=" + READ_TYPE;
+
+       if(!float_equal(miopen_beta, 0.0))
+           {
+           parms += " -DBETA";
+       }
+
+       if(blens[1] == 1)
+       {
+           parms += " -DBIAS";
+       }
+
+       num_wg = clens[1];
+        num_wg = num_wg > max_num_wg ? max_num_wg : num_wg;
+        parms += " -DMAX_NUM_WG=" + std::to_string(max_num_wg);
+
+           const std::vector<size_t> vgd1{MAP_RD, static_cast<size_t>(num_wg), 1};
+       handle.GetKernel(
+                "Op2dTensorLite", network_config, program_name, "Op2dTensorLite", vld, vgd1, parms)(
+                ATensor,
+                int(astrides[1]), // a_cstride,
+                BTensor,
+                int(bstrides[1]), // b_cstride,
+                CTensor,
+                int(cstrides[1]), // c_cstride,
+                miopen_alpha0,
+                miopen_alpha1,
+                miopen_beta,
+                long(Aoffset),
+                long(Boffset),
+                long(Coffset),
+                int(clens[1])
+       );
+   }
+   else
+   {
+        // Special case for adding tensors in place
+            size_t global_threads;
+            global_threads = num_wg * local_threads;
+            const std::vector<size_t> vgd{global_threads, 1, 1};
+
+            parms += " -DUSE_3D_TENSOR_GENERIC";
+            parms += " -DMAX_NUM_WG=" + std::to_string(max_num_wg);
+
+            handle.GetKernel("Op3dTensorGeneric",
+                             network_config,
+                             program_name,
+                             "Op3dTensorGeneric",
+                             vld,
+                             vgd,
+                             parms)(ATensor,
+                                    int(astrides[0]), // a_nstride,
+                                    int(astrides[1]), // a_cstride,
+                                    BTensor,
+                                    int(blens[1]),    // b_c,
+                                    int(blens[2]),    // b_h,
+                                    int(bstrides[0]), // b_nstride,
+                                    int(bstrides[1]), // b_cstride,
+                                    CTensor,
+                                    int(clens[1]),    // c_c,
+                                    int(clens[2]),    // c_h,
+                                    int(cstrides[0]), // c_nstride,
+                                    int(cstrides[1]), // c_cstride,
+                                    miopen_alpha0,
+                                    miopen_alpha1,
+                                    miopen_beta,
+                                    bitmap,
+                                    work_per_wg,
+                                    long(Aoffset),
+                                    long(Boffset),
+                                    long(Coffset),
+                                    int(num_wg_orig));
+
+   }   
+   
+}
+
+void OpTensor4d(Handle& handle,
+                miopenTensorOp_t tensorOp,
+                const void* alpha0,
+                const TensorDescriptor& aTensorDesc,
+                ConstData_t ATensor,
+                const void* alpha1,
+                const TensorDescriptor& bTensorDesc,
+                ConstData_t BTensor,
+                const void* beta,
+                const TensorDescriptor& cTensorDesc,
+                Data_t CTensor,
+                const size_t Aoffset,
+                const size_t Boffset,
+                const size_t Coffset)
+{
+   auto blens = bTensorDesc.GetLengths();
+    auto clens = cTensorDesc.GetLengths();
+    auto dims  = clens.size();
 
     auto astrides = aTensorDesc.GetStrides();
     auto bstrides = bTensorDesc.GetStrides();
@@ -220,12 +572,16 @@ void OpTensor(Handle& handle,
     // accounted for in the bitmap
     CreateBitmapAndGrid(bitmap, blens, clens, num_wg, work_per_wg, (d - 2));
 
+    // quick fix for btensor = <1, 1, 1, 1>
+    if(bTensorDesc.GetElementSize() == 1)
+        bitmap = 4;
+
 #if(MIO_TENSOROCL_DEBUG == 1)
     printf("bitmap: %u\n", bitmap);
     printf("work_per_wg: %d, num_wg: %d\n", work_per_wg, num_wg);
 #endif
 
-    // Forward Convolution Bias specialization
+   // Forward Convolution Bias specialization
     // for fwd-bias, bitmap looks like <0, 1, 0, 0>
     // Is the no. of work-groups and the work for each wg balanced?
     auto fwd_conv_bias = bitmap == (1 << 2) ? 1 : 0;
@@ -239,9 +595,9 @@ void OpTensor(Handle& handle,
         incr_wg = 1;
     }
 
-    int num_wg_1   = num_wg;
-    int max_num_wg = 4096;
-    num_wg         = num_wg > max_num_wg ? max_num_wg : num_wg;
+    int num_wg_orig = num_wg;
+    int max_num_wg  = 4096;
+    num_wg          = num_wg > max_num_wg ? max_num_wg : num_wg;
 
     size_t local_threads = 256;
 
@@ -253,308 +609,600 @@ void OpTensor(Handle& handle,
         local_threads = 64;
     }
 
-    std::string parms = " -DFWD_CONV_BIAS=" + std::to_string(fwd_conv_bias) + " -DINCR_WG=" +
-                        std::to_string(incr_wg) + " -DLEADING_ONES=" +
-                        std::to_string(leading_ones) + " -DMIOPEN_TYPE=" +
-                        GetDataType(bTensorDesc.GetType()) + " -DFIRST_NOT_ONE=" +
-                        std::to_string(d - 1) + " -DMIOPEN_TENSOR_DIMS=" + std::to_string(bsize) +
-                        " -DMAX_NUM_WG=" + std::to_string(max_num_wg);
+    std::string network_config{};
 
-    parms += " -DMIOPEN_TENSOR_OP=";
-    switch(tensorOp)
-    {
-    case 0: parms += "miopenAdd"; break;
-    case 1: parms += "miopenMul"; break;
-    case 2: parms += "miopenMin"; break;
-    case 3: parms += "miopenMax"; break;
-    }
-    std::string program_name = "MIOpenTensorKernels.cl";
+    network_config += GetDataType(bTensorDesc.GetType()) + std::to_string(max_num_wg);
 
-    const std::vector<size_t> vld{local_threads, 1, 1};
+    std::string program_name = "MIOpenTensorKernels.cl";   
+   const std::vector<size_t> vld{local_threads, 1, 1};
 
     // Special case for adding tensors in place
     size_t global_threads;
-    if(dims == 4)
-        global_threads = (leading_ones == 1 && (d - 1) == 3) ? num_wg : num_wg * local_threads;
-    else
-        global_threads = (leading_ones == 1 && (d - 1) == dims) ? num_wg : num_wg * local_threads;
-    global_threads     = (global_threads < local_threads) ? local_threads : global_threads;
+    global_threads =
+        (static_cast<int>(leading_ones) == 1 && (d - 1) == 3) ? num_wg : num_wg * local_threads;
+    global_threads = (global_threads < local_threads) ? local_threads : global_threads;
 
     const std::vector<size_t> vgd{global_threads, 1, 1};
 
-    float miopen_alpha0, miopen_alpha1, miopen_beta;
-    switch(bTensorDesc.GetType())
-    {
-    case miopenFloat:
-    case miopenHalf:
-    {
-        miopen_alpha0 = *(static_cast<const float*>(alpha0));
-        miopen_alpha1 = *(static_cast<const float*>(alpha1));
-        miopen_beta   = *(static_cast<const float*>(beta));
-    }
-    break;
-    }
-
     bool packed_tensor = true;
 
-    auto alens = aTensorDesc.GetLengths();
-    packed_tensor &= IsPackedTensor(astrides, alens);
-    packed_tensor &= IsPackedTensor(bstrides, blens);
-    packed_tensor &= IsPackedTensor(cstrides, clens);
+   auto alens = aTensorDesc.GetLengths();  
+   packed_tensor &= IsPackedTensor(astrides, alens);
+   packed_tensor &= IsPackedTensor(bstrides, blens);
+   packed_tensor &= IsPackedTensor(cstrides, clens);
+
+    // auto alens = aTensorDesc.GetLengths();
+    //packed_tensor &= aTensorDesc.IsPacked();
+    //packed_tensor &= bTensorDesc.IsPacked();
+    //packed_tensor &= cTensorDesc.IsPacked();
+
+    bool packed_equal_tensor =
+        packed_tensor && (bTensorDesc.GetElementSize() == cTensorDesc.GetElementSize());
 
 #if(MIO_TENSOROCL_DEBUG == 1)
     printf("packed_tensor: %d\n", packed_tensor);
+    printf("equal_tensor: %d\n", bTensorDesc.GetElementSize() == cTensorDesc.GetElementSize());
 #endif
 
-    if(bsize == 5)
-    {
-        handle.GetKernel(
-            "Op5dTensorGeneric", "", program_name, "Op5dTensorGeneric", vld, vgd, parms)(
-            ATensor,
-            int(astrides[0]),
-            int(astrides[1]),
-            int(astrides[2]),
-            int(astrides[3]),
-            BTensor,
-            int(blens[1]),    // b_c,
-            int(blens[2]),    // b_d,
-            int(blens[3]),    // b_h,
-            int(blens[4]),    // b_w,
-            int(bstrides[0]), // b_nstride,
-            int(bstrides[1]), // b_cstride,
-            int(bstrides[2]), // b_dstride,
-            int(bstrides[3]), // b_hstride,
-            CTensor,
-            int(clens[1]),    // c_c,
-            int(clens[2]),    // c_d,
-            int(clens[3]),    // c_h,
-            int(clens[4]),    // c_w,
-            int(cstrides[0]), // c_nstride,
-            int(cstrides[1]), // c_cstride,
-            int(cstrides[2]), // c_dstride,
-            int(cstrides[3]), // c_hstride,
-            miopen_alpha0,
-            miopen_alpha1,
-            miopen_beta,
-            bitmap,
-            work_per_wg,
-            long(Aoffset),
-            long(Boffset),
-            long(Coffset),
-            int(num_wg_1));
-    }
-    else if(bsize == 3)
-    {
-        handle.GetKernel(
-            "Op3dTensorGeneric", "", program_name, "Op3dTensorGeneric", vld, vgd, parms)(
-            ATensor,
-            int(astrides[0]), // a_nstride,
-            int(astrides[1]), // a_cstride,
-            BTensor,
-            int(blens[1]),    // b_c,
-            int(blens[2]),    // b_h,
-            int(bstrides[0]), // b_nstride,
-            int(bstrides[1]), // b_cstride,
-            CTensor,
-            int(clens[1]),    // c_c,
-            int(clens[2]),    // c_h,
-            int(cstrides[0]), // c_nstride,
-            int(cstrides[1]), // c_cstride,
-            miopen_alpha0,
-            miopen_alpha1,
-            miopen_beta,
-            bitmap,
-            work_per_wg,
-            long(Aoffset),
-            long(Boffset),
-            long(Coffset),
-            int(num_wg_1));
-    }
-    else if(bsize == 2)
-    {
-        handle.GetKernel(
-            "Op2dTensorGeneric", "", program_name, "Op2dTensorGeneric", vld, vgd, parms)(
-            ATensor,
-            int(astrides[0]),
-            BTensor,
-            int(blens[1]),
-            int(bstrides[0]),
-            CTensor,
-            int(clens[1]),
-            int(cstrides[0]),
-            miopen_alpha0,
-            miopen_alpha1,
-            miopen_beta,
-            bitmap,
-            work_per_wg,
-            long(Aoffset),
-            long(Boffset),
-            long(Coffset),
-            int(num_wg_1));
-    }
-    else if(bsize == 1)
-    {
-        handle.GetKernel(
-            "Op1dTensorGeneric", "", program_name, "Op1dTensorGeneric", vld, vgd, parms)(
-            ATensor,
-            BTensor,
-            int(blens[0]),
-            CTensor,
-            int(clens[0]),
-            miopen_alpha0,
-            miopen_alpha1,
-            miopen_beta,
-            bitmap,
-            work_per_wg,
-            long(Aoffset),
-            long(Boffset),
-            long(Coffset),
-            int(num_wg_1));
-    }
-    else if(fwd_conv_bias)
-    {
-
-        if(packed_tensor)
+    network_config += std::to_string(bTensorDesc.GetType()) +
+                      std::to_string(aTensorDesc.GetType()) + std::to_string(tensorOp) +
+                      std::to_string(global_threads) + std::to_string(local_threads);
+
+   float miopen_alpha0, miopen_alpha1, miopen_beta;
+    switch(bTensorDesc.GetType())
+    {
+        case miopenFloat:
+        case miopenHalf:
         {
-            handle.GetKernel(
-                "OpTensorFwdBias", "", program_name, "OpTensorFwdBias", vld, vgd, parms)(
+            miopen_alpha0 = *(static_cast<const float*>(alpha0));
+            miopen_alpha1 = *(static_cast<const float*>(alpha1));
+            miopen_beta   = *(static_cast<const float*>(beta));
+        }
+        break;
+    }
+   std::string parms = " -DMIOPEN_TYPE=" + GetDataType(bTensorDesc.GetType()) +
+                            " -DMAX_NUM_WG=" + std::to_string(max_num_wg);
+
+   if(aTensorDesc.GetType() == miopenFloat)
+   {
+           parms += " -DMIOPEN_USE_FP16=0";
+           parms += " -DMIOPEN_USE_FP32=1";
+       }
+   else if(aTensorDesc.GetType() == miopenHalf)
+       {
+           parms += " -DMIOPEN_USE_FP16=1";
+           parms += " -DMIOPEN_USE_FP32=0";
+       }
+
+       parms += " -DMIOPEN_TENSOR_OP=";
+       switch(tensorOp)
+    {
+       case 0: parms += "miopenAdd"; break;
+        case 1: parms += "miopenMul"; break;
+        case 2: parms += "miopenMin"; break;
+        case 3: parms += "miopenMax"; break;
+       }
+   if(fwd_conv_bias != 0)
+       {
+       parms += " -DINCR_WG=" + std::to_string(incr_wg);
+
+       if(packed_tensor)
+       {
+           parms += " -DUSE_FWD_BIAS";
+
+           handle.GetKernel(   "OpTensorFwdBias",
+                               network_config,
+                                 program_name,
+                                 "OpTensorFwdBias",
+                                 vld,
+                                 vgd,
+                                 parms)(ATensor,
+                                        BTensor,
+                                        int(blens[1]),
+                                        CTensor,
+                                        int(clens[0]),
+                                        int(cstrides[0]),
+                                        int(cstrides[1]),
+                                        work_per_wg,
+                                        miopen_alpha0,
+                                        miopen_alpha1,
+                                        miopen_beta,
+                                        long(Aoffset),
+                                        long(Boffset),
+                                        long(Coffset),
+                                        int(num_wg_orig));
+           }
+       else
+           {
+           parms += " -DUSE_FWD_BIAS_GENERIC";
+            handle.GetKernel(  "OpTensorFwdBiasGeneric",
+                                 network_config,
+                                 program_name,
+                                 "OpTensorFwdBiasGeneric",
+                                 vld,
+                                 vgd,
+                                 parms)(ATensor,
+                                        int(astrides[0]),
+                                        int(astrides[1]),
+                                        int(astrides[2]),
+                                        BTensor,
+                                        int(blens[1]),
+                                        int(bstrides[1]),
+                                        CTensor,
+                                        int(clens[0]),
+                                        int(clens[3]),
+                                        int(cstrides[0]),
+                                        int(cstrides[1]),
+                                        int(cstrides[2]),
+                                        miopen_alpha0,
+                                        miopen_alpha1,
+                                        miopen_beta,
+                                        work_per_wg,
+                                        long(Aoffset),
+                                        long(Boffset),
+                                        long(Coffset),
+                                        int(num_wg_orig));
+       }
+
+   }
+   // precede leading_ones for bitmap = 1,1,1,1
+       else if(packed_equal_tensor)
+       {
+       parms += " -DUSE_4D_TENSOR_LITE";
+        // for naive tensor ops
+       size_t RD_BLCK              = (clens[2] % 4 == 0) ? 4 : (clens[2] % 2 == 0) ? 2 : 1;
+           const std::string data_type = GetDataType(bTensorDesc.GetType());
+
+       size_t MAP_RD   = clens[2] / RD_BLCK;
+       size_t TENS_LEN = cTensorDesc.GetElementSize();
+           RD_BLCK =
+                (TENS_LEN % 4 == 0) ? 4 : (TENS_LEN % 3 == 0) ? 3 : (TENS_LEN % 2 == 0) ? 2 : 1;
+           MAP_RD = TENS_LEN / RD_BLCK;
+
+           const std::string READ_TYPE =
+                (RD_BLCK == 1) ? data_type : data_type + std::to_string(RD_BLCK);
+
+           parms += " -DRD_BLCK=" + std::to_string(RD_BLCK) + " -DMAP_RD=" +
+                     std::to_string(MAP_RD) + " -DREAD_TYPE=" + READ_TYPE;
+
+       if(!float_equal(miopen_beta, 0.0))
+           {
+           parms += " -DBETA";
+        }
+
+       const std::vector<size_t> vgd1{TENS_LEN / RD_BLCK, 1, 1};
+
+       handle.GetKernel(
+                "Op4dTensorLite", network_config, program_name, "Op4dTensorLite", vld, vgd1, parms)(
                 ATensor,
                 BTensor,
-                int(blens[1]),
                 CTensor,
-                int(clens[0]),
-                int(cstrides[0]),
-                int(cstrides[1]),
-                work_per_wg,
                 miopen_alpha0,
                 miopen_alpha1,
                 miopen_beta,
                 long(Aoffset),
                 long(Boffset),
-                long(Coffset),
-                int(num_wg_1));
-        }
-        else
-        {
+                long(Coffset));
+   }
+   else if(leading_ones)
+   {
+           parms += " -DFIRST_NOT_ONE=" + std::to_string(d - 1);
+       if(packed_tensor)
+        {   
+           parms += " -DUSE_LEADING_ONES";
+            handle.GetKernel(  "OpTensorLeadingOnes",
+                                 network_config,
+                                 program_name,
+                                 "OpTensorLeadingOnes",
+                                 vld,
+                                 vgd,
+                                 parms)(ATensor,
+                                        BTensor,
+                                        CTensor,
+                                        int(clens[1]),
+                                        int(clens[2]),
+                                        int(clens[3]),
+                                        int(cstrides[0]),
+                                        int(cstrides[1]),
+                                        work_per_wg,
+                                        miopen_alpha0,
+                                        miopen_alpha1,
+                                        miopen_beta,
+                                        long(Aoffset),
+                                        long(Boffset),
+                                        long(Coffset),
+                                        int(num_wg_orig));
+       }
+       else
+           {
+           parms += " -DUSE_LEADING_ONES_GENERIC";
+
+           handle.GetKernel(   "OpTensorLeadingOnesGeneric",
+                                 network_config,
+                                 program_name,
+                                 "OpTensorLeadingOnesGeneric",
+                                 vld,
+                                 vgd,
+                                 parms)(ATensor,
+                                        int(astrides[0]),
+                                        int(astrides[1]),
+                                        int(astrides[2]),
+                                        BTensor,
+                                        int(bstrides[0]),
+                                        int(bstrides[1]),
+                                        int(bstrides[2]),
+                                        CTensor,
+                                        int(clens[1]),
+                                        int(clens[2]),
+                                        int(clens[3]),
+                                        int(cstrides[0]),
+                                        int(cstrides[1]),
+                                        int(cstrides[2]),
+                                        miopen_alpha0,
+                                        miopen_alpha1,
+                                        miopen_beta,
+                                        work_per_wg,
+                                        long(Aoffset),
+                                        long(Boffset),
+                                        long(Coffset),
+                                        int(num_wg_orig));
+       }
+
+   }
+   else
+    {
+       parms += " -DUSE_4D_TENSOR_GENERIC";
 
-            handle.GetKernel("OpTensorFwdBiasGeneric",
-                             "",
+       handle.GetKernel(   "Op4dTensorGeneric",
+                             network_config,
                              program_name,
-                             "OpTensorFwdBiasGeneric",
+                             "Op4dTensorGeneric",
                              vld,
                              vgd,
                              parms)(ATensor,
-                                    int(astrides[0]),
-                                    int(astrides[1]),
-                                    int(astrides[2]),
+                                    int(astrides[0]), // a_nstride,
+                                    int(astrides[1]), // a_cstride,
+                                    int(astrides[2]), // a_hstride,
                                     BTensor,
-                                    int(blens[1]),
-                                    int(bstrides[1]),
+                                    int(blens[1]),    // b_c,
+                                    int(blens[2]),    // b_h,
+                                    int(blens[3]),    // b_w,
+                                    int(bstrides[0]), // b_nstride,
+                                    int(bstrides[1]), // b_cstride,
+                                    int(bstrides[2]), // b_hstride,
                                     CTensor,
-                                    int(clens[0]),
-                                    int(clens[3]),
-                                    int(cstrides[0]),
-                                    int(cstrides[1]),
-                                    int(cstrides[2]),
+                                    int(clens[1]),    // c_c,
+                                    int(clens[2]),    // c_h,
+                                    int(clens[3]),    // c_w,
+                                    int(cstrides[0]), // c_nstride,
+                                    int(cstrides[1]), // c_cstride,
+                                    int(cstrides[2]), // c_hstride,
                                     miopen_alpha0,
                                     miopen_alpha1,
                                     miopen_beta,
+                                    bitmap,
                                     work_per_wg,
                                     long(Aoffset),
                                     long(Boffset),
                                     long(Coffset),
-                                    int(num_wg_1));
+                                    int(num_wg_orig));
+   }
+
+   
+}
+void OpTensorOther(Handle& handle,
+                   miopenTensorOp_t tensorOp,
+                   const void* alpha0,
+                   const TensorDescriptor& aTensorDesc,
+                   ConstData_t ATensor,
+                   const void* alpha1,
+                   const TensorDescriptor& bTensorDesc,
+                   ConstData_t BTensor,
+                   const void* beta,
+                   const TensorDescriptor& cTensorDesc,
+                   Data_t CTensor,
+                   const size_t Aoffset,
+                   const size_t Boffset,
+                   const size_t Coffset)
+{
+
+    auto blens = bTensorDesc.GetLengths();
+    auto clens = cTensorDesc.GetLengths();
+
+    auto astrides = aTensorDesc.GetStrides();
+    auto bstrides = bTensorDesc.GetStrides();
+    auto bsize    = blens.size();
+    auto cstrides = cTensorDesc.GetStrides();
+
+    // first_not_one is incorrect if btensor size equal to 1
+    auto first_not_one = std::find_if(blens.rbegin(), blens.rend(), [](int i) { return i != 1; });
+    auto d             = std::distance(blens.begin(), first_not_one.base());
+
+    // quick fix
+    int num_wg = first_not_one != blens.rend() ? (*first_not_one == 0 ? 1 : *first_not_one) : 1;
+    int work_per_wg = std::accumulate(clens.begin() + d, clens.end(), 1, std::multiplies<int>());
+
+    unsigned int bitmap = 0;
+    // update bitmap for first_not_one
+    bitmap |= (1 << (bsize - d));
+
+    // (d-2) is because distance starts from 1 and 0
+    // also, we need to go past the "first_not_one" as that is already
+    // accounted for in the bitmap
+    CreateBitmapAndGrid(bitmap, blens, clens, num_wg, work_per_wg, (d - 2));
+
+#if(MIO_TENSOROCL_DEBUG == 1)
+    printf("bitmap: %u\n", bitmap);
+    printf("work_per_wg: %d, num_wg: %d\n", work_per_wg, num_wg);
+#endif
+
+    int num_wg_orig = num_wg;
+    int max_num_wg  = 4096;
+    num_wg          = num_wg > max_num_wg ? max_num_wg : num_wg;
+
+    size_t local_threads = 256;
+   std::string program_name = "MIOpenTensorKernels.cl";
+
+    const std::vector<size_t> vld{local_threads, 1, 1};
+
+    // Special case for adding tensors in place
+    size_t global_threads;
+    global_threads = num_wg * local_threads;
+
+    const std::vector<size_t> vgd{global_threads, 1, 1};
+
+    std::string network_config{};
+    network_config += std::to_string(bTensorDesc.GetType()) +
+                      std::to_string(aTensorDesc.GetType()) + std::to_string(tensorOp) +
+                      std::to_string(global_threads) + std::to_string(local_threads);
+
+   float miopen_alpha0, miopen_alpha1, miopen_beta;
+    switch(bTensorDesc.GetType())
+    {   
+        case miopenFloat:
+        case miopenHalf:
+        {   
+            miopen_alpha0 = *(static_cast<const float*>(alpha0));
+            miopen_alpha1 = *(static_cast<const float*>(alpha1));
+            miopen_beta   = *(static_cast<const float*>(beta));
         }
+        break;
     }
-    else if(leading_ones)
+
+   std::string parms = " -DMIOPEN_TYPE=" + GetDataType(bTensorDesc.GetType()) +
+                            " -DMAX_NUM_WG=" + std::to_string(max_num_wg);
+
+       if(aTensorDesc.GetType() == miopenFloat)
+       {
+       parms += " -DMIOPEN_USE_FP16=0";
+           parms += " -DMIOPEN_USE_FP32=1";
+       }
+    else if(aTensorDesc.GetType() == miopenHalf)
     {
-        if(packed_tensor)
-        {
-            handle.GetKernel(
-                "OpTensorLeadingOnes", "", program_name, "OpTensorLeadingOnes", vld, vgd, parms)(
-                ATensor,
-                BTensor,
-                CTensor,
-                int(clens[1]),
-                int(clens[2]),
-                int(clens[3]),
-                int(cstrides[0]),
-                int(cstrides[1]),
-                work_per_wg,
-                miopen_alpha0,
-                miopen_alpha1,
-                miopen_beta,
-                long(Aoffset),
-                long(Boffset),
-                long(Coffset),
-                int(num_wg_1));
-        }
-        else
-        {
+           parms += " -DMIOPEN_USE_FP16=1";
+        parms += " -DMIOPEN_USE_FP32=0";
+       }
+
+   parms += " -DMIOPEN_TENSOR_OP=";
+       switch(tensorOp)
+       {
+           case 0: parms += "miopenAdd"; break;
+        case 1: parms += "miopenMul"; break;
+        case 2: parms += "miopenMin"; break;
+        case 3: parms += "miopenMax"; break;
+   }
+
+   if(bsize == 5)
+    {
+           parms += " -DUSE_5D_TENSOR_GENERIC";
 
-            handle.GetKernel("OpTensorLeadingOnesGeneric",
-                             "",
+           handle.GetKernel(   "Op5dTensorGeneric",
+                             network_config,
                              program_name,
-                             "OpTensorLeadingOnesGeneric",
+                             "Op5dTensorGeneric",
                              vld,
                              vgd,
                              parms)(ATensor,
                                     int(astrides[0]),
                                     int(astrides[1]),
                                     int(astrides[2]),
+                                    int(astrides[3]),
+                                    BTensor,
+                                    int(blens[1]),    // b_c,
+                                    int(blens[2]),    // b_d,
+                                    int(blens[3]),    // b_h,
+                                    int(blens[4]),    // b_w,
+                                    int(bstrides[0]), // b_nstride,
+                                    int(bstrides[1]), // b_cstride,
+                                    int(bstrides[2]), // b_dstride,
+                                    int(bstrides[3]), // b_hstride,
+                                    CTensor,
+                                    int(clens[1]),    // c_c,
+                                    int(clens[2]),    // c_d,
+                                    int(clens[3]),    // c_h,
+                                    int(clens[4]),    // c_w,
+                                    int(cstrides[0]), // c_nstride,
+                                    int(cstrides[1]), // c_cstride,
+                                    int(cstrides[2]), // c_dstride,
+                                    int(cstrides[3]), // c_hstride,
+                                    miopen_alpha0,
+                                    miopen_alpha1,
+                                    miopen_beta,
+                                    bitmap,
+                                    work_per_wg,
+                                    long(Aoffset),
+                                    long(Boffset),
+                                    long(Coffset),
+                                    int(num_wg_orig));
+   }
+   else if(bsize == 2)
+    {
+           parms += " -DUSE_2D_TENSOR_GENERIC";
+
+       handle.GetKernel(   "Op2dTensorGeneric",
+                             network_config,
+                             program_name,
+                             "Op2dTensorGeneric",
+                             vld,
+                             vgd,
+                             parms)(ATensor,
+                                    int(astrides[0]),
                                     BTensor,
+                                    int(blens[1]),
                                     int(bstrides[0]),
-                                    int(bstrides[1]),
-                                    int(bstrides[2]),
                                     CTensor,
                                     int(clens[1]),
-                                    int(clens[2]),
-                                    int(clens[3]),
                                     int(cstrides[0]),
-                                    int(cstrides[1]),
-                                    int(cstrides[2]),
                                     miopen_alpha0,
                                     miopen_alpha1,
                                     miopen_beta,
+                                    bitmap,
+                                    work_per_wg,
+                                    long(Aoffset),
+                                    long(Boffset),
+                                    long(Coffset),
+                                    int(num_wg_orig));
+   }
+   else if(bsize == 1)
+   {
+       parms += " -DUSE_1D_TENSOR_GENERIC";
+
+           handle.GetKernel(   "Op1dTensorGeneric",
+                             network_config,
+                             program_name,
+                             "Op1dTensorGeneric",
+                             vld,
+                             vgd,
+                             parms)(ATensor,
+                                    BTensor,
+                                    int(blens[0]),
+                                    CTensor,
+                                    int(clens[0]),
+                                    miopen_alpha0,
+                                    miopen_alpha1,
+                                    miopen_beta,
+                                    bitmap,
                                     work_per_wg,
                                     long(Aoffset),
                                     long(Boffset),
                                     long(Coffset),
-                                    int(num_wg_1));
+                                    int(num_wg_orig));
+   }
+}
+
+void OpTensor(Handle& handle,
+              miopenTensorOp_t tensorOp,
+              const void* alpha0,
+              const TensorDescriptor& aTensorDesc,
+              ConstData_t ATensor,
+              const void* alpha1,
+              const TensorDescriptor& bTensorDesc,
+              ConstData_t BTensor,
+              const void* beta,
+              const TensorDescriptor& cTensorDesc,
+              Data_t CTensor,
+              const size_t Aoffset,
+              const size_t Boffset,
+              const size_t Coffset)
+{
+   if(ATensor == nullptr || BTensor == nullptr || CTensor == nullptr)
+    {   
+        MIOPEN_THROW(miopenStatusBadParm);
+    }
+
+    // if(aTensorDesc != cTensorDesc)
+    if(aTensorDesc.GetElementSize() != cTensorDesc.GetElementSize())
+    {   
+        MIOPEN_THROW("A and C Tensors do not match");
+    }
+
+    if(bTensorDesc.GetType() != cTensorDesc.GetType())
+    {
+        MIOPEN_THROW("Datatypes for B and C tensors do not match !");
+    }
+
+    auto blens = bTensorDesc.GetLengths();
+#if(MIO_TENSOROCL_DEBUG == 1)
+    printf("blen:[");
+    for(auto len : blens)
+    {
+        printf(" %lu", len);
+    }
+    printf("]\n");
+#endif
+    auto clens = cTensorDesc.GetLengths();
+
+    if(clens.size() > 5)
+    {
+        MIOPEN_THROW("Tensor dimension larger than 5: " + std::to_string(clens.size()));
+    }
+   if(blens.size() != clens.size())
+    {
+        MIOPEN_THROW("Number of dims in B and C Tensors do not match: " +
+                     std::to_string(blens.size()) + ", " + std::to_string(clens.size()));
+    }
+
+    for(auto i = 0; i < clens.size(); i++)
+    {
+        if(blens[i] != 1 && blens[i] != clens[i])
+        {
+            MIOPEN_THROW("BTensor dim != 1 && BTensor dim != CTensor dim: " + std::to_string(i));
         }
     }
-    else
+
+    auto bsize = blens.size();
+   if(bsize == 3)
+    {
+        OpTensor3d(handle,
+                   tensorOp,
+                   alpha0,
+                   aTensorDesc,
+                   ATensor,
+                   alpha1,
+                   bTensorDesc,
+                   BTensor,
+                   beta,
+                   cTensorDesc,
+                   CTensor,
+                   Aoffset,
+                   Boffset,
+                   Coffset);
+    }
+    else if(bsize == 4)
+    {
+        OpTensor4d(handle,
+                   tensorOp,
+                   alpha0,
+                   aTensorDesc,
+                   ATensor,
+                   alpha1,
+                   bTensorDesc,
+                   BTensor,
+                   beta,
+                   cTensorDesc,
+                   CTensor,
+                   Aoffset,
+                   Boffset,
+                   Coffset);
+    }
+   else
     {
-        handle.GetKernel(
-            "Op4dTensorGeneric", "", program_name, "Op4dTensorGeneric", vld, vgd, parms)(
-            ATensor,
-            int(astrides[0]), // a_nstride,
-            int(astrides[1]), // a_cstride,
-            int(astrides[2]), // a_hstride,
-            BTensor,
-            int(blens[1]),    // b_c,
-            int(blens[2]),    // b_h,
-            int(blens[3]),    // b_w,
-            int(bstrides[0]), // b_nstride,
-            int(bstrides[1]), // b_cstride,
-            int(bstrides[2]), // b_hstride,
-            CTensor,
-            int(clens[1]),    // c_c,
-            int(clens[2]),    // c_h,
-            int(clens[3]),    // c_w,
-            int(cstrides[0]), // c_nstride,
-            int(cstrides[1]), // c_cstride,
-            int(cstrides[2]), // c_hstride,
-            miopen_alpha0,
-            miopen_alpha1,
-            miopen_beta,
-            bitmap,
-            work_per_wg,
-            long(Aoffset),
-            long(Boffset),
-            long(Coffset),
-            int(num_wg_1));
+        OpTensorOther(handle,
+                      tensorOp,
+                      alpha0,
+                      aTensorDesc,
+                      ATensor,
+                      alpha1,
+                      bTensorDesc,
+                      BTensor,
+                      beta,
+                      cTensorDesc,
+                      CTensor,
+                      Aoffset,
+                      Boffset,
+                      Coffset);
     }
+
 }
 
 struct copyTensorDesc
@@ -572,130 +1220,173 @@ void CopyTensor(Handle& handle,
                 int srcOffset,
                 int destOffset)
 {
-
-    using tensorDesc_t = copyTensorDesc;
-    if(src == nullptr || dest == nullptr)
+   if(src == nullptr || dest == nullptr)
     {
         MIOPEN_THROW(miopenStatusBadParm, "Null pointer for tensor.");
     }
-    if(srcDesc.GetElementSize() != destDesc.GetElementSize())
-    {
-        MIOPEN_THROW(miopenStatusBadParm, "Tensor data sizes do not match.");
-    }
 
     if(srcDesc.GetType() != destDesc.GetType())
     {
         MIOPEN_THROW(miopenStatusBadParm, "Tensor types do not match.");
     }
 
-    if(srcDesc.GetLengths().size() != destDesc.GetLengths().size())
+    if(srcDesc.GetLengths() != destDesc.GetLengths())
     {
         MIOPEN_THROW(miopenStatusBadParm, "Tensor dimension lengths do not match.");
     }
 
-    if(srcDesc.GetLengths().size() > 5 || destDesc.GetLengths().size() > 5)
+    auto flat_descriptors = GetConsistentFlattenedTensorDescriptors(srcDesc, destDesc);
+    const TensorDescriptor& srcDesc_flat = std::get<0>(flat_descriptors);
+    const TensorDescriptor& dstDesc_flat = std::get<1>(flat_descriptors);  
+   
+#ifndef NDEBUG
+    if(srcDesc.GetSize() != srcDesc_flat.GetSize())
     {
-        MIOPEN_THROW(miopenStatusBadParm, "Tensor dimension sizes unsupported.");
+        std::cout << __func__ << std::endl
+                  << "src real descriptor: " << srcDesc << std::endl
+                  << "src flat descriptor: " << srcDesc_flat << std::endl
+                  << "dst real descriptor: " << destDesc << std::endl
+                  << "dst flat descriptor: " << dstDesc_flat << std::endl;
     }
+#endif
 
-    size_t srcSize = srcDesc.GetElementSize();
-    std::string parms{};
-
-    if(srcOffset > 0 || destOffset > 0 || srcDesc != destDesc ||
-       (srcDesc.GetElementSpace() != srcDesc.GetElementSize() ||
-        destDesc.GetElementSpace() != destDesc.GetElementSize()))
+    std::size_t srcDim_flat = srcDesc_flat.GetSize();
+    if(srcDim_flat < 1 || srcDim_flat > 5)
+    {
+        MIOPEN_THROW(miopenStatusBadParm, "Tensor dimension sizes unsupported.");
+    }
+   if(srcOffset > 0 || destOffset > 0 || (!(srcDesc_flat.IsPacked() && dstDesc_flat.IsPacked())))
     {
-        tensorDesc_t sKernDesc;
-        tensorDesc_t dKernDesc;
+        std::string kernel_name = "SubTensorOpWithSubTensor" + std::to_string(srcDim_flat) + "d";
 
-        sKernDesc.dims = srcDesc.GetLengths().size();
-        for(int i = 0; i < 5; i++)
+        const std::vector<std::size_t>& lens = srcDesc_flat.GetLengths();
+        std::string network_config = "copy " + std::to_string(srcDesc_flat.GetType());
+        for(auto& len : lens)
         {
-            if(i < sKernDesc.dims)
-            {
-                sKernDesc.lens[i]    = srcDesc.GetLengths()[i];
-                sKernDesc.strides[i] = srcDesc.GetStrides()[i];
-                dKernDesc.lens[i]    = destDesc.GetLengths()[i];
-                dKernDesc.strides[i] = destDesc.GetStrides()[i];
-            }
-            else
-            {
-                sKernDesc.lens[i] = dKernDesc.lens[i] = 1;
-                sKernDesc.strides[i] = dKernDesc.strides[i] = 0;
-            }
+            network_config += " " + std::to_string(len);
         }
 
-        std::vector<size_t> vld = {1, 1, 1};
-        std::vector<size_t> vgd = {1, 1, 1};
+        std::string program_name = "MIOpenSubTensorOpWithSubTensorKernel.cl";
 
-        if(sKernDesc.dims > 2)
-        {
-            vld[0] = 4;
-            vld[1] = 8;
-            vld[2] = 8;
-
-            vgd[0] = (srcDesc.GetLengths()[sKernDesc.dims - 3] > vld[0]
-                          ? srcDesc.GetLengths()[sKernDesc.dims - 3]
-                          : vld[0]);
-            vgd[0] = (vgd[0] > 16) ? 16 : vgd[0];
-
-            vgd[1] = (srcDesc.GetLengths()[sKernDesc.dims - 2] > vld[1]
-                          ? srcDesc.GetLengths()[sKernDesc.dims - 2]
-                          : vld[1]);
-            vgd[1] = (vgd[1] > 64) ? 64 : vgd[1];
-
-            vgd[2] = (srcDesc.GetLengths()[sKernDesc.dims - 1] > vld[2]
-                          ? srcDesc.GetLengths()[sKernDesc.dims - 1]
-                          : vld[2]);
-            vgd[2] = (vgd[2] > 64) ? 64 : vgd[2];
-        }
-        else if(sKernDesc.dims == 1)
+        std::vector<std::size_t> worker_sizes = get_worker_sizes(lens);
+
+        std::size_t wgd = std::accumulate(worker_sizes.begin(),
+                                              worker_sizes.end(),
+                                              std::size_t{1},
+                                              std::multiplies<std::size_t>());
+        std::size_t wld = 256 < wgd ? 256 : wgd;
+
+        std::string parms = "-DSUBTENSOR_OP_WITH_SUBTENSOR=SUBTENSOR_OP_WITH_SUBTENSOR_COPY" +
+                                parms_half_or_float(srcDesc_flat.GetType());
+       for(int i = 0; i < srcDim_flat; ++i)
         {
-            vld[0] = 256;
-            vgd[0] = (srcDesc.GetLengths()[0] > vld[0] ? srcDesc.GetLengths()[0] : vld[0]);
-            vgd[0] = (vgd[0] > 65536) ? 65536 : vgd[0];
+            parms +=
+                " -DWORK_LENGTH_" + std::to_string(i) + "=" + std::to_string(worker_sizes[i]);
         }
-        else if(sKernDesc.dims == 2)
+       
+       switch(srcDim_flat)
         {
-            vld[0] = vld[1] = 16;
-            vgd[0]          = (srcDesc.GetLengths()[0] > vld[0] ? srcDesc.GetLengths()[0] : vld[0]);
-            vgd[0]          = (vgd[0] > 256) ? 256 : vgd[0];
-            vgd[1]          = (srcDesc.GetLengths()[1] > vld[1] ? srcDesc.GetLengths()[1] : vld[1]);
-            vgd[1]          = (vgd[1] > 256) ? 256 : vgd[1];
+            case 1:
+            {
+                handle.GetKernel(kernel_name, network_config, program_name, kernel_name,
+                                 {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                                 src,
+                                 srcOffset,
+                                 int(srcDesc_flat.GetStrides()[0]),
+                                 int(srcDesc_flat.GetLengths()[0]),
+                                 dest,
+                                 destOffset,
+                                 int(dstDesc_flat.GetStrides()[0]));
+                break;
+            }
+case 2:
+            {
+                handle.GetKernel(kernel_name, network_config, program_name, kernel_name,
+                                 {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                                 src,
+                                 srcOffset,
+                                 int(srcDesc_flat.GetStrides()[0]),
+                                 int(srcDesc_flat.GetStrides()[1]),
+                                 int(srcDesc_flat.GetLengths()[0]),
+                                 int(srcDesc_flat.GetLengths()[1]),
+                                 dest,
+                                 destOffset,
+                                 int(dstDesc_flat.GetStrides()[0]),
+                                 int(dstDesc_flat.GetStrides()[1]));
+                break;
+            }
+            case 3:
+            {
+                handle.GetKernel(kernel_name, network_config, program_name, kernel_name,
+                                 {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                                 src,
+                                 srcOffset,
+                                 int(srcDesc_flat.GetStrides()[0]),
+                                 int(srcDesc_flat.GetStrides()[1]),
+                                 int(srcDesc_flat.GetStrides()[2]),
+                                 int(srcDesc_flat.GetLengths()[0]),
+                                 int(srcDesc_flat.GetLengths()[1]),
+                                 int(srcDesc_flat.GetLengths()[2]),
+                                 dest,
+                                 destOffset,
+                                 int(dstDesc_flat.GetStrides()[0]),
+                                 int(dstDesc_flat.GetStrides()[1]),
+                                 int(dstDesc_flat.GetStrides()[2]));
+                break;
+            }
+           case 4:
+            {
+                handle.GetKernel(kernel_name, network_config, program_name, kernel_name,
+                                 {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                                 src,
+                                 srcOffset,
+                                 int(srcDesc_flat.GetStrides()[0]),
+                                 int(srcDesc_flat.GetStrides()[1]),
+                                 int(srcDesc_flat.GetStrides()[2]),
+                                 int(srcDesc_flat.GetStrides()[3]),
+                                 int(srcDesc_flat.GetLengths()[0]),
+                                 int(srcDesc_flat.GetLengths()[1]),
+                                 int(srcDesc_flat.GetLengths()[2]),
+                                 int(srcDesc_flat.GetLengths()[3]),
+                                 dest,
+                                 destOffset,
+                                 int(dstDesc_flat.GetStrides()[0]),
+                                 int(dstDesc_flat.GetStrides()[1]),
+                                 int(dstDesc_flat.GetStrides()[2]),
+                                 int(dstDesc_flat.GetStrides()[3]));
+                break;
+            }
+           case 5:
+            {
+                handle.GetKernel(kernel_name, network_config, program_name, kernel_name,
+                                 {wld, 1, 1}, {wgd, 1, 1}, parms)(
+                                 src,
+                                 srcOffset,
+                                 int(srcDesc_flat.GetStrides()[0]),
+                                 int(srcDesc_flat.GetStrides()[1]),
+                                 int(srcDesc_flat.GetStrides()[2]),
+                                 int(srcDesc_flat.GetStrides()[3]),
+                                 int(srcDesc_flat.GetStrides()[4]),
+                                 int(srcDesc_flat.GetLengths()[0]),
+                                 int(srcDesc_flat.GetLengths()[1]),
+                                 int(srcDesc_flat.GetLengths()[2]),
+                                 int(srcDesc_flat.GetLengths()[3]),
+                                 int(srcDesc_flat.GetLengths()[4]),
+                                 dest,
+                                 destOffset,
+                                 int(dstDesc_flat.GetStrides()[0]),
+                                 int(dstDesc_flat.GetStrides()[1]),
+                                 int(dstDesc_flat.GetStrides()[2]),
+                                 int(dstDesc_flat.GetStrides()[3]),
+                                 int(dstDesc_flat.GetStrides()[4]));
+                break;
+            }
+            default: assert(false);
         }
-        std::string program_name = "MIOpenTensorScaleKernel.cl";
-        handle.GetKernel("CopyTensor", "", program_name, "CopyTensor", vld, vgd, parms)(
-            src,
-            dest,
-            srcOffset,
-            sKernDesc.strides[0],
-            sKernDesc.strides[1],
-            sKernDesc.strides[2],
-            sKernDesc.strides[3],
-            sKernDesc.lens[0],
-            sKernDesc.lens[1],
-            srcDesc.GetElementSpace(),
-            destOffset,
-            dKernDesc.strides[0],
-            dKernDesc.strides[1],
-            dKernDesc.strides[2],
-            dKernDesc.strides[3],
-            dKernDesc.lens[0],
-            dKernDesc.lens[1],
-            dKernDesc.lens[2],
-            dKernDesc.lens[3],
-            dKernDesc.lens[4],
-            destDesc.GetElementSpace(),
-            sKernDesc.dims);
-    }
+   }
     else
     {
-        //        printf("Using handle copy.\n");
-        //        for(int i=0;i<srcDesc.GetStrides().size();i++){
-        //            printf("srcStrides[%d]: %d\n",i,srcDesc.GetStrides()[i]);
-        //            printf("destStrides[%d]: %d\n",i,destDesc.GetStrides()[i]);
-        //        }
-        handle.Copy(src, dest, srcSize * sizeof(srcDesc.GetType()));
+        handle.Copy(src, dest, srcDesc_flat.GetElementSize() * GetTypeSize(srcDesc_flat.GetType()));
     }
 }
 
diff --git a/src/rnn.cpp b/src/rnn.cpp
index c5f67ef..9591e22 100644
--- a/src/rnn.cpp
+++ b/src/rnn.cpp
@@ -34,7 +34,7 @@
 // Disable specific warnings
 #define MIO_RNN_DEBUG 0
 
-#define MIOPEN_RNN_SYNCH 0
+#define MIOPEN_RNN_SYNCH /*0*/ 1
 #define MIO_RNN_CPP_PROF 0
 
 namespace miopen {
diff --git a/src/solver/conv_ocl_dir2Dfwd_exhaustive_search.cpp b/src/solver/conv_ocl_dir2Dfwd_exhaustive_search.cpp
index 594c661..fe2917a 100644
--- a/src/solver/conv_ocl_dir2Dfwd_exhaustive_search.cpp
+++ b/src/solver/conv_ocl_dir2Dfwd_exhaustive_search.cpp
@@ -32,6 +32,7 @@
 #include <miopen/legacy_exhaustive_search.hpp>
 #include <miopen/mlo_utils.hpp>
 #include <miopen/solver.hpp>
+#include <chrono>
 #ifdef max
 #undef max
 #endif
@@ -241,7 +242,10 @@ static int MeasureLoop(Handle* profile_h,
 
             params.GetStream().Finish();
 
-            s = miopen_mach_absolute_time();
+            //s = miopen_mach_absolute_time();
+            // gem5 needs deterministic timer instead, this timer is
+            // implemented and is a user space call
+            auto kernelStart = std::chrono::steady_clock::now();
 
             for(int i = 0; i < iter && ret == 0; i++)
             {
@@ -256,9 +260,15 @@ static int MeasureLoop(Handle* profile_h,
             }
 
             params.GetStream().Finish();
-            e = miopen_mach_absolute_time();
-
-            processing_time = subtractTimes(e, s) / iter;
+            //e = miopen_mach_absolute_time();
+            // gem5 needs deterministic timer instead, this timer is
+            // implemented and is a user space call
+            auto kernelStop = std::chrono::steady_clock::now();
+
+            //processing_time = subtractTimes(e, s) / iter;
+            std::chrono::duration<double> kernelTime = (kernelStop -
+                                                        kernelStart);
+            processing_time = kernelTime.count() / iter;
         }
     }
     catch(miopen::Exception&)
diff --git a/src/tensor.cpp b/src/tensor.cpp
index 68078ba..d62f800 100644
--- a/src/tensor.cpp
+++ b/src/tensor.cpp
@@ -33,15 +33,11 @@
 
 namespace miopen {
 
-TensorDescriptor::TensorDescriptor() {}
+TensorDescriptor::TensorDescriptor() : packed(true) {}
 
 TensorDescriptor::TensorDescriptor(miopenDataType_t t, std::initializer_list<std::size_t> plens)
     : lens(plens), type(t)
 {
-    if(t != miopenFloat)
-    {
-        MIOPEN_THROW(miopenStatusNotImplemented, "Only float datatype is supported");
-    }
     this->CalculateStrides();
 }
 
@@ -50,19 +46,12 @@ TensorDescriptor::TensorDescriptor(miopenDataType_t t,
                                    std::initializer_list<std::size_t> pstrides)
     : lens(plens), strides(pstrides), type(t)
 {
-    if(t != miopenFloat)
-    {
-        MIOPEN_THROW(miopenStatusNotImplemented, "Only float datatype is supported");
-    }
+    packed = (this->GetElementSize() == this->GetElementSpace());
 }
 
 TensorDescriptor::TensorDescriptor(miopenDataType_t t, const int* plens, int size)
-    : lens(plens, plens + size), type(t)
+    : lens(plens, plens + size), packed(true), type(t)
 {
-    if(t != miopenFloat)
-    {
-        MIOPEN_THROW(miopenStatusNotImplemented, "Only float datatype is supported");
-    }
     if(!std::all_of(plens, plens + size, [](int x) { return x >= 0; }))
         MIOPEN_THROW("Invalid length. Length must be greater than 0.");
     this->CalculateStrides();
@@ -73,14 +62,19 @@ TensorDescriptor::TensorDescriptor(miopenDataType_t t,
                                    int size)
     : lens(plens, plens + size), strides(pstrides, pstrides + size), type(t)
 {
-    if(t != miopenFloat)
-    {
-        MIOPEN_THROW(miopenStatusNotImplemented, "Only float datatype is supported");
-    }
     if(!std::all_of(plens, plens + size, [](int x) { return x >= 0; }))
         MIOPEN_THROW("Invalid length. Length must be greater than 0.");
     if(!std::all_of(pstrides, pstrides + size, [](int x) { return x >= 0; }))
         MIOPEN_THROW("Invalid strides. Strides must be greater than 0.");
+    packed = (this->GetElementSize() == this->GetElementSpace());
+}
+
+TensorDescriptor::TensorDescriptor(miopenDataType_t t,
+                                   std::vector<std::size_t> lens_in,
+                                   std::vector<std::size_t> strides_in)
+    : lens(std::move(lens_in)), strides(std::move(strides_in)), type(t)
+{
+    packed = (this->GetElementSize() == this->GetElementSpace());
 }
 
 void TensorDescriptor::CalculateStrides()
@@ -137,6 +131,8 @@ std::size_t TensorDescriptor::GetNumBytes() const
     return typesize * this->GetElementSpace();
 }
 
+bool TensorDescriptor::IsPacked() const { return this->packed; }
+
 bool TensorDescriptor::operator==(const TensorDescriptor& rhs) const
 {
     assert(this->lens.size() == rhs.strides.size());
diff --git a/src/tmp_dir.cpp b/src/tmp_dir.cpp
index ac27c78..e417d83 100644
--- a/src/tmp_dir.cpp
+++ b/src/tmp_dir.cpp
@@ -7,6 +7,7 @@ namespace miopen {
 void SystemCmd(std::string cmd)
 {
 // std::cout << cmd << std::endl;
+    std::cout << cmd << std::endl; // ** TEMP: DEBUG ONLY
 // We shouldn't call system commands
 #ifdef MIOPEN_USE_CLANG_TIDY
     (void)cmd;
